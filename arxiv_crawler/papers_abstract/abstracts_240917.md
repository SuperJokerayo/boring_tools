# Abstracts of Papers

## Physics
### Self-similarity and the direct (enstrophy) cascade in two-dimensional fluid turbulence
**Authors**: Mateo Reynoso, Dmitriy Zhigunov, Roman O. Grigoriev

**Published Date**: 2023-08-06

**Updated Date**: 2024-09-16

**PDF Url**: [2308.03007v2](http://arxiv.org/pdf/2308.03007v2)

**Abstract**: A widely used statistical theory of 2D turbulence developed by Kraichnan,
Leith, and Batchelor (KLB) predicts a power-law scaling for the energy,
$E(k)\propto k^\alpha$ with an integral exponent $\alpha={-3}$, in the inertial
range associated with the direct cascade. In the presence of large-scale
coherent structures, a power-law scaling is observed, but the exponent often
differs substantially from the value predicted by the KLB theory. Here we
present a dynamical theory which describes the key physical mechanism behind
the direct cascade and sheds new light on the relationship between the
structure of the large-scale flow and the scaling of the small-scale structures
in the inertial range. This theory also goes a step beyond KLB, to predict the
upper and lower bounds of the inertial range as well as the energy scaling in
the dissipation range.


### Renormalization of the Einstein-Cartan Theory in First-Order Form
**Authors**: F. T. Brandt, J. Frenkel, S. Martins-Filho, D. G. C. McKeon

**Published Date**: 2024-09-16

**Updated Date**: 2024-09-16

**PDF Url**: [2409.10493v1](http://arxiv.org/pdf/2409.10493v1)

**Abstract**: We examine the Einstein-Cartan (EC) theory in first-order form, which has a
diffeomorphism as well as a local Lorentz invariance. We study the
renormalizability of this theory in the framework of the Batalin-Vilkovisky
formalism, which allows for a gauge invariant renormalization. Using the
background field method, we discuss the gauge invariance of the background
effective action and analyze the Ward identities which reflect the symmetries
of the EC theory. As an application, we compute, in a general background gauge,
the self-energy of the tetrad field at one-loop order.


### Do Pre-trained Vision-Language Models Encode Object States?
**Authors**: Kaleb Newman, Shijie Wang, Yuan Zang, David Heffren, Chen Sun

**Published Date**: 2024-09-16

**Updated Date**: 2024-09-16

**PDF Url**: [2409.10488v1](http://arxiv.org/pdf/2409.10488v1)

**Abstract**: For a vision-language model (VLM) to understand the physical world, such as
cause and effect, a first step is to capture the temporal dynamics of the
visual world, for example how the physical states of objects evolve over time
(e.g. a whole apple into a sliced apple). Our paper aims to investigate if VLMs
pre-trained on web-scale data learn to encode object states, which can be
extracted with zero-shot text prompts. We curate an object state recognition
dataset ChangeIt-Frames, and evaluate nine open-source VLMs, including models
trained with contrastive and generative objectives. We observe that while these
state-of-the-art vision-language models can reliably perform object
recognition, they consistently fail to accurately distinguish the objects'
physical states. Through extensive experiments, we identify three areas for
improvements for VLMs to better encode object states, namely the quality of
object localization, the architecture to bind concepts to objects, and the
objective to learn discriminative visual and language encoders on object
states. Data and code are released.


### Calculus and applications
**Authors**: Teo Banica

**Published Date**: 2024-01-01

**Updated Date**: 2024-09-16

**PDF Url**: [2401.00911v2](http://arxiv.org/pdf/2401.00911v2)

**Abstract**: This is an introduction to calculus, and its applications to basic questions
from physics. We first discuss the theory of functions $f:\mathbb R\to\mathbb
R$, with the notion of continuity, and the construction of the derivative
$f'(x)$ and of the integral $\int_a^bf(x)dx$. Then we investigate the case of
the complex functions $f:\mathbb C\to\mathbb C$, and notably the holomorphic
functions, and harmonic functions. Then, we discuss the multivariable
functions, $f:\mathbb R^N\to\mathbb R^M$ or $f:\mathbb R^N\to\mathbb C^M$ or
$f:\mathbb C^N\to\mathbb C^M$, with general theory, integration results,
maximization questions, and basic applications to physics.


### Hydrodynamic hovering of swimming bacteria above surfaces
**Authors**: Pyae Hein Htet, Debasish Das, Eric Lauga

**Published Date**: 2024-09-16

**Updated Date**: 2024-09-16

**PDF Url**: [2409.10447v1](http://arxiv.org/pdf/2409.10447v1)

**Abstract**: Flagellated bacteria are hydrodynamically attracted to rigid walls, yet past
work shows a 'hovering' state where they swim stably at a finite height above
surfaces. We use numerics and theory to reveal the physical origin of hovering.
Simulations first show that hovering requires an elongated cell body and
results from a tilt away from the wall. Theoretical models then identify two
essential asymmetries: the response of width-asymmetric cells to active flows
created by length-asymmetric cells. A minimal model reconciles near and
far-field hydrodynamics, capturing all key features of hovering.


### Neutrino Mixing from a Fresh Perspective
**Authors**: Pralay Chakraborty, Manash Dey, Biswajit Karmakar, Subhankar Roy

**Published Date**: 2024-05-16

**Updated Date**: 2024-09-16

**PDF Url**: [2405.10353v2](http://arxiv.org/pdf/2405.10353v2)

**Abstract**: We propose a neutrino mass matrix texture bearing a suitable correlation
$m_{22}=-2\,m_{13}$ and study its phenomenological implications. In light of
both normal and inverted hierarchies, the texture imposes specific bounds on
some observational parameters. As a potential application, the prediction of
effective Majorana neutrino mass $m_{\beta\beta}$ is visualized for both
hierarchies. To understand the proposed texture from the first principle, we
incorporate the type-I+II seesaw mechanism in association with $A_4 \times
Z_{10} \times Z_2$ group.


### Thermal fluid closures and pressure anisotropies in numerical simulations of plasma wakefield acceleration
**Authors**: Daniele Simeoni, Andrea Renato Rossi, Gianmarco Parise, Fabio Guglietta, Mauro Sbragaglia

**Published Date**: 2024-04-30

**Updated Date**: 2024-09-16

**PDF Url**: [2404.19635v2](http://arxiv.org/pdf/2404.19635v2)

**Abstract**: We investigate the dynamics of plasma-based acceleration processes with
collisionless particle dynamics and non negligible thermal effects. We aim at
assessing the applicability of fluid-like models, obtained by suitable closure
assumptions applied to the relativistic kinetic equations, thus not suffering
of statistical noise, even in presence of a finite temperature. The work here
presented focuses on the characterization of pressure anisotropies, which
crucially depend on the adopted closure scheme, and hence are useful to discern
the appropriate thermal fluid model. To this aim, simulation results of
spatially resolved fluid models with different thermal closure assumptions are
compared with the results of particle-in-cell (PIC) simulations at changing
temperature and amplitude of plasma oscillations.


### Fundamental physical constants set the observability and operation of phase and other transitions and increase entropy
**Authors**: K. Trachenko

**Published Date**: 2024-08-07

**Updated Date**: 2024-09-16

**PDF Url**: [2408.03773v4](http://arxiv.org/pdf/2408.03773v4)

**Abstract**: Approaching the problem of understanding fundamental physical constants
(FPCs) started with discussing the role these constants play in high-energy
nuclear physics and astrophysics. Condensed matter physics was relatively
unexplored in this regard. More recently, it was realised that FPCs set lower
or upper bounds on key condensed matter properties. In this Perspective, we
discuss a wider role played by FPCs in condensed matter physics: at given
environmental conditions, FPCs set the observability and operation of entire
physical effects and phenomena. We discuss second-order phase transitions
including structural and superconducting transitions and first-order
transitions including melting and boiling. We also discuss metastable states,
transitions between them, chemical reactions and their products. An interesting
byproduct of this discussion is that the order of magnitude of the transition
temperature can be calculated from FPCs. We show that the new states emerging
as a result of various transitions increase the phase space and entropy. Were
FPCs to take different values, these transitions would become inoperative at
our environmental conditions and the new states due to these transitions would
not emerge. This suggests that the current values of FPCs, by enabling various
transitions and reactions which give rise to new states, promote entropy
increase. We propose that this is a general effect that applies to different
levels of structure in the Universe.


### How Haag-tied is QFT, really?
**Authors**: Chris Mitsch, Marian Gilton, David Freeborn

**Published Date**: 2022-12-14

**Updated Date**: 2024-09-16

**PDF Url**: [2212.06977v4](http://arxiv.org/pdf/2212.06977v4)

**Abstract**: Haag's theorem cries out for explanation and critical assessment: it sounds
the alarm that something is (perhaps) not right in one of the standard way of
constructing interacting fields to be used in generating predictions for
scattering experiments. Viewpoints as to the precise nature of the problem, the
appropriate solution, and subsequently-called-for developments in areas of
physics, mathematics, and philosophy differ widely. In this paper, we develop
and deploy a conceptual framework for critically assessing these disparate
responses to Haag's theorem. Doing so reveals the driving force of more general
questions as to the nature and purpose of foundational work in physics.


### Multidimensional Deconvolution with Profiling
**Authors**: Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman

**Published Date**: 2024-09-16

**Updated Date**: 2024-09-16

**PDF Url**: [2409.10421v1](http://arxiv.org/pdf/2409.10421v1)

**Abstract**: In many experimental contexts, it is necessary to statistically remove the
impact of instrumental effects in order to physically interpret measurements.
This task has been extensively studied in particle physics, where the
deconvolution task is called unfolding. A number of recent methods have shown
how to perform high-dimensional, unbinned unfolding using machine learning.
However, one of the assumptions in all of these methods is that the detector
response is accurately modeled in the Monte Carlo simulation. In practice, the
detector response depends on a number of nuisance parameters that can be
constrained with data. We propose a new algorithm called Profile OmniFold
(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm
while being able to simultaneously profile the nuisance parameters. We
illustrate the method with a Gaussian example as a proof of concept
highlighting its promising capabilities.


## Diffusion
### MacDiff: Unified Skeleton Modeling with Masked Conditional Diffusion
**Authors**: Lehong Wu, Lilang Lin, Jiahang Zhang, Yiyang Ma, Jiaying Liu

**Published Date**: 2024-09-16

**Updated Date**: 2024-09-16

**PDF Url**: [2409.10473v1](http://arxiv.org/pdf/2409.10473v1)

**Abstract**: Self-supervised learning has proved effective for skeleton-based human action
understanding. However, previous works either rely on contrastive learning that
suffers false negative problems or are based on reconstruction that learns too
much unessential low-level clues, leading to limited representations for
downstream tasks. Recently, great advances have been made in generative
learning, which is naturally a challenging yet meaningful pretext task to model
the general underlying data distributions. However, the representation learning
capacity of generative models is under-explored, especially for the skeletons
with spacial sparsity and temporal redundancy. To this end, we propose Masked
Conditional Diffusion (MacDiff) as a unified framework for human skeleton
modeling. For the first time, we leverage diffusion models as effective
skeleton representation learners. Specifically, we train a diffusion decoder
conditioned on the representations extracted by a semantic encoder. Random
masking is applied to encoder inputs to introduce a information bottleneck and
remove redundancy of skeletons. Furthermore, we theoretically demonstrate that
our generative objective involves the contrastive learning objective which
aligns the masked and noisy views. Meanwhile, it also enforces the
representation to complement for the noisy view, leading to better
generalization performance. MacDiff achieves state-of-the-art performance on
representation learning benchmarks while maintaining the competence for
generative tasks. Moreover, we leverage the diffusion model for data
augmentation, significantly enhancing the fine-tuning performance in scenarios
with scarce labeled data. Our project is available at
https://lehongwu.github.io/ECCV24MacDiff/.


### On Synthetic Texture Datasets: Challenges, Creation, and Curation
**Authors**: Blaine Hoak, Patrick McDaniel

**Published Date**: 2024-09-16

**Updated Date**: 2024-09-16

**PDF Url**: [2409.10297v1](http://arxiv.org/pdf/2409.10297v1)

**Abstract**: The influence of textures on machine learning models has been an ongoing
investigation, specifically in texture bias/learning, interpretability, and
robustness. However, due to the lack of large and diverse texture data
available, the findings in these works have been limited, as more comprehensive
evaluations have not been feasible. Image generative models are able to provide
data creation at scale, but utilizing these models for texture synthesis has
been unexplored and poses additional challenges both in creating accurate
texture images and validating those images. In this work, we introduce an
extensible methodology and corresponding new dataset for generating
high-quality, diverse texture images capable of supporting a broad set of
texture-based tasks. Our pipeline consists of: (1) developing prompts from a
range of descriptors to serve as input to text-to-image models, (2) adopting
and adapting Stable Diffusion pipelines to generate and filter the
corresponding images, and (3) further filtering down to the highest quality
images. Through this, we create the Prompted Textures Dataset (PTD), a dataset
of 362,880 texture images that span 56 textures. During the process of
generating images, we find that NSFW safety filters in image generation
pipelines are highly sensitive to texture (and flag up to 60\% of our texture
images), uncovering a potential bias in these models and presenting unique
challenges when working with texture data. Through both standard metrics and a
human evaluation, we find that our dataset is high quality and diverse.


### ReflectDiffu: Reflect between Emotion-intent Contagion and Mimicry for Empathetic Response Generation via a RL-Diffusion Framework
**Authors**: Jiahao Yuan, Zixiang Di, Zhiqing Cui, Guisong Yang, Usman Naseem

**Published Date**: 2024-09-16

**Updated Date**: 2024-09-16

**PDF Url**: [2409.10289v1](http://arxiv.org/pdf/2409.10289v1)

**Abstract**: Empathetic response generation necessitates the integration of emotional and
intentional dynamics to foster meaningful interactions. Existing research
either neglects the intricate interplay between emotion and intent, leading to
suboptimal controllability of empathy, or resorts to large language models
(LLMs), which incur significant computational overhead. In this paper, we
introduce ReflectDiffu, a lightweight and comprehensive framework for
empathetic response generation. This framework incorporates emotion contagion
to augment emotional expressiveness and employs an emotion-reasoning mask to
pinpoint critical emotional elements. Additionally, it integrates intent
mimicry within reinforcement learning for refinement during diffusion. By
harnessing an intent twice reflect the mechanism of
Exploring-Sampling-Correcting, ReflectDiffu adeptly translates emotional
decision-making into precise intent actions, thereby addressing empathetic
response misalignments stemming from emotional misrecognition. Through
reflection, the framework maps emotional states to intents, markedly enhancing
both response empathy and flexibility. Comprehensive experiments reveal that
ReflectDiffu outperforms existing models regarding relevance, controllability,
and informativeness, achieving state-of-the-art results in both automatic and
human evaluations.


### DreamHead: Learning Spatial-Temporal Correspondence via Hierarchical Diffusion for Audio-driven Talking Head Synthesis
**Authors**: Fa-Ting Hong, Yunfei Liu, Yu Li, Changyin Zhou, Fei Yu, Dan Xu

**Published Date**: 2024-09-16

**Updated Date**: 2024-09-16

**PDF Url**: [2409.10281v1](http://arxiv.org/pdf/2409.10281v1)

**Abstract**: Audio-driven talking head synthesis strives to generate lifelike video
portraits from provided audio. The diffusion model, recognized for its superior
quality and robust generalization, has been explored for this task. However,
establishing a robust correspondence between temporal audio cues and
corresponding spatial facial expressions with diffusion models remains a
significant challenge in talking head generation. To bridge this gap, we
present DreamHead, a hierarchical diffusion framework that learns
spatial-temporal correspondences in talking head synthesis without compromising
the model's intrinsic quality and adaptability.~DreamHead learns to predict
dense facial landmarks from audios as intermediate signals to model the spatial
and temporal correspondences.~Specifically, a first hierarchy of
audio-to-landmark diffusion is first designed to predict temporally smooth and
accurate landmark sequences given audio sequence signals. Then, a second
hierarchy of landmark-to-image diffusion is further proposed to produce
spatially consistent facial portrait videos, by modeling spatial
correspondences between the dense facial landmark and appearance. Extensive
experiments show that proposed DreamHead can effectively learn spatial-temporal
consistency with the designed hierarchical diffusion and produce high-fidelity
audio-driven talking head videos for multiple identities.


### A Survey on Statistical Theory of Deep Learning: Approximation, Training Dynamics, and Generative Models
**Authors**: Namjoon Suh, Guang Cheng

**Published Date**: 2024-01-14

**Updated Date**: 2024-09-16

**PDF Url**: [2401.07187v3](http://arxiv.org/pdf/2401.07187v3)

**Abstract**: In this article, we review the literature on statistical theories of neural
networks from three perspectives: approximation, training dynamics and
generative models. In the first part, results on excess risks for neural
networks are reviewed in the nonparametric framework of regression (and
classification in Appendix~{\color{blue}B}). These results rely on explicit
constructions of neural networks, leading to fast convergence rates of excess
risks. Nonetheless, their underlying analysis only applies to the global
minimizer in the highly non-convex landscape of deep neural networks. This
motivates us to review the training dynamics of neural networks in the second
part. Specifically, we review papers that attempt to answer ``how the neural
network trained via gradient-based methods finds the solution that can
generalize well on unseen data.'' In particular, two well-known paradigms are
reviewed: the Neural Tangent Kernel (NTK) paradigm, and Mean-Field (MF)
paradigm. Last but not least, we review the most recent theoretical
advancements in generative models including Generative Adversarial Networks
(GANs), diffusion models, and in-context learning (ICL) in the Large Language
Models (LLMs) from two perpsectives reviewed previously, i.e., approximation
and training dynamics.


