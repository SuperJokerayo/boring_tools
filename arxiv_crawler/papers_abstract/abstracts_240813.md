# Abstracts of Papers

## Physics
### Non-Maxwellian Ion Distribution in the Equatorial and Auroral Electrojets
**Authors**: Rattanakorn Koontaweepunya, Yakov S. Dimant, Meers M. Oppenheim

**Published Date**: 2024-08-12

**Updated Date**: 2024-08-12

**PDF Url**: [2408.06339v1](http://arxiv.org/pdf/2408.06339v1)

**Abstract**: Strong electric fields in the auroral and equatorial electrojets can distort
the background ion distribution function away from Maxwellian. We developed a
collisional plasma kinetic model using the Boltzmann equation and a simple BGK
collision operator which predicts a relatively simple relationship between the
intensity of the background electric field and the resulting ion distribution
function. To test the model, we perform 3-D plasma particle-in-cell simulations
and compare the results to the model. The simulation applies an elastic
collision operator assuming a constant ion-neutral collision rate. These
simulations show less ion heating in the Pedersen direction than the analytic
model but show similar overall heating. The model overestimates the heating in
the Pedersen direction because the simple BGK operator includes no angular
collisional scattering in the ion velocity space. On the other hand, the
fully-kinetic particle-in-cell code is able to capture the physics of ion
scattering in 3-D and therefore heats ions more isotropically. Although the
simple BGK analytic theory does not precisely model the non-Maxwellian ion
distribution function, it does capture the overall momentum and energy flows
and therefore can provide the basis of further analysis of E-region wave
evolution.


### Nicolai maps for super Yang-Mills on the light cone
**Authors**: Olaf Lechtenfeld

**Published Date**: 2024-06-06

**Updated Date**: 2024-08-12

**PDF Url**: [2406.04406v2](http://arxiv.org/pdf/2406.04406v2)

**Abstract**: We construct Nicolai maps for supersymmetric Yang-Mills theory in four and
ten spacetime dimensions in the light-cone gauge, where the elimination of
non-propagating degrees of freedom causes nonlocal and four-fermi interactions
in the Lagrangian. The presence of the latter used to be an obstruction to the
Nicolai map, which has recently been overcome at the price of quantum
corrections to the map. No gauge-fixing or ghost terms arise in this
formulation, since only physical transverse degrees of freedom occur. We
present an explicit form of the Nicolai map to second order in the gauge
coupling. In four dimensions, a `chiral' choice of the map leaves one of the
two transverse gauge-field modes invariant, which forces the classical part of
the map (on the other mode) to become a polynomial (quadratic in the gauge
coupling, cubic in the gauge field)! In the power series expansion for the
ten-dimensional map however, cancellations at each order in the coupling are
systematic but incomplete, still leaving an infinite power series for the
Nicolai map (on all eight transverse modes). Nevertheless, the existence of a
polynomial variant is conceivable, also for the maximal ${\cal N}{=}\,4$ theory
in four dimensions.


### Dynamical resource theory of incompatibility preservability
**Authors**: Chung-Yun Hsieh, Benjamin Stratton, Chao-Hsien Wu, Huan-Yu Ku

**Published Date**: 2024-08-12

**Updated Date**: 2024-08-12

**PDF Url**: [2408.06315v1](http://arxiv.org/pdf/2408.06315v1)

**Abstract**: The uncertainty principle is one of quantum theory's most foundational
features. It underpins a quantum phenomenon called measurement incompatibility
-- two physical observables of a single quantum system may not always be
measured simultaneously. Apart from being fundamentally important, measurement
incompatibility is also a powerful resource in the broad quantum science and
technologies, with wide applications to cryptography, communication, random
number generation, and device-independent tasks. Since every physical system is
unavoidably subject to noise, an important, yet still open, question is how to
characterise the ability of noisy quantum dynamics to preserve measurement
incompatibility. This work fills this gap by providing the first resource
theory of this ability, termed incompatibility preservability. We quantify
incompatibility preservability by a robustness measure. Then, we introduce an
operational task, entanglement-assisted filter game, to completely characterise
both the robustness measure and the conversion of incompatibility
preservability. Our results provide a general framework to describe how noisy
dynamics affect the uncertainty principle's signature.


### Inverse designing metamaterials with programmable nonlinear functional responses in graph space
**Authors**: Marco Maurizi, Derek Xu, Yu-Tong Wang, Desheng Yao, David Hahn, Mourad Oudich, Anish Satpati, Mathieu Bauchy, Wei Wang, Yizhou Sun, Yun Jing, Xiaoyu Rayne Zheng

**Published Date**: 2024-08-12

**Updated Date**: 2024-08-12

**PDF Url**: [2408.06300v1](http://arxiv.org/pdf/2408.06300v1)

**Abstract**: Material responses to static and dynamic stimuli, represented as nonlinear
curves, are design targets for engineering functionalities like structural
support, impact protection, and acoustic and photonic bandgaps.
Three-dimensional metamaterials offer significant tunability due to their
internal structure, yet existing methods struggle to capture their complex
behavior-to-structure relationships. We present GraphMetaMat, a graph-based
framework capable of designing three-dimensional metamaterials with
programmable responses and arbitrary manufacturing constraints. Integrating
graph networks, physics biases, reinforcement learning, and tree search,
GraphMetaMat can target stress-strain curves spanning four orders of magnitude
and complex behaviors, as well as viscoelastic transmission responses with
varying attenuation gaps. GraphMetaMat can create cushioning materials for
protective equipment and vibration-damping panels for electric vehicles,
outperforming commercial materials, and enabling the automatic design of
materials with on-demand functionalities.


### Stabilizer Entanglement Distillation and Efficient Fault-Tolerant Encoder
**Authors**: Yu Shi, Ashlesha Patil, Saikat Guha

**Published Date**: 2024-08-12

**Updated Date**: 2024-08-12

**PDF Url**: [2408.06299v1](http://arxiv.org/pdf/2408.06299v1)

**Abstract**: Entanglement is essential for quantum information processing but is limited
by noise. We address this by developing high-yield entanglement distillation
protocols with several advancements. (1) We extend the 2-to-1 recurrence
entanglement distillation protocol to higher-rate n-to-(n-1) protocols that can
correct any single-qubit errors. These protocols are evaluated through
numerical simulations focusing on fidelity and yield. We also outline a method
to adapt any classical error-correcting code for entanglement distillation,
where the code can correct both bit-flip and phase-flip errors by incorporating
Hadamard gates. (2) We propose a constant-depth decoder for stabilizer codes
that transforms logical states into physical ones using single-qubit
measurements. This decoder is applied to entanglement distillation protocols,
reducing circuit depth and enabling protocols derived from advanced quantum
error-correcting codes. We demonstrate this by evaluating the circuit
complexity for entanglement distillation protocols based on surface codes and
quantum convolutional codes. (3) Our stabilizer entanglement distillation
techniques advance quantum computing. We propose a fault-tolerant protocol for
constant-depth encoding and decoding of arbitrary quantum states, applicable to
quantum low-density parity-check (qLDPC) codes and surface codes. This protocol
is feasible with state-of-the-art reconfigurable atom arrays and surpasses the
limits of conventional logarithmic depth encoders. Overall, our study
integrates stabilizer formalism, measurement-based quantum computing, and
entanglement distillation, advancing both quantum communication and computing.


### Adjoint-Based Enforcement of State Constraints in PDE Optimization Problems
**Authors**: Pritpal Matharu, Bartosz Protas

**Published Date**: 2023-12-04

**Updated Date**: 2024-08-12

**PDF Url**: [2312.01929v2](http://arxiv.org/pdf/2312.01929v2)

**Abstract**: This study demonstrates how the adjoint-based framework traditionally used to
compute gradients in PDE optimization problems can be extended to handle
general constraints on the state variables. This is accomplished by
constructing a projection of the gradient of the objective functional onto a
subspace tangent to the manifold defined by the constraint. This projection is
realized by solving an adjoint problem defined in terms of the same adjoint
operator as used in the system employed to determine the gradient, but with a
different forcing. We focus on the "optimize-then-discretize" paradigm in the
infinite-dimensional setting where the required regularity of both the gradient
and of the projection is ensured. The proposed approach is illustrated with two
examples: a simple test problem describing optimization of heat transfer in one
direction and a more involved problem where an optimal closure is found for a
turbulent flow described by the Navier-Stokes system in two dimensions, both
considered subject to different state constraints. The accuracy of the
gradients and projections computed by solving suitable adjoint systems is
carefully verified and the presented computational results show that the
solutions of the optimization problems obtained with the proposed approach
satisfy the state constraints with a good accuracy, although not exactly.


### DUNE: A Machine Learning Deep UNet++ based Ensemble Approach to Monthly, Seasonal and Annual Climate Forecasting
**Authors**: Pratik Shukla, Milton Halem

**Published Date**: 2024-08-12

**Updated Date**: 2024-08-12

**PDF Url**: [2408.06262v1](http://arxiv.org/pdf/2408.06262v1)

**Abstract**: Capitalizing on the recent availability of ERA5 monthly averaged long-term
data records of mean atmospheric and climate fields based on high-resolution
reanalysis, deep-learning architectures offer an alternative to physics-based
daily numerical weather predictions for subseasonal to seasonal (S2S) and
annual means. A novel Deep UNet++-based Ensemble (DUNE) neural architecture is
introduced, employing multi-encoder-decoder structures with residual blocks.
When initialized from a prior month or year, this architecture produced the
first AI-based global monthly, seasonal, or annual mean forecast of 2-meter
temperatures (T2m) and sea surface temperatures (SST). ERA5 monthly mean data
is used as input for T2m over land, SST over oceans, and solar radiation at the
top of the atmosphere for each month of 40 years to train the model. Validation
forecasts are performed for an additional two years, followed by five years of
forecast evaluations to account for natural annual variability. AI-trained
inference forecast weights generate forecasts in seconds, enabling ensemble
seasonal forecasts. Root Mean Squared Error (RMSE), Anomaly Correlation
Coefficient (ACC), and Heidke Skill Score (HSS) statistics are presented
globally and over specific regions. These forecasts outperform persistence,
climatology, and multiple linear regression for all domains. DUNE forecasts
demonstrate comparable statistical accuracy to NOAA's operational monthly and
seasonal probabilistic outlook forecasts over the US but at significantly
higher resolutions. RMSE and ACC error statistics for other recent AI-based
daily forecasts also show superior performance for DUNE-based forecasts. The
DUNE model's application to an ensemble data assimilation cycle shows
comparable forecast accuracy with a single high-resolution model, potentially
eliminating the need for retraining on extrapolated datasets.


### Quantum Simulations of Chemistry in First Quantization with any Basis Set
**Authors**: Timothy N. Georges, Marius Bothe, Christoph Sünderhauf, Bjorn K. Berntson, Róbert Izsák, Aleksei V. Ivanov

**Published Date**: 2024-08-06

**Updated Date**: 2024-08-12

**PDF Url**: [2408.03145v2](http://arxiv.org/pdf/2408.03145v2)

**Abstract**: Quantum computation of the energy of molecules and materials is one of the
most promising applications of fault-tolerant quantum computers. However,
practical applications require algorithms with reduced resource requirements.
Previous work has mainly represented the Hamiltonian of the system in second
quantization. Existing methods in first quantization are limited to grid-based
approaches that do not allow for active space calculations. In this work, we
present a method to solve the generic ground-state chemistry problem in first
quantization on a fault-tolerant quantum computer using any basis set. This
allows for calculations in the active space using modern quantum chemistry
basis sets. We derive a linear-combination-of-unitaries decomposition for a
chemical Hamiltonian in first quantization and then construct an efficient
block encoding, exploiting sparsity of the Hamiltonian. For active space
calculations using a molecular orbital basis set, we achieve an asymptotic
speed up in Toffoli-gate count compared to the equivalent method in second
quantization [Berry, et. al. Quantum 3, 208 (2019)]. We also consider the dual
plane waves for materials simulations and find that in physically interesting
regimes we achieve orders of magnitude improvement in quantum resources
compared to the second quantization counterpart. In some instances, our
approach provides similar or even lower resources compared to the first
quantization plane wave algorithm of Refs.[Babbush, et. al npj Quantum Inf 5(1)
92 (2019), Su et. al PRX Quantum 2(4), 040332 (2021)] that, unlike our
approach, avoids loading the classical data from quantum memory. This work
opens up possibilities to reduce quantum resources even further using
factorization methods of a Hamiltonian or modern pseudopotentials. Furthermore,
our approach can be adapted to other applications, such as the vibrational
properties of chemical systems.


### One-loop impact factors for heavy quarkonium production: $S$-wave case
**Authors**: Maxim Nefedov

**Published Date**: 2024-08-12

**Updated Date**: 2024-08-12

**PDF Url**: [2408.06234v1](http://arxiv.org/pdf/2408.06234v1)

**Abstract**: With the aim to extend the study of inclusive heavy quarkonium production at
forward rapidities with the resummation of high partinic
center-of-momentum-energy logarithms beyond Leading Logarithmic Approximation
(LLA), the explicit analytic results for one-loop corrections to the following
impact factors had been obtained: $\gamma R \to Q\bar{Q}\left[^1S_0^{[8]}
\right]$, $g R \to Q\bar{Q}\left[^1S_0^{[1]} \right]$, $gR\to Q\bar{Q}\left[
^1S_0^{[8]} \right]$ and $gR\to Q\bar{Q}\left[ ^3S_1^{[8]}\right]$, with $R$
being the Reggeized gluon and $Q$ is the heavy quark. The computation is done
in the framework of Lipatov's gauge-invariant EFT for Multi-Regge processes in
QCD with the tilted-Wilson-line regularisation for rapidity divergences. As
expected, only single-logarithmic rapidity divergence proportional to the
one-loop Regge trajetory of a gluon remains in the final result for
impact-factors. Numerical comparison with Regge limits ($s/(-t) \gg 1$) of
one-loop QCD amplitudes, described in the paper, provides a strong cross-check
of obtained results. The relations of obtained results with other
regularisation schemes for rapidity divergences used in low-$x$ physics, such
as BFKL scheme, High-Energy Factorisation (HEF) scheme and shockwave scheme,
are given.


### A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring
**Authors**: Vispi Karkaria, Jie Chen, Christopher Luey, Chase Siuta, Damien Lim, Robert Radulescu, Wei Chen

**Published Date**: 2024-08-12

**Updated Date**: 2024-08-12

**PDF Url**: [2408.06220v1](http://arxiv.org/pdf/2408.06220v1)

**Abstract**: We introduce a novel digital twin framework for predictive maintenance of
long-term physical systems. Using monitoring tire health as an application, we
show how the digital twin framework can be used to enhance automotive safety
and efficiency, and how the technical challenges can be overcome using a
three-step approach. Firstly, for managing the data complexity over a long
operation span, we employ data reduction techniques to concisely represent
physical tires using historical performance and usage data. Relying on these
data, for fast real-time prediction, we train a transformer-based model offline
on our concise dataset to predict future tire health over time, represented as
Remaining Casing Potential (RCP). Based on our architecture, our model
quantifies both epistemic and aleatoric uncertainty, providing reliable
confidence intervals around predicted RCP. Secondly, to incorporate real-time
data, we update the predictive model in the digital twin framework, ensuring
its accuracy throughout its life span with the aid of hybrid modeling and the
use of discrepancy function. Thirdly, to assist decision making in predictive
maintenance, we implement a Tire State Decision Algorithm, which strategically
determines the optimal timing for tire replacement based on RCP forecasted by
our transformer model. This approach ensures our digital twin accurately
predicts system health, continually refines its digital representation, and
supports predictive maintenance decisions. Our framework effectively embodies a
physical system, leveraging big data and machine learning for predictive
maintenance, model updates, and decision-making.


## Diffusion
### The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery
**Authors**: Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha

**Published Date**: 2024-08-12

**Updated Date**: 2024-08-12

**PDF Url**: [2408.06292v1](http://arxiv.org/pdf/2408.06292v1)

**Abstract**: One of the grand challenges of artificial general intelligence is developing
agents capable of conducting scientific research and discovering new knowledge.
While frontier models have already been used as aids to human scientists, e.g.
for brainstorming ideas, writing code, or prediction tasks, they still conduct
only a small part of the scientific process. This paper presents the first
comprehensive framework for fully automatic scientific discovery, enabling
frontier large language models to perform research independently and
communicate their findings. We introduce The AI Scientist, which generates
novel research ideas, writes code, executes experiments, visualizes results,
describes its findings by writing a full scientific paper, and then runs a
simulated review process for evaluation. In principle, this process can be
repeated to iteratively develop ideas in an open-ended fashion, acting like the
human scientific community. We demonstrate its versatility by applying it to
three distinct subfields of machine learning: diffusion modeling,
transformer-based language modeling, and learning dynamics. Each idea is
implemented and developed into a full paper at a cost of less than $15 per
paper. To evaluate the generated papers, we design and validate an automated
reviewer, which we show achieves near-human performance in evaluating paper
scores. The AI Scientist can produce papers that exceed the acceptance
threshold at a top machine learning conference as judged by our automated
reviewer. This approach signifies the beginning of a new era in scientific
discovery in machine learning: bringing the transformative benefits of AI
agents to the entire research process of AI itself, and taking us closer to a
world where endless affordable creativity and innovation can be unleashed on
the world's most challenging problems. Our code is open-sourced at
https://github.com/SakanaAI/AI-Scientist


### Unified Discrete Diffusion for Categorical Data
**Authors**: Lingxiao Zhao, Xueying Ding, Lijun Yu, Leman Akoglu

**Published Date**: 2024-02-06

**Updated Date**: 2024-08-12

**PDF Url**: [2402.03701v2](http://arxiv.org/pdf/2402.03701v2)

**Abstract**: Discrete diffusion models have seen a surge of attention with applications on
naturally discrete data such as language and graphs. Although discrete-time
discrete diffusion has been established for a while, only recently Campbell et
al. (2022) introduced the first framework for continuous-time discrete
diffusion. However, their training and sampling processes differ significantly
from the discrete-time version, necessitating nontrivial approximations for
tractability. In this paper, we first present a series of mathematical
simplifications of the variational lower bound that enable more accurate and
easy-to-optimize training for discrete diffusion. In addition, we derive a
simple formulation for backward denoising that enables exact and accelerated
sampling, and importantly, an elegant unification of discrete-time and
continuous-time discrete diffusion. Thanks to simpler analytical formulations,
both forward and now also backward probabilities can flexibly accommodate any
noise distribution, including different noise distributions for multi-element
objects. Experiments show that our proposed USD3 (for Unified Simplified
Discrete Denoising Diffusion) outperform all SOTA baselines on established
datasets. We open-source our unified code at
https://github.com/LingxiaoShawn/USD3.


### Control-A-Video: Controllable Text-to-Video Diffusion Models with Motion Prior and Reward Feedback Learning
**Authors**: Weifeng Chen, Yatai Ji, Jie Wu, Hefeng Wu, Pan Xie, Jiashi Li, Xin Xia, Xuefeng Xiao, Liang Lin

**Published Date**: 2023-05-23

**Updated Date**: 2024-08-12

**PDF Url**: [2305.13840v3](http://arxiv.org/pdf/2305.13840v3)

**Abstract**: Recent advances in text-to-image (T2I) diffusion models have enabled
impressive image generation capabilities guided by text prompts. However,
extending these techniques to video generation remains challenging, with
existing text-to-video (T2V) methods often struggling to produce high-quality
and motion-consistent videos. In this work, we introduce Control-A-Video, a
controllable T2V diffusion model that can generate videos conditioned on text
prompts and reference control maps like edge and depth maps. To tackle video
quality and motion consistency issues, we propose novel strategies to
incorporate content prior and motion prior into the diffusion-based generation
process. Specifically, we employ a first-frame condition scheme to transfer
video generation from the image domain. Additionally, we introduce
residual-based and optical flow-based noise initialization to infuse motion
priors from reference videos, promoting relevance among frame latents for
reduced flickering. Furthermore, we present a Spatio-Temporal Reward Feedback
Learning (ST-ReFL) algorithm that optimizes the video diffusion model using
multiple reward models for video quality and motion consistency, leading to
superior outputs. Comprehensive experiments demonstrate that our framework
generates higher-quality, more consistent videos compared to existing
state-of-the-art methods in controllable text-to-video generation


### Between Randomness and Arbitrariness: Some Lessons for Reliable Machine Learning at Scale
**Authors**: A. Feder Cooper

**Published Date**: 2024-06-13

**Updated Date**: 2024-08-12

**PDF Url**: [2406.09548v2](http://arxiv.org/pdf/2406.09548v2)

**Abstract**: To develop rigorous knowledge about ML models -- and the systems in which
they are embedded -- we need reliable measurements. But reliable measurement is
fundamentally challenging, and touches on issues of reproducibility,
scalability, uncertainty quantification, epistemology, and more. This
dissertation addresses criteria needed to take reliability seriously: both
criteria for designing meaningful metrics, and for methodologies that ensure
that we can dependably and efficiently measure these metrics at scale and in
practice. In doing so, this dissertation articulates a research vision for a
new field of scholarship at the intersection of machine learning, law, and
policy. Within this frame, we cover topics that fit under three different
themes: (1) quantifying and mitigating sources of arbitrariness in ML, (2)
taming randomness in uncertainty estimation and optimization algorithms, in
order to achieve scalability without sacrificing reliability, and (3) providing
methods for evaluating generative-AI systems, with specific focuses on
quantifying memorization in language models and training latent diffusion
models on open-licensed data. By making contributions in these three themes,
this dissertation serves as an empirical proof by example that research on
reliable measurement for machine learning is intimately and inescapably bound
up with research in law and policy. These different disciplines pose similar
research questions about reliable measurement in machine learning. They are, in
fact, two complementary sides of the same research vision, which, broadly
construed, aims to construct machine-learning systems that cohere with broader
societal values.


### Residual Corrective Diffusion Modeling for Km-scale Atmospheric Downscaling
**Authors**: Morteza Mardani, Noah Brenowitz, Yair Cohen, Jaideep Pathak, Chieh-Yu Chen, Cheng-Chin Liu, Arash Vahdat, Mohammad Amin Nabian, Tao Ge, Akshay Subramaniam, Karthik Kashinath, Jan Kautz, Mike Pritchard

**Published Date**: 2023-09-24

**Updated Date**: 2024-08-11

**PDF Url**: [2309.15214v4](http://arxiv.org/pdf/2309.15214v4)

**Abstract**: The state of the art for physical hazard prediction from weather and climate
requires expensive km-scale numerical simulations driven by coarser resolution
global inputs. Here, a generative diffusion architecture is explored for
downscaling such global inputs to km-scale, as a cost-effective machine
learning alternative. The model is trained to predict 2km data from a regional
weather model over Taiwan, conditioned on a 25km global reanalysis. To address
the large resolution ratio, different physics involved at different scales and
prediction of channels beyond those in the input data, we employ a two-step
approach where a UNet predicts the mean and a corrector diffusion (CorrDiff)
model predicts the residual. CorrDiff exhibits encouraging skill in bulk MAE
and CRPS scores. The predicted spectra and distributions from CorrDiff
faithfully recover important power law relationships in the target data. Case
studies of coherent weather phenomena show that CorrDiff can help sharpen wind
and temperature gradients that co-locate with intense rainfall in cold front,
and can help intensify typhoons and synthesize rain band structures.
Calibration of model uncertainty remains challenging. The prospect of unifying
methods like CorrDiff with coarser resolution global weather models implies a
potential for global-to-regional multi-scale machine learning simulation.


