# Abstracts of Papers

## Physics
### Mental Modeling of Reinforcement Learning Agents by Language Models
**Authors**: Wenhao Lu, Xufeng Zhao, Josua Spisak, Jae Hee Lee, Stefan Wermter

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18505v1](http://arxiv.org/pdf/2406.18505v1)

**Abstract**: Can emergent language models faithfully model the intelligence of
decision-making agents? Though modern language models exhibit already some
reasoning ability, and theoretically can potentially express any probable
distribution over tokens, it remains underexplored how the world knowledge
these pretrained models have memorized can be utilized to comprehend an agent's
behaviour in the physical world. This study empirically examines, for the first
time, how well large language models (LLMs) can build a mental model of agents,
termed agent mental modelling, by reasoning about an agent's behaviour and its
effect on states from agent interaction history. This research may unveil the
potential of leveraging LLMs for elucidating RL agent behaviour, addressing a
key challenge in eXplainable reinforcement learning (XRL). To this end, we
propose specific evaluation metrics and test them on selected RL task datasets
of varying complexity, reporting findings on agent mental model establishment.
Our results disclose that LLMs are not yet capable of fully mental modelling
agents through inference alone without further innovations. This work thus
provides new insights into the capabilities and limitations of modern LLMs.


### $Λ_{\rm s}$CDM cosmology: Alleviating major cosmological tensions by predicting standard neutrino properties
**Authors**: Anita Yadav, Suresh Kumar, Cihad Kibris, Ozgur Akarsu

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18496v1](http://arxiv.org/pdf/2406.18496v1)

**Abstract**: We investigate a two-parameter extension of the $\Lambda_{\rm s}$CDM model by
allowing variations in the effective number of neutrino species $N_{\rm eff}$
and their total mass $\sum m_\nu$. Our motivation is twofold: (i) to examine
whether $\Lambda_{\rm s}$CDM retains its success in fitting the data and
addressing major cosmological tensions, without suggesting a need for a
deviation from the standard model of particle physics, and (ii) to determine
whether the data indicate new physics that could potentially address
cosmological tensions, either in the post-recombination universe through the
late-time mirror AdS-dS transition, or in the pre-recombination universe
through modifications in the standard values of $N_{\rm eff}$ and $\sum m_\nu$,
or both. Within the extended $\Lambda_{\rm s}$CDM model, referred to as
$\Lambda_{\rm s}$CDM+$N_{\rm eff}$+$\sum m_{\rm \nu}$, we find no significant
tension when considering the Planck-alone analysis. We observe that
incorporating BAO data limits the further success of the $\Lambda_{\rm s}$CDM
extension. However, the weakly model-dependent BAOtr data, along with Planck
and Planck+PP\&SH0ES, favor $H_0\sim 73\,{\rm km\, s^{-1}\, Mpc^{-1}}$. In
cases where BAOtr dataset is used, the mirror AdS-dS transition is very
effective in providing enhanced $H_0$ values, and thus the model requires no
significant deviation from the standard value of $N_{\rm eff} = 3.044$. Both
the $H_0$ and $S_8$ tensions are effectively addressed, with some compromise in
the case of the Planck+BAO dataset. Finally, the upper bounds obtained on $\sum
m_\nu \lesssim 0.5$~eV are fully compatible with neutrino oscillation
experiments. Our findings provide evidence that late-time physics beyond
$\Lambda$CDM, such as $\Lambda_{\rm s}$CDM, without altering the standard
pre-recombination universe, can suffice to alleviate the major cosmological
tensions.


### Indefinite Causal Structure and Causal Inequalities with Time-Symmetry
**Authors**: Luke Mrini, Lucien Hardy

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18489v1](http://arxiv.org/pdf/2406.18489v1)

**Abstract**: Time-reversal symmetry is a prevalent feature of microscopic physics,
including operational quantum theory and classical general relativity. Previous
works have studied indefinite causal structure using the language of
operational quantum theory, however, these rely on time-asymmetric conditions
to constrain both operations and the process matrix. Here, we use
time-symmetric, operational probabilistic theory to develop a time-symmetric
process matrix formalism for indefinite causal structure. This framework allows
for more processes than previously considered and a larger set of causal
inequalities. We demonstrate that this larger set of causal inequalities offers
new opportunities for device-independent certification of causal
non-separability by violating new inequalities. Additionally, we determined
that the larger class of time-symmetric processes found here is equivalent to
those with Indefinite Causal Order and Time Direction (ICOTD) considered by
Chiribella and Liu, thereby providing a description of these processes in terms
of process matrices.


### Modeling the amplitude and energy decay of a weakly damped harmonic oscillator using the energy dissipation rate and a simple trick
**Authors**: Karlo Lelas, Robert Pezer

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18488v1](http://arxiv.org/pdf/2406.18488v1)

**Abstract**: We demonstrate how to derive the exponential decrease of amplitude and an
excellent approximation of the energy decay of a weakly damped harmonic
oscillator. This is achieved using a basic understanding of the undamped
harmonic oscillator and the connection between the damping force's power and
the energy dissipation rate. The trick is to add the energy dissipation rates
corresponding to two specific pairs of initial conditions with the same initial
energy. In this way, we obtain a first-order differential equation from which
we quickly determine the time-dependent amplitude and the energies
corresponding to each pair of considered initial conditions. Comparing the
results of our model to the exact solutions and energies yielded an excellent
agreement. The physical concepts and mathematical tools we utilize are familiar
to first-year undergraduates.


### NuHepMC: A standardized event record format for neutrino event generators
**Authors**: S. Gardiner, J. Isaacson, L. Pickering

**Published Date**: 2023-10-20

**Updated Date**: 2024-06-26

**PDF Url**: [2310.13211v2](http://arxiv.org/pdf/2310.13211v2)

**Abstract**: Simulations of neutrino interactions are playing an increasingly important
role in the pursuit of high-priority measurements for the field of particle
physics. A significant technical barrier for efficient development of these
simulations is the lack of a standard data format for representing individual
neutrino scattering events. We propose and define such a universal format,
named NuHepMC, as a common standard for the output of neutrino event
generators. The NuHepMC format uses data structures and concepts from the
HepMC3 event record library adopted by other subfields of high-energy physics.
These are supplemented with an original set of conventions for generically
representing neutrino interaction physics within the HepMC3 infrastructure.


### Universal Anomaly Detection at the LHC: Transforming Optimal Classifiers and the DDD Method
**Authors**: Sascha Caron, José Enrique García Navarro, María Moreno Llácer, Polina Moskvitina, Mats Rovers, Adrián Rubio Jímenez, Roberto Ruiz de Austri, Zhongyi Zhang

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18469v1](http://arxiv.org/pdf/2406.18469v1)

**Abstract**: In this work, we present a novel approach to transform supervised classifiers
into effective unsupervised anomaly detectors. The method we have developed,
termed Discriminatory Detection of Distortions (DDD), enhances anomaly
detection by training a discriminator model on both original and artificially
modified datasets. We conducted a comprehensive evaluation of our models on the
Dark Machines Anomaly Score Challenge channels and a search for 4-top quark
events, demonstrating the effectiveness of our approach across various final
states and beyond the Standard Model scenarios.
  We compare the performance of the DDD method with the Deep Robust One-Class
Classification method (DROCC), which incorporates signals in the training
process, and the Deep Support Vector Data Description (DeepSVDD) method, a well
established and well performing method for anomaly detection. Results show that
the effectiveness of each model varies by signal and channel, with DDD proving
to be a very effective anomaly detector. We recommend the combined use of
DeepSVDD and DDD for purely unsupervised applications, with the addition of
flow models for improved performance when resources allow.
  Findings suggest that network architectures that excel in supervised
contexts, such as the particle transformer with standard model interactions,
also perform well as unsupervised anomaly detectors. We also show that with
these methods, it is likely possible to recognize 4-top quark production as an
anomaly without prior knowledge of the process. We argue that the Large Hadron
Collider community can transform supervised classifiers into anomaly detectors
to uncover potential new physical phenomena in each search.


### Bayesian inverse Navier-Stokes problems: joint flow field reconstruction and parameter learning
**Authors**: Alexandros Kontogiannis, Scott V. Elgersma, Andrew J. Sederman, Matthew P. Juniper

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18464v1](http://arxiv.org/pdf/2406.18464v1)

**Abstract**: We formulate and solve a Bayesian inverse Navier-Stokes (N-S) problem that
assimilates velocimetry data in order to jointly reconstruct a 3D flow field
and learn the unknown N-S parameters, including the boundary position. By
hardwiring a generalised N-S problem, and regularising its unknown parameters
using Gaussian prior distributions, we learn the most likely parameters in a
collapsed search space. The most likely flow field reconstruction is then the
N-S solution that corresponds to the learned parameters. We develop the method
in the variational setting and use a stabilised Nitsche weak form of the N-S
problem that permits the control of all N-S parameters. To regularise the
inferred the geometry, we use a viscous signed distance field (vSDF) as an
auxiliary variable, which is given as the solution of a viscous Eikonal
boundary value problem. We devise an algorithm that solves this inverse
problem, and numerically implement it using an adjoint-consistent stabilised
cut-cell finite element method. We then use this method to reconstruct magnetic
resonance velocimetry (flow-MRI) data of a 3D steady laminar flow through a
physical model of an aortic arch for two different Reynolds numbers and
signal-to-noise ratio (SNR) levels (low/high). We find that the method can
accurately i) reconstruct the low SNR data by filtering out the noise/artefacts
and recovering flow features that are obscured by noise, and ii) reproduce the
high SNR data without overfitting. Although the framework that we develop
applies to 3D steady laminar flows in complex geometries, it readily extends to
time-dependent laminar and Reynolds-averaged turbulent flows, as well as
non-Newtonian (e.g. viscoelastic) fluids.


### Large Knowledge Model: Perspectives and Challenges
**Authors**: Huajun Chen

**Published Date**: 2023-12-05

**Updated Date**: 2024-06-26

**PDF Url**: [2312.02706v2](http://arxiv.org/pdf/2312.02706v2)

**Abstract**: Humankind's understanding of the world is fundamentally linked to our
perception and cognition, with \emph{human languages} serving as one of the
major carriers of \emph{world knowledge}. In this vein, \emph{Large Language
Models} (LLMs) like ChatGPT epitomize the pre-training of extensive,
sequence-based world knowledge into neural networks, facilitating the
processing and manipulation of this knowledge in a parametric space. This
article explores large models through the lens of "knowledge". We initially
investigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in
enhancing LLMs, covering aspects like knowledge-augmented language model,
structure-inducing pre-training, knowledgeable prompts, structured CoT,
knowledge editing, semantic tools for LLM and knowledgeable AI agents.
Subsequently, we examine how LLMs can boost traditional symbolic knowledge
bases, encompassing aspects like using LLM as KG builder and controller,
structured knowledge pretraining, and LLM-enhanced symbolic reasoning.
Considering the intricate nature of human knowledge, we advocate for the
creation of \emph{Large Knowledge Models} (LKM), specifically engineered to
manage diversified spectrum of knowledge structures. This promising undertaking
would entail several key challenges, such as disentangling knowledge base from
language models, cognitive alignment with human knowledge, integration of
perception and cognition, and building large commonsense models for interacting
with physical world, among others. We finally propose a five-"A" principle to
distinguish the concept of LKM.


### Scalable tomography of many-body quantum environments with low temporal entanglement
**Authors**: Ilia A. Luchnikov, Michael Sonner, Dmitry A. Abanin

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18458v1](http://arxiv.org/pdf/2406.18458v1)

**Abstract**: Describing dynamics of a quantum system coupled to a complex many-body
environment is a ubiquitous problem in quantum science. General non-Markovian
environments are characterized by their influence matrix~(IM) -- a multi-time
tensor arising from repeated interactions between the system and environment.
While complexity of the most generic IM grows exponentially with the evolution
time, recent works argued that for many instances of physical many-body
environments, the IM is significantly less complex. This is thanks to area-law
scaling of temporal entanglement, which quantifies the correlations between the
past and the future states of the system. However, efficient classical
algorithms for computing IM are only available for non-interacting environments
or certain interacting 1D environments. Here, we study a learning algorithm for
reconstructing IMs of large many-body environments simulated on a quantum
processor. This hybrid algorithm involves experimentally collecting quantum
measurement results of auxiliary qubits which are repeatedly coupled to the
many-body environment, followed by a classical machine-learning construction of
a matrix-product (MPS) representation of the IM. Using the example of 1D
spin-chain environments, with a classically generated training dataset, we
demonstrate that the algorithm allows scalable reconstruction of IMs for long
evolution times. The reconstructed IM can be used to efficiently model quantum
transport through an impurity, including cases with multiple leads and
time-dependent controls. These results indicate the feasibility of
characterizing long-time dynamics of complex environments using a limited
number of measurements, under the assumption of a moderate temporal
entanglement.


### How to Achieve High Spatial Resolution in Organic Optobioelectronic Devices?
**Authors**: Luca Fabbri, Ludovico Migliaccio, Aleksandra Širvinskytė, Giacomo Rizzi, Luca Bondi, Cristiano Tamarozzi, Stefan A. L. Weber, Beatrice Fraboni, Eric Daniel Glowacki, Tobias Cramer

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18447v1](http://arxiv.org/pdf/2406.18447v1)

**Abstract**: Light activated local stimulation and sensing of biological cells offers
enormous potential for minimally invasive bioelectronic interfaces. Organic
semiconductors are a promising material class to achieve this kind of
transduction due to their optoelectronic properties and biocompatibility. Here
we investigate which material properties are necessary to keep the optical
excitation localized. This is critical to single cell transduction with high
spatial resolution. As a model system we use organic photocapacitors for cell
stimulation made of the small molecule semiconductors H2Pc and PTCDI. We
investigate the spatial broadening of the localized optical excitation with
photovoltage microscopy measurements. Our experimental data combined with
modelling show that resolution losses due to the broadening of the excitation
are directly related to the effective diffusion length of charge carriers
generated at the heterojunction. With additional transient photovoltage
measurements we find that the H2Pc/PTCDI heterojunction offers a small
diffusion length of lambda = 1.5 +/- 0.1 um due to the small mobility of charge
carriers along the heterojunction. Instead covering the heterojunction with a
layer of PEDOT:PSS improves the photocapacitor performance but increases the
carrier diffusion length to lambda = 7.0 +/- 0.3 um due to longer lifetime and
higher carrier mobility. Furthermore, we introduce electrochemical photocurrent
microscopy experiments to demonstrate micrometric resolution with the
pn-junction under realistic aqueous operation conditions. This work offers
valuable insights into the physical mechanisms governing the excitation and
transduction profile and provide design principles for future organic
semiconductor junctions, aiming to achieve high efficiency and high spatial
resolution.


## Diffusion
### Towards diffusion models for large-scale sea-ice modelling
**Authors**: Tobias Sebastian Finn, Charlotte Durand, Alban Farchi, Marc Bocquet, Julien Brajard

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18417v1](http://arxiv.org/pdf/2406.18417v1)

**Abstract**: We make the first steps towards diffusion models for unconditional generation
of multivariate and Arctic-wide sea-ice states. While targeting to reduce the
computational costs by diffusion in latent space, latent diffusion models also
offer the possibility to integrate physical knowledge into the generation
process. We tailor latent diffusion models to sea-ice physics with a censored
Gaussian distribution in data space to generate data that follows the physical
bounds of the modelled variables. Our latent diffusion models reach similar
scores as the diffusion model trained in data space, but they smooth the
generated fields as caused by the latent mapping. While enforcing physical
bounds cannot reduce the smoothing, it improves the representation of the
marginal ice zone. Therefore, for large-scale Earth system modelling, latent
diffusion models can have many advantages compared to diffusion in data space
if the significant barrier of smoothing can be resolved.


### Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process
**Authors**: Tianyu Lin, Zhiguang Chen, Zhonghao Yan, Fudan Zheng, Weijiang Yu

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18361v1](http://arxiv.org/pdf/2406.18361v1)

**Abstract**: Diffusion models have demonstrated their effectiveness across various
generative tasks. However, when applied to medical image segmentation, these
models encounter several challenges, including significant resource and time
requirements. They also necessitate a multi-step reverse process and multiple
samples to produce reliable predictions. To address these challenges, we
introduce the first latent diffusion segmentation model, named SDSeg, built
upon stable diffusion (SD). SDSeg incorporates a straightforward latent
estimation strategy to facilitate a single-step reverse process and utilizes
latent fusion concatenation to remove the necessity for multiple samples.
Extensive experiments indicate that SDSeg surpasses existing state-of-the-art
methods on five benchmark datasets featuring diverse imaging modalities.
Remarkably, SDSeg is capable of generating stable predictions with a solitary
reverse step and sample, epitomizing the model's stability as implied by its
name. The code is available at
https://github.com/lin-tianyu/Stable-Diffusion-Seg


### Molecular Diffusion Models with Virtual Receptors
**Authors**: Matan Halfon, Eyal Rozenberg, Ehud Rivlin, Daniel Freedman

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18330v1](http://arxiv.org/pdf/2406.18330v1)

**Abstract**: Machine learning approaches to Structure-Based Drug Design (SBDD) have proven
quite fertile over the last few years. In particular, diffusion-based
approaches to SBDD have shown great promise. We present a technique which
expands on this diffusion approach in two crucial ways. First, we address the
size disparity between the drug molecule and the target/receptor, which makes
learning more challenging and inference slower. We do so through the notion of
a Virtual Receptor, which is a compressed version of the receptor; it is
learned so as to preserve key aspects of the structural information of the
original receptor, while respecting the relevant group equivariance. Second, we
incorporate a protein language embedding used originally in the context of
protein folding. We experimentally demonstrate the contributions of both the
virtual receptors and the protein embeddings: in practice, they lead to both
better performance, as well as significantly faster computations.


### Generative artificial intelligence in ophthalmology: multimodal retinal images for the diagnosis of Alzheimer's disease with convolutional neural networks
**Authors**: I. R. Slootweg, M. Thach, K. R. Curro-Tafili, F. D. Verbraak, F. H. Bouwman, Y. A. L. Pijnenburg, J. F. Boer, J. H. P. de Kwisthout, L. Bagheriye, P. J. González

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18247v1](http://arxiv.org/pdf/2406.18247v1)

**Abstract**: Background/Aim. This study aims to predict Amyloid Positron Emission
Tomography (AmyloidPET) status with multimodal retinal imaging and
convolutional neural networks (CNNs) and to improve the performance through
pretraining with synthetic data. Methods. Fundus autofluorescence, optical
coherence tomography (OCT), and OCT angiography images from 328 eyes of 59
AmyloidPET positive subjects and 108 AmyloidPET negative subjects were used for
classification. Denoising Diffusion Probabilistic Models (DDPMs) were trained
to generate synthetic images and unimodal CNNs were pretrained on synthetic
data and finetuned on real data or trained solely on real data. Multimodal
classifiers were developed to combine predictions of the four unimodal CNNs
with patient metadata. Class activation maps of the unimodal classifiers
provided insight into the network's attention to inputs. Results. DDPMs
generated diverse, realistic images without memorization. Pretraining unimodal
CNNs with synthetic data improved AUPR at most from 0.350 to 0.579. Integration
of metadata in multimodal CNNs improved AUPR from 0.486 to 0.634, which was the
best overall best classifier. Class activation maps highlighted relevant
retinal regions which correlated with AD. Conclusion. Our method for generating
and leveraging synthetic data has the potential to improve AmyloidPET
prediction from multimodal retinal imaging. A DDPM can generate realistic and
unique multimodal synthetic retinal images. Our best performing unimodal and
multimodal classifiers were not pretrained on synthetic data, however
pretraining with synthetic data slightly improved classification performance
for two out of the four modalities.


### Galaxy spectroscopy without spectra: Galaxy properties from photometric images with conditional diffusion models
**Authors**: Lars Doorenbos, Eva Sextl, Kevin Heng, Stefano Cavuoti, Massimo Brescia, Olena Torbaniuk, Giuseppe Longo, Raphael Sznitman, Pablo Márquez-Neila

**Published Date**: 2024-06-26

**Updated Date**: 2024-06-26

**PDF Url**: [2406.18175v1](http://arxiv.org/pdf/2406.18175v1)

**Abstract**: Modern spectroscopic surveys can only target a small fraction of the vast
amount of photometrically cataloged sources in wide-field surveys. Here, we
report the development of a generative AI method capable of predicting optical
galaxy spectra from photometric broad-band images alone. This method draws from
the latest advances in diffusion models in combination with contrastive
networks. We pass multi-band galaxy images into the architecture to obtain
optical spectra. From these, robust values for galaxy properties can be derived
with any methods in the spectroscopic toolbox, such as standard population
synthesis techniques and Lick indices. When trained and tested on 64x64-pixel
images from the Sloan Digital Sky Survey, the global bimodality of star-forming
and quiescent galaxies in photometric space is recovered, as well as a
mass-metallicity relation of star-forming galaxies. The comparison between the
observed and the artificially created spectra shows good agreement in overall
metallicity, age, Dn4000, stellar velocity dispersion, and E(B-V) values.
Photometric redshift estimates of our generative algorithm can compete with
other current, specialized deep-learning techniques. Moreover, this work is the
first attempt in the literature to infer velocity dispersion from photometric
images. Additionally, we can predict the presence of an active galactic nucleus
up to an accuracy of 82%. With our method, scientifically interesting galaxy
properties, normally requiring spectroscopic inputs, can be obtained in future
data sets from large-scale photometric surveys alone. The spectra prediction
via AI can further assist in creating realistic mock catalogs.


