# Abstracts of Papers

## Physics
### Quantum and Classical Dynamics with Random Permutation Circuits
**Authors**: Bruno Bertini, Katja Klobas, Pavel Kos, Daniel Malz

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11960v1](http://arxiv.org/pdf/2407.11960v1)

**Abstract**: Understanding thermalisation in quantum many-body systems is among the most
enduring problems in modern physics. A particularly interesting question
concerns the role played by quantum mechanics in this process, i.e. whether
thermalisation in quantum many-body systems is fundamentally different from
that in classical many-body systems and, if so, which of its features are
genuinely quantum. Here we study this question in minimally structured
many-body systems which are only constrained to have local interactions, i.e.
local random circuits. We introduce a class of random permutation circuits
(RPCs), where the gates locally permute basis states modelling generic
microscopic classical dynamics, and compare them to random unitary circuits
(RUCs), a standard toy model for generic quantum dynamics. We show that, like
RUCs, RPCs permit the analytical computation of several key quantities such as
out-of-time order correlators (OTOCs), or entanglement entropies. RPCs can be
interpreted both as quantum or classical dynamics, which we use to find
similarities and differences between the two. Performing the average over all
random circuits, we discover a series of exact relations, connecting quantities
in RUC and (quantum) RPCs. In the classical setting, we obtain similar exact
results relating (quantum) purity to (classical) growth of mutual information
and (quantum) OTOCs to (classical) decorrelators. Our results indicate that
despite of the fundamental differences between quantum and classical systems,
their dynamics exhibits qualitatively similar behaviours.


### On the statistical theory of self-gravitating collisionless dark matter flow: high order kinematic and dynamic relations
**Authors**: Zhijie Xu

**Published Date**: 2022-02-07

**Updated Date**: 2024-07-16

**PDF Url**: [2202.02991v3](http://arxiv.org/pdf/2202.02991v3)

**Abstract**: To better understand the collisionless dark matter flow on different scales,
statistical theory involving kinematic and dynamic relations must be developed
for different types of flow, e.g. incompressible, constant divergence, and
irrotational flow. This paper extends our previous work on the second-order
statistics (Phys. Fluids 35, 077105) to high order statistics. Kinematic and
dynamic relations were developed for dark matter flow on different scales. The
results were validated by N-body simulations. On large scales, we found i)
third-order velocity correlations can be related to density correlation or
pairwise velocity; ii) the $p$th-order velocity correlations follow $\propto
a^{(p+2)/2}$ for odd $p$ and $\propto a^{p/2}$ for even $p$, where $a$ is the
scale factor; iii) the overdensity $\delta$ is proportional to density
correlation on the same scale; iv) velocity dispersion on a given scale $r$ is
proportional to the overdensity on the same scale. On small scales, i) a
self-closed velocity evolution is developed by decomposing the velocity into
motion in haloes and motion of haloes; ii) the evolution of vorticity and
enstrophy are derived from the evolution of velocity; iii) dynamic relations
are derived to relate second- and third-order correlations; iv) while the first
moment of pairwise velocity follows $\langle\Delta u_L\rangle=-Har$ ($H$ is the
Hubble parameter), the third moment follows $\langle(\Delta
u_L)^3\rangle\propto\varepsilon_uar$ that can be directly compared with
simulations and observations, where $\varepsilon_u\approx10^{-7}$m$^2$/s$^3$ is
the constant rate for energy cascade; v) the $p$th order velocity correlations
follow $\propto a^{(3p-5)/4}$ for odd $p$ and $\propto a^{3p/4}$ for even $p$.
Finally, the combined kinematic and dynamic relations lead to exponential and
one-fourth power-law velocity correlations on large and small scales,
respectively.


### Stable infinite-temperature eigenstates in SU(2)-symmetric nonintegrable models
**Authors**: Christopher J. Turner, Marcin Szyniszewski, Bhaskar Mukherjee, Ronald Melendrez, Hitesh J. Changlani, Arijeet Pal

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11956v1](http://arxiv.org/pdf/2407.11956v1)

**Abstract**: Nonintegrable many-body quantum systems typically thermalize at long times
through the mechanism of quantum chaos. However, some exceptional systems, such
as those harboring quantum scars, break thermalization, serving as testbeds for
foundational problems of quantum statistical physics. Here, we investigate a
class of nonintegrable bond-staggered models that is endowed with a large
number of zero-energy eigenstates and possesses a non-Abelian internal
symmetry. We use character theory to give a lower bound on the zero-energy
degeneracy, which matches exact diagonalization results, and is found to grow
exponentially with the system size. We also show that few-magnon zero-energy
states have an exact analytical description, allowing us to build a basis of
low-entangled fixed-separation states, which is stable to most perturbations
found in experiments. This remarkable dynamical stability of special states
elucidates our understanding of nonequilibrium processes in non-Abelian chaotic
quantum models.


### Minimally Entangled Typical Thermal States for Classical and Quantum Simulation of Gauge Theories at Finite Temperature and Density
**Authors**: I-Chi Chen, João C. Getelina, Klée Pollock, Srimoyee Sen, Yong-Xin Yao, Thomas Iadecola

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11949v1](http://arxiv.org/pdf/2407.11949v1)

**Abstract**: Simulating strongly coupled gauge theories at finite temperature and density
is a longstanding challenge in nuclear and high-energy physics that also has
fundamental implications for condensed matter physics. In this work, we
investigate the utility of minimally entangled typical thermal state (METTS)
approaches to facilitate both classical and quantum computational studies of
such systems. METTS techniques combine classical random sampling with imaginary
time evolution, which can be performed on either a classical or a quantum
computer, to estimate thermal averages of observables. We study the simplest
model of a confining gauge theory, namely $\mathbb{Z}_2$ gauge theory coupled
to spinless fermionic matter in 1+1 dimensions, which can be directly mapped to
a local quantum spin chain with two- and three-body interactions. We benchmark
both a classical matrix-product-state implementation of METTS and a recently
proposed adaptive variational approach to METTS that is a promising candidate
for implementation on near-term quantum devices, focusing on the equation of
state as well as on various measures of fermion confinement. Of particular
importance is the choice of basis for obtaining new METTS samples, which
impacts both the classical sampling complexity (a key factor in both classical
and quantum simulation applications) and complexity of circuits used in the
quantum computing approach. Our work sets the stage for future studies of
strongly coupled gauge theories with both classical and quantum hardware.


### Model for bubble nucleation efficiency of low-energy nuclear recoils in bubble chambers for dark matter detection
**Authors**: Xiang Li, Marie-Cécile Piro

**Published Date**: 2024-01-28

**Updated Date**: 2024-07-16

**PDF Url**: [2401.15531v2](http://arxiv.org/pdf/2401.15531v2)

**Abstract**: Bubble chambers are promising technologies for detecting low-energy nuclear
recoils from the elastic scattering of dark matter particle candidates. Bubble
nucleation occurs when the energy deposition exceeds a specific threshold
defined traditionally by the "heat-spike" Seitz threshold. In this paper, we
report on a physical model that can account for observed discrepancies between
the current Seitz model and the measured nucleation efficiency of low-energy
nuclear recoils, which is necessary for interpreting dark matter signals. In
our work, we combine molecular dynamics and Monte Carlo simulations together
with the Lindhard model to predict bubble nucleation efficiency and energy
thresholds for C$_3$F$_8$, CF$_3$I, and xenon with enhanced accuracy over the
Seitz model when compared to existing experimental data. We use our model to
determine the effect on cross-section limits for spin-dependent and
spin-independent interactions and compare it to the current PICO dark matter
experiment. Our technique can also be applied to estimate the efficiency of
future target fluids where no experimental data are available. As an example,
we predict the nucleation efficiency, the energy threshold and the
cross-section limits in the spin-independent channel for the Scintillating
Bubble Chamber experiment filled with superheated liquid argon.


### Backpropagation through space, time, and the brain
**Authors**: Benjamin Ellenberger, Paul Haider, Jakob Jordan, Kevin Max, Ismael Jaras, Laura Kriener, Federico Benitez, Mihai A. Petrovici

**Published Date**: 2024-03-25

**Updated Date**: 2024-07-16

**PDF Url**: [2403.16933v2](http://arxiv.org/pdf/2403.16933v2)

**Abstract**: How physical networks of neurons, bound by spatio-temporal locality
constraints, can perform efficient credit assignment, remains, to a large
extent, an open question. In machine learning, the answer is almost universally
given by the error backpropagation algorithm, through both space and time.
However, this algorithm is well-known to rely on biologically implausible
assumptions, in particular with respect to spatio-temporal (non-)locality.
Alternative forward-propagation models such as real-time recurrent learning
only partially solve the locality problem, but only at the cost of scaling, due
to prohibitive storage requirements.
  We introduce Generalized Latent Equilibrium (GLE), a computational framework
for fully local spatio-temporal credit assignment in physical, dynamical
networks of neurons. We start by defining an energy based on neuron-local
mismatches, from which we derive both neuronal dynamics via stationarity and
parameter dynamics via gradient descent. The resulting dynamics can be
interpreted as a real-time, biologically plausible approximation of
backpropagation through space and time in deep cortical networks with
continuous-time neuronal dynamics and continuously active, local synaptic
plasticity. In particular, GLE exploits the morphology of dendritic trees to
enable more complex information storage and processing in single neurons, as
well as the ability of biological neurons to phase-shift their output rate with
respect to their membrane potential, which is essential in both directions of
information propagation. For the forward computation, it enables the mapping of
time-continuous inputs to neuronal space, effectively performing a
spatio-temporal convolution. For the backward computation, it permits the
temporal inversion of feedback signals, which consequently approximate the
adjoint variables necessary for useful parameter updates.


### Calibration and simulation of ionization signal and electronics noise in the ICARUS liquid argon time projection chamber
**Authors**: ICARUS collaboration, P. Abratenko, N. Abrego-Martinez, A. Aduszkiewicz, F. Akbar, L. Aliaga Soplin, M. Artero Pons, J. Asaadi, W. F. Badgett, B. Baibussinov, B. Behera, V. Bellini, R. Benocci, S. Berkman, S. Bertolucci, M. Betancourt, M. Bonesini, T. Boone, B. Bottino, A. Braggiotti, D. Brailsford, S. J. Brice, V. Brio, C. Brizzolari, H. S. Budd A. Campani, A. Campos, D. Carber, M. Carneiro, I. Caro Terrazas, H. Carranza, F. Castillo Fernandez, A. Castro, S. Centro, G. Cerati, A. Chatterjee, D. Cherdack, S. Cherubini, N. Chitirasreemadam, M. Cicerchia, T. Coan, A. Cocco, M. R. Convery, L. Cooper-Troendle, S. Copello, A. A. Dange, A. De Roeck, L. Di Noto, C. Di Stefano, D. DiFerdinando, M. Diwan, S. Dolan, L. Domine, S. Donati, F. Drielsma, J. Dyer, S. Dytman, A. Falcone, C. Farnese, A. Fava, A. Ferrari, N. Gallice, F. G. Garcia, C. Gatto, D. Gibin, A. Gioiosa, W. Gu, A. Guglielmi, G. Gurung, H. Hausner, A. Heggestuen, B. Howard, R. Howell, I. Ingratta, C. James, W. Jang, Y. -J. Jwa, L. Kashur, W. Ketchum, J. S. Kim, D. -H. Koh, J. Larkin, Y. Li, C. Mariani, C. M. Marshall, S. Martynenko, N. Mauri, K. S. McFarland, D. P. Méndez1 A. Menegolli, G. Meng, O. G. Miranda, A. Mogan, N. Moggi, E. Montagna, C. Montanari, A. Montanari, M. Mooney, G. Moreno-Granados, J. Mueller, M. Murphy, D. Naples, V. C. L. Nguyen, S. Palestini, M. Pallavicini, V. Paolone, R. Papaleo, L. Pasqualini, L. Patrizii, L. Paudel, G. Petrillo, C. Petta, V. Pia, F. Pietropaolo, F. Poppi, M. Pozzato, G. Putnam, X. Qian, A. Rappoldi, G. L. Raselli, S. Repetto, F. Resnati, A. M. Ricci, G. Riccobene, E. Richards, M. Rosenberg, M. Rossella, P. Roy, C. Rubbia, M. Saad, S. Saha, P. Sala, S. Samanta, P. Sapienza, A. Scaramelli, A. Scarpelli, D. Schmitz, A. Schukraft, D. Senadheera, S-H. Seo, F. Sergiampietri, G. Sirri, J. S. Smedley, J. Smith, L. Stanco, J. Stewart, H. A. Tanaka, F. Tapia, M. Tenti, K. Terao, F. Terranova, V. Togo, D. Torretta, M. Torti, F. Tortorici, R. Triozzi, Y. -T. Tsai, S. Tufanli, T. Usher, F. Varanini, S. Ventura, M. Vicenzi, C. Vignoli, B. Viren, Z. Williams, R. J. Wilson, P. Wilson, J. Wolfs, T. Wongjirad, A. Wood, E. Worcester, M. Worcester, M. Wospakrik, H. Yu, J. Yu, A. Zani, J. Zennamo, J. C. Zettlemoyer, C. Zhang, S. Zucchelli

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11925v1](http://arxiv.org/pdf/2407.11925v1)

**Abstract**: The ICARUS liquid argon time projection chamber (LArTPC) neutrino detector
has been taking physics data since 2022 as part of the Short-Baseline Neutrino
(SBN) Program. This paper details the equalization of the response to charge in
the ICARUS time projection chamber (TPC), as well as data-driven tuning of the
simulation of ionization charge signals and electronics noise. The equalization
procedure removes non-uniformities in the ICARUS TPC response to charge in
space and time. This work leverages the copious number of cosmic ray muons
available to ICARUS at the surface. The ionization signal shape simulation
applies a novel procedure that tunes the simulation to match what is measured
in data. The end result of the equalization procedure and simulation tuning
allows for a comparison of charge measurements in ICARUS between Monte Carlo
simulation and data, showing good performance with minimal residual bias
between the two.


### Importance of accounting for student identities and intersectionality for creating equitable and inclusive physics learning environments
**Authors**: Lisabeth Marie Santana, Chandralekha Singh

**Published Date**: 2024-03-20

**Updated Date**: 2024-07-16

**PDF Url**: [2403.13621v2](http://arxiv.org/pdf/2403.13621v2)

**Abstract**: This research focuses on the experiences of seven undergraduate women who
were majoring in physics in a medium-size physics department at a small liberal
arts college. In the semi-structured, empathetic interviews we conducted, the
women discussed how they decided to major in physics, their interactions with
their peers and instructors, who supported them during their physics
trajectory, and suggestions that would improve their experiences in physics. We
used Standpoint theory and focused on the experiences of undergraduate women to
get a holistic perspective of how they became interested in physics, how they
have been supported in their physics journey as well as identify any challenges
that they faced in their undergraduate physics program due to their identity.
Using synergistic frameworks such as the Domains of Power and the Holistic
Ecosystem for Learning Physics in an Inclusive and Equitable Environment
(HELPIEE), we analyzed how those in the position of power, e.g., instructors,
can play important roles in establishing and maintaining safe, equitable, and
inclusive environments for students, which is especially important for
historically marginalized students such as women and ethnic and racial minority
students in physics. We also discuss the suggestions provided by the
undergraduate women to implement in the future to support current and future
undergraduate women in physics and astronomy. Their suggestions are separated
as personal advice for peers and suggestions for physics instructors.


### The CONUS+ experiment
**Authors**: The CONUS+ Collaboration, :, N. Ackermann, S. Armbruster, H. Bonet, C. Buck, K. Fulber, J. Hakenmuller, J. Hempfling, G. Heusser, M. Lindner, W. Maneschg, K. Ni, M. Rank, T. Rink, E. Sanchez Garcia, I. Stalder, H. Strecker, R. Wink, J. Woenckhaus

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11912v1](http://arxiv.org/pdf/2407.11912v1)

**Abstract**: The CONUS+ experiment aims to detect coherent elastic neutrino-nucleus
scattering (CEvNS) of reactor antineutrinos on germanium nuclei in the fully
coherent regime, continuing on this way the CONUS physics program started at
the Brokdorf nuclear power plant, Germany. The CONUS+ setup is installed in the
nuclear power plant in Leibstadt, Switzerland, at a distance of 20.7 m from the
3.6 GW thermal power reactor core. The CEvNS signature will be measured with
the same four point-contact high-purity germanium (HPGe) detectors produced for
the former experiment, however refurbished and with optimized low energy
thresholds. To suppress the background in the CONUS+ detectors, the passive and
active layers of the original CONUS shield were modified such to fit better to
the significantly changed background conditions at the new experimental
location. New data acquisition and monitoring systems were developed. A direct
network connection between the experiment and the Max-Planck-Institut fur
Kernphysik (MPIK) makes it possible to control and monitor data acquisition in
real time. The impact of all these modifications is discussed with particular
emphasis on the resulting CEvNS signal prediction for the first data collection
phase of CONUS+. Prospects of the planned upgrade in a second phase integrating
new larger HPGe detectors are also discussed.


### Cumulative Advantage of Brokerage in Academia
**Authors**: Jan Bachmann, Lisette Espín-Noboa, Gerardo Iñiguez, Fariba Karimi

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11909v1](http://arxiv.org/pdf/2407.11909v1)

**Abstract**: Science is a collaborative endeavor in which "who collaborates with whom"
profoundly influences scientists' career trajectories and success. Despite its
relevance, little is known about how scholars facilitate new collaborations
among their peers. In this study, we quantify brokerage in academia and study
its effect on the careers of physicists worldwide. We find that early-career
participation in brokerage increases later-stage involvement for all
researchers, with increasing participation rates and greater career impact
among more successful scientists. This cumulative advantage process suggests
that brokerage contributes to the unequal distribution of success in academia.
Surprisingly, this affects both women and men equally, despite women being more
junior in all brokerage roles and lagging behind men's participation due to
their late and slow arrival to physics. Because of its cumulative nature,
promoting brokerage opportunities to early career scientists might help reduce
the inequalities in academic success.


## Diffusion
### Efficient Training with Denoised Neural Weights
**Authors**: Yifan Gong, Zheng Zhan, Yanyu Li, Yerlan Idelbayev, Andrey Zharkov, Kfir Aberman, Sergey Tulyakov, Yanzhi Wang, Jian Ren

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11966v1](http://arxiv.org/pdf/2407.11966v1)

**Abstract**: Good weight initialization serves as an effective measure to reduce the
training cost of a deep neural network (DNN) model. The choice of how to
initialize parameters is challenging and may require manual tuning, which can
be time-consuming and prone to human error. To overcome such limitations, this
work takes a novel step towards building a weight generator to synthesize the
neural weights for initialization. We use the image-to-image translation task
with generative adversarial networks (GANs) as an example due to the ease of
collecting model weights spanning a wide range. Specifically, we first collect
a dataset with various image editing concepts and their corresponding trained
weights, which are later used for the training of the weight generator. To
address the different characteristics among layers and the substantial number
of weights to be predicted, we divide the weights into equal-sized blocks and
assign each block an index. Subsequently, a diffusion model is trained with
such a dataset using both text conditions of the concept and the block indexes.
By initializing the image translation model with the denoised weights predicted
by our diffusion model, the training requires only 43.3 seconds. Compared to
training from scratch (i.e., Pix2pix), we achieve a 15x training time
acceleration for a new concept while obtaining even better image generation
quality.


### Context-Guided Diffusion for Out-of-Distribution Molecular and Protein Design
**Authors**: Leo Klarner, Tim G. J. Rudner, Garrett M. Morris, Charlotte M. Deane, Yee Whye Teh

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11942v1](http://arxiv.org/pdf/2407.11942v1)

**Abstract**: Generative models have the potential to accelerate key steps in the discovery
of novel molecular therapeutics and materials. Diffusion models have recently
emerged as a powerful approach, excelling at unconditional sample generation
and, with data-driven guidance, conditional generation within their training
domain. Reliably sampling from high-value regions beyond the training data,
however, remains an open challenge -- with current methods predominantly
focusing on modifying the diffusion process itself. In this paper, we develop
context-guided diffusion (CGD), a simple plug-and-play method that leverages
unlabeled data and smoothness constraints to improve the out-of-distribution
generalization of guided diffusion models. We demonstrate that this approach
leads to substantial performance gains across various settings, including
continuous, discrete, and graph-structured diffusion processes with
applications across drug discovery, materials science, and protein design.


### Enhanced Safety in Autonomous Driving: Integrating Latent State Diffusion Model for End-to-End Navigation
**Authors**: Detian Chu, Linyuan Bai, Jianuo Huang, Zhenlong Fang, Peng Zhang, Wei Kang

**Published Date**: 2024-07-08

**Updated Date**: 2024-07-16

**PDF Url**: [2407.06317v3](http://arxiv.org/pdf/2407.06317v3)

**Abstract**: With the advancement of autonomous driving, ensuring safety during motion
planning and navigation is becoming more and more important. However, most
end-to-end planning methods suffer from a lack of safety. This research
addresses the safety issue in the control optimization problem of autonomous
driving, formulated as Constrained Markov Decision Processes (CMDPs). We
propose a novel, model-based approach for policy optimization, utilizing a
conditional Value-at-Risk based Soft Actor Critic to manage constraints in
complex, high-dimensional state spaces effectively. Our method introduces a
worst-case actor to guide safe exploration, ensuring rigorous adherence to
safety requirements even in unpredictable scenarios. The policy optimization
employs the Augmented Lagrangian method and leverages latent diffusion models
to predict and simulate future trajectories. This dual approach not only aids
in navigating environments safely but also refines the policy's performance by
integrating distribution modeling to account for environmental uncertainties.
Empirical evaluations conducted in both simulated and real environment
demonstrate that our approach outperforms existing methods in terms of safety,
efficiency, and decision-making capabilities.


### A Simple Latent Diffusion Approach for Panoptic Segmentation and Mask Inpainting
**Authors**: Wouter Van Gansbeke, Bert De Brabandere

**Published Date**: 2024-01-18

**Updated Date**: 2024-07-16

**PDF Url**: [2401.10227v2](http://arxiv.org/pdf/2401.10227v2)

**Abstract**: Panoptic and instance segmentation networks are often trained with
specialized object detection modules, complex loss functions, and ad-hoc
post-processing steps to manage the permutation-invariance of the instance
masks. This work builds upon Stable Diffusion and proposes a latent diffusion
approach for panoptic segmentation, resulting in a simple architecture that
omits these complexities. Our training consists of two steps: (1) training a
shallow autoencoder to project the segmentation masks to latent space; (2)
training a diffusion model to allow image-conditioned sampling in latent space.
This generative approach unlocks the exploration of mask completion or
inpainting. The experimental validation on COCO and ADE20k yields strong
segmentation results. Finally, we demonstrate our model's adaptability to
multi-tasking by introducing learnable task embeddings.


### Single Layer Single Gradient Unlearning
**Authors**: Zikui Cai, Yaoteng Tan, M. Salman Asif

**Published Date**: 2024-07-16

**Updated Date**: 2024-07-16

**PDF Url**: [2407.11867v1](http://arxiv.org/pdf/2407.11867v1)

**Abstract**: Machine unlearning methods seek to revise pretrained models such that effects
of certain training samples can be removed. In addition to effective erasure,
low computational cost and general utility retention are also highly desirable.
Existing unlearning methods usually involve iterative updates over the model
parameters, which incurs a high computational cost. In this work, we propose an
efficient method that only requires a one-time gradient computation, with which
we modify only a single layer of model parameters. Specifically, we first
identify a small number of model layers that lie on the Pareto front of high
forget importance and low retain influence as critical layers. Then we search
for a suitable step size and take a step along the gradient direction of a
single critical layer while keeping other layers frozen. This method is highly
modular and can be used to unlearn multiple concepts simultaneously in a
controllable manner. We demonstrate the effectiveness and efficiency of this
method on various models including CLIP, stable diffusion, and VLMs, surpassing
other state-of-the-art methods.


## Quantitative Finance
### Hedging Beyond the Mean: A Distributional Reinforcement Learning Perspective for Hedging Portfolios with Structured Products
**Authors**: Anil Sharma, Freeman Chen, Jaesun Noh, Julio DeJesus, Mario Schlener

**Published Date**: 2024-07-15

**Updated Date**: 2024-07-15

**PDF Url**: [2407.10903v1](http://arxiv.org/pdf/2407.10903v1)

**Abstract**: Research in quantitative finance has demonstrated that reinforcement learning
(RL) methods have delivered promising outcomes in the context of hedging
financial portfolios. For example, hedging a portfolio of European options
using RL achieves better $PnL$ distribution than the trading hedging strategies
like Delta neutral and Delta-Gamma neutral [Cao et. al. 2020]. There is great
attention given to the hedging of vanilla options, however, very little is
mentioned on hedging a portfolio of structured products such as Autocallable
notes. Hedging structured products is much more complex and the traditional RL
approaches tend to fail in this context due to the underlying complexity of
these products. These are more complicated due to presence of several barriers
and coupon payments, and having a longer maturity date (from $7$ years to a
decade), etc. In this direction, we propose a distributional RL based method to
hedge a portfolio containing an Autocallable structured note. We will
demonstrate our RL hedging strategy using American and Digital options as
hedging instruments. Through several empirical analysis, we will show that
distributional RL provides better $PnL$ distribution than traditional
approaches and learns a better policy depicting lower value-at-risk ($VaR$) and
conditional value-at-risk ($CVaR$), showcasing the potential for enhanced risk
management.


### Numbers Matter! Bringing Quantity-awareness to Retrieval Systems
**Authors**: Satya Almasian, Milena Bruseva, Michael Gertz

**Published Date**: 2024-07-14

**Updated Date**: 2024-07-14

**PDF Url**: [2407.10283v1](http://arxiv.org/pdf/2407.10283v1)

**Abstract**: Quantitative information plays a crucial role in understanding and
interpreting the content of documents. Many user queries contain quantities and
cannot be resolved without understanding their semantics, e.g., ``car that
costs less than $10k''. Yet, modern search engines apply the same ranking
mechanisms for both words and quantities, overlooking magnitude and unit
information. In this paper, we introduce two quantity-aware ranking techniques
designed to rank both the quantity and textual content either jointly or
independently. These techniques incorporate quantity information in available
retrieval systems and can address queries with numerical conditions equal,
greater than, and less than. To evaluate the effectiveness of our proposed
models, we introduce two novel quantity-aware benchmark datasets in the domains
of finance and medicine and compare our method against various lexical and
neural models. The code and data are available under
https://github.com/satya77/QuantityAwareRankers.


