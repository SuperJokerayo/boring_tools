{
    "Physics": [
        {
            "title": "Neural Approximate Mirror Maps for Constrained Diffusion Models",
            "authors": "Berthy T. Feng, Ricardo Baptista, Katherine L. Bouman",
            "summary": "Diffusion models excel at creating visually-convincing images, but they often\nstruggle to meet subtle constraints inherent in the training data. Such\nconstraints could be physics-based (e.g., satisfying a PDE), geometric (e.g.,\nrespecting symmetry), or semantic (e.g., including a particular number of\nobjects). When the training data all satisfy a certain constraint, enforcing\nthis constraint on a diffusion model not only improves its\ndistribution-matching accuracy but also makes it more reliable for generating\nvalid synthetic data and solving constrained inverse problems. However,\nexisting methods for constrained diffusion models are inflexible with different\ntypes of constraints. Recent work proposed to learn mirror diffusion models\n(MDMs) in an unconstrained space defined by a mirror map and to impose the\nconstraint with an inverse mirror map, but analytical mirror maps are\nchallenging to derive for complex constraints. We propose neural approximate\nmirror maps (NAMMs) for general constraints. Our approach only requires a\ndifferentiable distance function from the constraint set. We learn an\napproximate mirror map that pushes data into an unconstrained space and a\ncorresponding approximate inverse that maps data back to the constraint set. A\ngenerative model, such as an MDM, can then be trained in the learned mirror\nspace and its samples restored to the constraint set by the inverse map. We\nvalidate our approach on a variety of constraints, showing that compared to an\nunconstrained diffusion model, a NAMM-based MDM substantially improves\nconstraint satisfaction. We also demonstrate how existing diffusion-based\ninverse-problem solvers can be easily applied in the learned mirror space to\nsolve constrained inverse problems.",
            "pdf_url": "http://arxiv.org/pdf/2406.12816v1",
            "published": "2024-06-18 17:36:09+00:00",
            "updated": "2024-06-18 17:36:09+00:00"
        },
        {
            "title": "The $g$-function and Defect Changing Operators from Wavefunction Overlap on a Fuzzy Sphere",
            "authors": "Zheng Zhou, Davide Gaiotto, Yin-Chen He, Yijian Zou",
            "summary": "Defects are common in physical systems with boundaries, impurities or\nextensive measurements. The interaction between bulk and defect can lead to\nrich physical phenomena. Defects in gapless phases of matter with conformal\nsymmetry usually flow to a defect conformal field theory (dCFT). Understanding\nthe universal properties of dCFTs is a challenging task. In this paper, we\npropose a computational strategy applicable to a line defect in arbitrary\ndimensions. Our main assumption is that the defect has a UV description in\nterms of a local modification of the Hamiltonian so that we can compute the\noverlap between low-energy eigenstates of a system with or without the defect\ninsertion. We argue that these overlaps contain a wealth of conformal data,\nincluding the $g$-function, which is an RG monotonic quantity that\ndistinguishes different dCFTs, the scaling dimensions of defect creation\noperators $\\Delta^{+0}_\\alpha$ and changing operators $\\Delta^{+-}_\\alpha$ that\nlive on the intersection of different types of line defects, and various OPE\ncoefficients. We apply this method to the fuzzy sphere regularization of 3D\nCFTs and study the magnetic line defect of the 3D Ising CFT. Using exact\ndiagonalization and DMRG, we report the non-perturbative results\n$g=0.602(2),\\Delta^{+0}_0=0.108(5)$ and $\\Delta^{+-}_0=0.84(5)$ for the first\ntime. We also obtain other OPE coefficients and scaling dimensions. Our results\nhave significant physical implications. For example, they constrain the\npossible occurrence of spontaneous symmetry breaking at line defects of the 3D\nIsing CFT. Our method can be potentially applied to various other dCFTs, such\nas plane defects and Wilson lines in gauge theories.",
            "pdf_url": "http://arxiv.org/pdf/2401.00039v3",
            "published": "2023-12-29 19:00:00+00:00",
            "updated": "2024-06-18 16:59:26+00:00"
        },
        {
            "title": "Engineering the Kitaev spin liquid in a quantum dot system",
            "authors": "Tessa Cookmeyer, Sankar Das Sarma",
            "summary": "The Kitaev model on a honeycomb lattice may provide a robust topological\nquantum memory platform, but finding a material that realizes the unique spin\nliquid phase remains a considerable challenge. We demonstrate that an effective\nKitaev Hamiltonian can arise from a half-filled Fermi-Hubbard Hamiltonian where\neach site can experience a magnetic field in a different direction. As such, we\nprovide a method for realizing the Kitaev spin liquid on a single hexagonal\nplaquette made up of twelve quantum dots. Despite the small system size, there\nare clear signatures of the Kitaev spin-liquid ground state, and there is a\nrange of parameters where these signatures are predicted, allowing a potential\nplatform where Kitaev spin-liquid physics can be explored experimentally in\nquantum dot plaquettes.",
            "pdf_url": "http://arxiv.org/pdf/2310.18393v3",
            "published": "2023-10-27 18:00:00+00:00",
            "updated": "2024-06-18 16:54:27+00:00"
        },
        {
            "title": "Latent Intuitive Physics: Learning to Transfer Hidden Physics from A 3D Video",
            "authors": "Xiangming Zhu, Huayu Deng, Haochen Yuan, Yunbo Wang, Xiaokang Yang",
            "summary": "We introduce latent intuitive physics, a transfer learning framework for\nphysics simulation that can infer hidden properties of fluids from a single 3D\nvideo and simulate the observed fluid in novel scenes. Our key insight is to\nuse latent features drawn from a learnable prior distribution conditioned on\nthe underlying particle states to capture the invisible and complex physical\nproperties. To achieve this, we train a parametrized prior learner given visual\nobservations to approximate the visual posterior of inverse graphics, and both\nthe particle states and the visual posterior are obtained from a learned neural\nrenderer. The converged prior learner is embedded in our probabilistic physics\nengine, allowing us to perform novel simulations on unseen geometries,\nboundaries, and dynamics without knowledge of the true physical parameters. We\nvalidate our model in three ways: (i) novel scene simulation with the learned\nvisual-world physics, (ii) future prediction of the observed fluid dynamics,\nand (iii) supervised particle simulation. Our model demonstrates strong\nperformance in all three tasks.",
            "pdf_url": "http://arxiv.org/pdf/2406.12769v1",
            "published": "2024-06-18 16:37:44+00:00",
            "updated": "2024-06-18 16:37:44+00:00"
        },
        {
            "title": "A hybrid reduced-order model for segregated fluid-structure interaction solvers in an ALE approach at high Reynolds number",
            "authors": "Valentin Nkana Ngan, Giovanni Stabile, Andrea Mola, Gianluigi Rozza",
            "summary": "This study introduces a first step for constructing a hybrid reduced-order\nmodels (ROMs) for segregated fluid-structure interaction in an Arbitrary\nLagrangian-Eulerian (ALE) approach at a high Reynolds number using the Finite\nVolume Method (FVM). The ROM is driven by proper orthogonal decomposition (POD)\nwith hybrid techniques that combines the classical Galerkin projection and two\ndata-driven methods (radial basis networks , and neural networks/ long short\nterm memory). Results demonstrate the ROM ability to accurately capture the\nphysics of fluid-structure interaction phenomena. This approach is validated\nthrough a case study focusing on flow-induced vibration (FIV) of a pitch-plunge\nairfoil at a high Reynolds number 10000000.",
            "pdf_url": "http://arxiv.org/pdf/2406.12701v1",
            "published": "2024-06-18 15:14:28+00:00",
            "updated": "2024-06-18 15:14:28+00:00"
        },
        {
            "title": "Exponential Error Reduction for Glueball Calculations Using a Two-Level Algorithm in Pure Gauge Theory",
            "authors": "Lorenzo Barca, Francesco Knechtli, Sofie Martins, Michael Peardon, Stefan Schaefer, Juan Andr\u00e9s Urrea-Ni\u00f1o",
            "summary": "This study explores the application of a two-level algorithm to enhance the\nsignal-to-noise ratio of glueball calculations in four-dimensional\n$\\mathrm{SU(3)}$ pure gauge theory. Our findings demonstrate that the\nstatistical errors exhibit an exponential reduction, enabling reliable\nextraction of effective masses at distances where current standard methods\nwould demand exponentially more samples. However, at shorter distances,\nstandard methods prove more efficient due to a saturation of the variance\nreduction using the multi-level method. We discuss the physical distance at\nwhich the multi-level sampling is expected to outperform the standard\nalgorithm, supported by numerical evidence across different lattice spacings\nand glueball channels. Additionally, we construct a variational basis\ncomprising 35 Wilson loops up to length 12 and 5 smearing sizes each,\npresenting results for the first state in the spectrum for the scalar,\npseudoscalar, and tensor channels.",
            "pdf_url": "http://arxiv.org/pdf/2406.12656v1",
            "published": "2024-06-18 14:25:41+00:00",
            "updated": "2024-06-18 14:25:41+00:00"
        },
        {
            "title": "Noncompletely Positive Quantum Maps Enable Efficient Local Energy Extraction in Batteries",
            "authors": "Aparajita Bhattacharyya, Kornikar Sen, Ujjwal Sen",
            "summary": "Energy extraction from quantum batteries by means of completely positive\ntrace-preserving (CPTP) maps leads to the concept of CPTP-local passive states,\nwhich identify bipartite states from which no energy can be squeezed out by\napplying any CPTP map to a particular subsystem. We prove, for arbitrary\ndimension, that if a state is CPTP-local passive with respect to a Hamiltonian,\nthen an arbitrary number of copies of the same state - including an\nasymptotically large one - is also CPTP-local passive. We show further that\nenergy can be extracted efficiently from CPTP-local passive states employing\nNCPTP but still physically realizable maps on the same part of the shared\nbattery on which operation of CPTP maps were useless. Moreover, we provide the\nmaximum extractable energy using local-CPTP operations, and then, we present an\nexplicit class of states and corresponding Hamiltonians, for which the maximum\ncan be outperformed using physical local NCPTP maps. We provide a necessary and\nsufficient condition and a separate necessary condition for an arbitrary\nbipartite state to be unable to supply any energy using non-completely positive\ntrace-preserving (NCPTP) operations on one party with respect to an arbitrary\nbut fixed Hamiltonian. We build an analogy between the relative status of CPTP\nand NCPTP operations for energy extraction in quantum batteries, and the\nassociation of distillable entanglement with entanglement cost for asymptotic\nlocal manipulations of entanglement. The surpassing of the maximum energy\nextractable by NCPTP maps for CPTP-passive as well as for CPTP non-passive\nbattery states can act as detectors of non-CPTPness of quantum maps.",
            "pdf_url": "http://arxiv.org/pdf/2307.16746v4",
            "published": "2023-07-31 15:08:05+00:00",
            "updated": "2024-06-18 13:57:57+00:00"
        },
        {
            "title": "Photoproduction of J/$\u03c8$ and dileptons in Pb-Pb collisions with nuclear overlap",
            "authors": "Nicolas Biz\u00e9",
            "summary": "Photon-photon reactions and the production of J/$\\psi$ meson through\nphotonuclear reactions have been extensively studied in ultra-peripheral\nheavy-ion collisions, in which the impact parameter is larger than twice the\nnuclear radius. In recent years, coherently photoproduced J/$\\psi$ and dilepton\nproduction via photon-photon interactions have also been observed in\nnucleus-nucleus (A-A) collisions with nuclear overlap. The former can help to\nconstrain the nuclear gluon distributions at low Bjorken-$x$ and high energy,\nwhile the latter could be used to further map the electromagnetic fields\nproduced in heavy-ion collisions. In addition, these measurements can shed\nlight on the theory behind photon-induced reactions in A-A collisions with\nnuclear overlap, including possible interactions of the measured probes with\nthe formed and fast expanding quark-gluon plasma. Since the produced quarkonium\nis expected to keep the polarization of the incoming photon due to $s$-channel\nhelicity conservation, the photoproduction origin of the J/$\\psi$ yield excess\nat very low transverse momentum, $p_{\\rm T}$, can be confirmed by the\nmeasurement of the J/$\\psi$ polarization. The ALICE detector can perform\nquarkonium production measurements at both mid ($|y|<0.9$) and forward\n($2.5<y<4$) rapidities down to $p_{\\rm T} = 0$. In the following, the new ALICE\nmeasurements of the J/$\\psi$ $y$-differential cross section and the first\npolarization results of coherently photoproduced J/$\\psi$ via the dimuon decay\nchannel at forward rapidity in Pb-Pb collisions at $\\sqrt{s_{NN}}=$ 5.02 TeV\nare reported. Additionally, the measurement of an excess with respect to\nexpectations from hadronic production in the dielectron yield, at low mass and\n$p_{\\rm T}$, at midrapidity in Pb-Pb collisions at $\\sqrt{s_{NN}}=$ 5.02~TeV,\nis presented. The results are compared with available theoretical models.",
            "pdf_url": "http://arxiv.org/pdf/2406.12630v1",
            "published": "2024-06-18 13:56:42+00:00",
            "updated": "2024-06-18 13:56:42+00:00"
        },
        {
            "title": "Nonresonant central exclusive production of charged-hadron pairs in proton-proton collisions at $\\sqrt{s}$ = 13 TeV",
            "authors": "CMS, TOTEM Collaborations",
            "summary": "The central exclusive production of charged-hadron pairs in pp collisions at\na centre-of-mass energy of 13 TeV is examined, based on data collected in a\nspecial high-$\\beta^*$ run of the LHC. The nonresonant continuum processes are\nstudied with the invariant mass of the centrally produced two-pion system in\nthe resonance-free region, $m_{\\pi^+\\pi^-}$ $\\lt$ 0.7 GeV or $m_{\\pi^+\\pi^-}$\n$\\gt$ 1.8 GeV. Differential cross sections as functions of the azimuthal angle\nbetween the surviving protons, squared exchanged four-momenta, and\n$m_{\\pi^+\\pi^-}$ are measured in a wide region of scattered proton transverse\nmomenta, between 0.2 and 0.8 GeV, and for pion rapidities $\\lvert y\\rvert$\n$\\lt$ 2. A rich structure of interactions related to double-pomeron exchange is\nobserved. A parabolic minimum in the distribution of the two-proton azimuthal\nangle is observed for the first time. It can be interpreted as an effect of\nadditional pomeron exchanges between the protons from the interference between\nthe bare and the rescattered amplitudes. After model tuning, various physical\nquantities are determined that are related to the pomeron cross section,\nproton-pomeron and meson-pomeron form factors, pomeron trajectory and\nintercept, and coefficients of diffractive eigenstates of the proton.",
            "pdf_url": "http://arxiv.org/pdf/2401.14494v2",
            "published": "2024-01-25 20:13:39+00:00",
            "updated": "2024-06-18 13:53:28+00:00"
        },
        {
            "title": "Second gadolinium loading to Super-Kamiokande",
            "authors": "K. Abe, C. Bronner, Y. Hayato, K. Hiraide, K. Hosokawa, K. Ieki, M. Ikeda, J. Kameda, Y. Kanemura, R. Kaneshima, Y. Kashiwagi, Y. Kataoka, S. Miki, S. Mine, M. Miura, S. Moriyama, Y. Nakano, M. Nakahata, S. Nakayama, Y. Noguchi, K. Sato, H. Sekiya, H. Shiba, K. Shimizu, M. Shiozawa, Y. Sonoda, Y. Suzuki, A. Takeda, Y. Takemoto, H. Tanaka, T. Yano, S. Han, T. Kajita, K. Okumura, T. Tashiro, T. Tomiya, X. Wang, S. Yoshida, P. Fernandez, L. Labarga, N. Ospina, B. Zaldivar, B. W. Pointon, E. Kearns, J. L. Raaf, L. Wan, T. Wester, J. Bian, N. J. Griskevich, M. B. Smy, H. W. Sobel, V. Takhistov, A. Yankelevich, J. Hill, M. C. Jang, S. H. Lee, D. H. Moon, R. G. Park, B. Bodur, K. Scholberg, C. W. Walter, A. Beauchene, O. Drapier, A. Giampaolo, Th. A. Mueller, A. D. Santos, P. Paganini, B. Quilain, R. Rogly, T. Nakamura, J. S. Jang, L. N. Machado, J. G. Learned, K. Choi, N. Iovine, S. Cao, L. H. V. Anthony, D. Martin, N. W. Prouse, M. Scott, Y. Uchida, V. Berardi, N. F. Calabria, M. G. Catanesi, E. Radicioni, A. Langella, G. De Rosa, G. Collazuol, F. Iacob, M. Mattiazzi, L. Ludovici, M. Gonin, L. Perisse, G. Pronost, C. Fujisawa, Y. Maekawa, Y. Nishimura, R. Okazaki, R. Akutsu, M. Friend, T. Hasegawa, T. Ishida, T. Kobayashi, M. Jakkapu, T. Matsubara, T. Nakadaira, K. Nakamura, Y. Oyama, K. Sakashita, T. Sekiguchi, T. Tsukamoto, N. Bhuiyan, G. T. Burton, F. Di Lodovico, J. Gao, A. Goldsack, T. Katori, J. Migenda, R. M. Ramsden, Z. Xie, S. Zsoldos, A. T. Suzuki, Y. Takagi, Y. Takeuchi, H. Zhong, J. Feng, L. Feng, J. R. Hu, Z. Hu, M. Kawaue, T. Kikawa, M. Mori, T. Nakaya, R. A. Wendell, K. Yasutome, S. J. Jenkins, N. McCauley, P. Mehta, A. Tarant, M. J. Wilking, Y. Fukuda, Y. Itow, H. Menjo, K. Ninomiya, Y. Yoshioka, J. Lagoda, M. Mandal, P. Mijakowski, Y. S. Prabhu, J. Zalipska, M. Jia, J. Jiang, W. Shi, C. Yanagisawa, M. Harada, Y. Hino, H. Ishino, Y. Koshio, F. Nakanishi, S. Sakai, T. Tada, T. Tano, T. Ishizuka, G. Barr, D. Barrow, L. Cook, S. Samani, D. Wark, A. Holin, F. Nova, S. Jung, B. S. Yang, J. Y. Yang, J. Yoo, J. E. P. Fannon, L. Kneale, M. Malek, J. M. McElwee, M. D. Thiesse, L. F. Thompson, S. T. Wilson, H. Okazawa, S. M. Lakshmi, S. B. Kim, E. Kwon, J. W. Seo, I. Yu, A. K. Ichikawa, K. Nakamura, S. Tairafune, K. Nishijima, A. Eguchi, K. Nakagiri, Y. Nakajima, S. Shima, N. Taniuchi, E. Watanabe, M. Yokoyama, P. de Perio, S. Fujita, C. Jesus-Valls, K. Martens, K. M. Tsui, M. R. Vagins, J. Xia, S. Izumiyama, M. Kuze, R. Matsumoto, K. Terada, M. Ishitsuka, H. Ito, Y. Ommura, N. Shigeta, M. Shinoki, K. Yamauchi, T. Yoshida, R. Gaur, V. Gousy-Leblanc, M. Hartz, A. Konaka, X. Li, S. Chen, B. D. Xu, B. Zhang, M. Posiadala-Zezula, S. B. Boyd, R. Edwards, D. Hadley, M. Nicholson, M. O'Flaherty, B. Richards, A. Ali, B. Jamieson, S. Amanai, Ll. Marti, A. Minamino, S. Suzuki, P. R. Scovell, E. Meehan, I. Bandac, C. Pena-Garay, J. Perez, O. Gileva, E. K. Lee, D. S. Leonard, Y. Sakakieda, A. Sakaguchi, K. Sueki, Y. Takaku, S. Yamasaki",
            "summary": "The first loading of gadolinium (Gd) into Super-Kamiokande in 2020 was\nsuccessful, and the neutron capture efficiency on Gd reached 50\\%. To further\nincrease the Gd neutron capture efficiency to 75\\%, 26.1 tons of $\\rm Gd_2(\\rm\nSO_4)_3\\cdot \\rm 8H_2O$ was additionally loaded into Super-Kamiokande (SK) from\nMay 31 to July 4, 2022. As the amount of loaded $\\rm Gd_2(\\rm SO_4)_3\\cdot \\rm\n8H_2O$ was doubled compared to the first loading, the capacity of the powder\ndissolving system was doubled. We also developed new batches of gadolinium\nsulfate with even further reduced radioactive impurities. In addition, a more\nefficient screening method was devised and implemented to evaluate these new\nbatches of $\\rm Gd_2(\\rm SO_4)_3\\cdot \\rm 8H_2O$. Following the second loading,\nthe Gd concentration in SK was measured to be $333.5\\pm2.5$ ppm via an Atomic\nAbsorption Spectrometer (AAS). From the mean neutron capture time constant of\nneutrons from an Am/Be calibration source, the Gd concentration was\nindependently measured to be 332.7 $\\pm$ 6.8(sys.) $\\pm$ 1.1(stat.) ppm,\nconsistent with the AAS result. Furthermore, during the loading the Gd\nconcentration was monitored continually using the capture time constant of each\nspallation neutron produced by cosmic-ray muons,and the final neutron capture\nefficiency was shown to become 1.5 times higher than that of the first loaded\nphase, as expected.",
            "pdf_url": "http://arxiv.org/pdf/2403.07796v3",
            "published": "2024-03-12 16:34:03+00:00",
            "updated": "2024-06-18 13:34:47+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Evaluating the design space of diffusion-based generative models",
            "authors": "Yuqing Wang, Ye He, Molei Tao",
            "summary": "Most existing theoretical investigations of the accuracy of diffusion models,\nalbeit significant, assume the score function has been approximated to a\ncertain accuracy, and then use this a priori bound to control the error of\ngeneration. This article instead provides a first quantitative understanding of\nthe whole generation process, i.e., both training and sampling. More precisely,\nit conducts a non-asymptotic convergence analysis of denoising score matching\nunder gradient descent. In addition, a refined sampling error analysis for\nvariance exploding models is also provided. The combination of these two\nresults yields a full error analysis, which elucidates (again, but this time\ntheoretically) how to design the training and sampling processes for effective\ngeneration. For instance, our theory implies a preference toward noise\ndistribution and loss weighting that qualitatively agree with the ones used in\n[Karras et al. 2022]. It also provides some perspectives on why the time and\nvariance schedule used in [Karras et al. 2022] could be better tuned than the\npioneering version in [Song et al. 2020].",
            "pdf_url": "http://arxiv.org/pdf/2406.12839v1",
            "published": "2024-06-18 17:56:10+00:00",
            "updated": "2024-06-18 17:56:10+00:00"
        },
        {
            "title": "Influence Maximization via Graph Neural Bandits",
            "authors": "Yuting Feng, Vincent Y. F. Tan, Bogdan Cautis",
            "summary": "We consider a ubiquitous scenario in the study of Influence Maximization\n(IM), in which there is limited knowledge about the topology of the diffusion\nnetwork. We set the IM problem in a multi-round diffusion campaign, aiming to\nmaximize the number of distinct users that are influenced. Leveraging the\ncapability of bandit algorithms to effectively balance the objectives of\nexploration and exploitation, as well as the expressivity of neural networks,\nour study explores the application of neural bandit algorithms to the IM\nproblem. We propose the framework IM-GNB (Influence Maximization with Graph\nNeural Bandits), where we provide an estimate of the users' probabilities of\nbeing influenced by influencers (also known as diffusion seeds). This initial\nestimate forms the basis for constructing both an exploitation graph and an\nexploration one. Subsequently, IM-GNB handles the exploration-exploitation\ntradeoff, by selecting seed nodes in real-time using Graph Convolutional\nNetworks (GCN), in which the pre-estimated graphs are employed to refine the\ninfluencers' estimated rewards in each contextual setting. Through extensive\nexperiments on two large real-world datasets, we demonstrate the effectiveness\nof IM-GNB compared with other baseline methods, significantly improving the\nspread outcome of such diffusion campaigns, when the underlying network is\nunknown.",
            "pdf_url": "http://arxiv.org/pdf/2406.12835v1",
            "published": "2024-06-18 17:54:33+00:00",
            "updated": "2024-06-18 17:54:33+00:00"
        },
        {
            "title": "Extracting Training Data from Unconditional Diffusion Models",
            "authors": "Yunhao Chen, Xingjun Ma, Difan Zou, Yu-Gang Jiang",
            "summary": "As diffusion probabilistic models (DPMs) are being employed as mainstream\nmodels for generative artificial intelligence (AI), the study of their\nmemorization of the raw training data has attracted growing attention. Existing\nworks in this direction aim to establish an understanding of whether or to what\nextent DPMs learn by memorization. Such an understanding is crucial for\nidentifying potential risks of data leakage and copyright infringement in\ndiffusion models and, more importantly, for more controllable generation and\ntrustworthy application of Artificial Intelligence Generated Content (AIGC).\nWhile previous works have made important observations of when DPMs are prone to\nmemorization, these findings are mostly empirical, and the developed data\nextraction methods only work for conditional diffusion models. In this work, we\naim to establish a theoretical understanding of memorization in DPMs with 1) a\nmemorization metric for theoretical analysis, 2) an analysis of conditional\nmemorization with informative and random labels, and 3) two better evaluation\nmetrics for measuring memorization. Based on the theoretical analysis, we\nfurther propose a novel data extraction method called \\textbf{Surrogate\ncondItional Data Extraction (SIDE)} that leverages a classifier trained on\ngenerated data as a surrogate condition to extract training data directly from\nunconditional diffusion models. Our empirical results demonstrate that SIDE can\nextract training data from diffusion models where previous methods fail, and it\nis on average over 50\\% more effective across different scales of the CelebA\ndataset.",
            "pdf_url": "http://arxiv.org/pdf/2406.12752v1",
            "published": "2024-06-18 16:20:12+00:00",
            "updated": "2024-06-18 16:20:12+00:00"
        },
        {
            "title": "To smooth a cloud or to pin it down: Guarantees and Insights on Score Matching in Denoising Diffusion Models",
            "authors": "Francisco Vargas, Teodora Reu, Anna Kerekes",
            "summary": "Denoising diffusion models are a class of generative models which have\nrecently achieved state-of-the-art results across many domains. Gradual noise\nis added to the data using a diffusion process, which transforms the data\ndistribution into a Gaussian. Samples from the generative model are then\nobtained by simulating an approximation of the time reversal of this diffusion\ninitialized by Gaussian samples. Recent research has explored adapting\ndiffusion models for sampling and inference tasks. In this paper, we leverage\nknown connections to stochastic control akin to the F\\\"ollmer drift to extend\nestablished neural network approximation results for the F\\\"ollmer drift to\ndenoising diffusion models and samplers.",
            "pdf_url": "http://arxiv.org/pdf/2305.09605v2",
            "published": "2023-05-16 16:56:19+00:00",
            "updated": "2024-06-18 16:01:52+00:00"
        },
        {
            "title": "Sparsifying dimensionality reduction of PDE solution data with Bregman learning",
            "authors": "Tjeerd Jan Heeringa, Christoph Brune, Mengwu Guo",
            "summary": "Classical model reduction techniques project the governing equations onto a\nlinear subspace of the original state space. More recent data-driven techniques\nuse neural networks to enable nonlinear projections. Whilst those often enable\nstronger compression, they may have redundant parameters and lead to suboptimal\nlatent dimensionality. To overcome these, we propose a multistep algorithm that\ninduces sparsity in the encoder-decoder networks for effective reduction in the\nnumber of parameters and additional compression of the latent space. This\nalgorithm starts with sparsely initialized a network and training it using\nlinearized Bregman iterations. These iterations have been very successful in\ncomputer vision and compressed sensing tasks, but have not yet been used for\nreduced-order modelling. After the training, we further compress the latent\nspace dimensionality by using a form of proper orthogonal decomposition. Last,\nwe use a bias propagation technique to change the induced sparsity into an\neffective reduction of parameters. We apply this algorithm to three\nrepresentative PDE models: 1D diffusion, 1D advection, and 2D\nreaction-diffusion. Compared to conventional training methods like Adam, the\nproposed method achieves similar accuracy with 30% less parameters and a\nsignificantly smaller latent space.",
            "pdf_url": "http://arxiv.org/pdf/2406.12672v1",
            "published": "2024-06-18 14:45:30+00:00",
            "updated": "2024-06-18 14:45:30+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "Self-Specialization: Uncovering Latent Expertise within Large Language Models",
            "authors": "Junmo Kang, Hongyin Luo, Yada Zhu, Jacob Hansen, James Glass, David Cox, Alan Ritter, Rogerio Feris, Leonid Karlinsky",
            "summary": "Recent works have demonstrated the effectiveness of self-alignment in which a\nlarge language model is aligned to follow general instructions using\ninstructional data generated from the model itself starting from a handful of\nhuman-written seeds. Instead of general alignment, in this work, we focus on\nself-alignment for expert domain specialization (e.g., biomedicine, finance).\nAs a preliminary, we quantitively show the marginal effect that generic\ninstruction-following training has on downstream expert domains' performance.\nTo remedy this, we propose self-specialization - allowing for effective model\nspecialization while achieving cross-task generalization by leveraging only a\nfew labeled seeds. Self-specialization offers a data- and parameter-efficient\nway of \"carving out\" an expert model out of a generalist pre-trained LLM.\nExploring a variety of popular open large models as a base for specialization,\nour experimental results in both biomedical and financial domains show that our\nself-specialized models outperform their base models by a large margin, and\neven larger models that are generally instruction-tuned or that have been\nadapted to the target domain by other means.",
            "pdf_url": "http://arxiv.org/pdf/2310.00160v2",
            "published": "2023-09-29 21:53:46+00:00",
            "updated": "2024-06-05 19:48:45+00:00"
        },
        {
            "title": "Limit Order Book Dynamics and Order Size Modelling Using Compound Hawkes Process",
            "authors": "Konark Jain, Nick Firoozye, Jonathan Kochems, Philip Treleaven",
            "summary": "Hawkes Process has been used to model Limit Order Book (LOB) dynamics in\nseveral ways in the literature however the focus has been limited to capturing\nthe inter-event times while the order size is usually assumed to be constant.\nWe propose a novel methodology of using Compound Hawkes Process for the LOB\nwhere each event has an order size sampled from a calibrated distribution. The\nprocess is formulated in a novel way such that the spread of the process always\nremains positive. Further, we condition the model parameters on time of day to\nsupport empirical observations. We make use of an enhanced non-parametric\nmethod to calibrate the Hawkes kernels and allow for inhibitory\ncross-excitation kernels. We showcase the results and quality of fits for an\nequity stock's LOB in the NASDAQ exchange and compare them against several\nbaselines. Finally, we conduct a market impact study of the simulator and show\nthe empirical observation of a concave market impact function is indeed\nreplicated.",
            "pdf_url": "http://arxiv.org/pdf/2312.08927v4",
            "published": "2023-12-14 13:36:15+00:00",
            "updated": "2024-05-07 14:17:10+00:00"
        },
        {
            "title": "Fourier Neural Network Approximation of Transition Densities in Finance",
            "authors": "Rong Du, Duy-Minh Dang",
            "summary": "This paper introduces FourNet, a novel single-layer feed-forward neural\nnetwork (FFNN) method designed to approximate transition densities for which\nclosed-form expressions of their Fourier transforms, i.e. characteristic\nfunctions, are available. A unique feature of FourNet lies in its use of a\nGaussian activation function, enabling exact Fourier and inverse Fourier\ntransformations and drawing analogies with the Gaussian mixture model. We\nmathematically establish FourNet's capacity to approximate transition densities\nin the $L_2$-sense arbitrarily well with finite number of neurons. The\nparameters of FourNet are learned by minimizing a loss function derived from\nthe known characteristic function and the Fourier transform of the FFNN,\ncomplemented by a strategic sampling approach to enhance training. We derive\npractical bounds for the $L_2$ estimation error and the potential pointwise\nloss of nonnegativity in FourNet, highlighting its robustness and applicability\nin practical settings. FourNet's accuracy and versatility are demonstrated\nthrough a wide range of dynamics common in quantitative finance, including\nL\\'{e}vy processes and the Heston stochastic volatility models-including those\naugmented with the self-exciting Queue-Hawkes jump process.",
            "pdf_url": "http://arxiv.org/pdf/2309.03966v2",
            "published": "2023-09-07 18:51:44+00:00",
            "updated": "2024-05-05 19:36:19+00:00"
        },
        {
            "title": "Fairness of ChatGPT",
            "authors": "Yunqi Li, Lanjing Zhang, Yongfeng Zhang",
            "summary": "Understanding and addressing unfairness in LLMs are crucial for responsible\nAI deployment. However, there is a limited number of quantitative analyses and\nin-depth studies regarding fairness evaluations in LLMs, especially when\napplying LLMs to high-stakes fields. This work aims to fill this gap by\nproviding a systematic evaluation of the effectiveness and fairness of LLMs\nusing ChatGPT as a study case. We focus on assessing ChatGPT's performance in\nhigh-takes fields including education, criminology, finance and healthcare. To\nconduct a thorough evaluation, we consider both group fairness and individual\nfairness metrics. We also observe the disparities in ChatGPT's outputs under a\nset of biased or unbiased prompts. This work contributes to a deeper\nunderstanding of LLMs' fairness performance, facilitates bias mitigation and\nfosters the development of responsible AI systems.",
            "pdf_url": "http://arxiv.org/pdf/2305.18569v2",
            "published": "2023-05-22 17:51:56+00:00",
            "updated": "2024-05-05 19:15:30+00:00"
        },
        {
            "title": "Modelling Opaque Bilateral Market Dynamics in Financial Trading: Insights from a Multi-Agent Simulation Study",
            "authors": "Alicia Vidler, Toby Walsh",
            "summary": "Exploring complex adaptive financial trading environments through multi-agent\nbased simulation methods presents an innovative approach within the realm of\nquantitative finance. Despite the dominance of multi-agent reinforcement\nlearning approaches in financial markets with observable data, there exists a\nset of systematically significant financial markets that pose challenges due to\ntheir partial or obscured data availability. We, therefore, devise a\nmulti-agent simulation approach employing small-scale meta-heuristic methods.\nThis approach aims to represent the opaque bilateral market for Australian\ngovernment bond trading, capturing the bilateral nature of bank-to-bank\ntrading, also referred to as \"over-the-counter\" (OTC) trading, and commonly\noccurring between \"market makers\". The uniqueness of the bilateral market,\ncharacterized by negotiated transactions and a limited number of agents, yields\nvaluable insights for agent-based modelling and quantitative finance. The\ninherent rigidity of this market structure, which is at odds with the global\nproliferation of multilateral platforms and the decentralization of finance,\nunderscores the unique insights offered by our agent-based model. We explore\nthe implications of market rigidity on market structure and consider the\nelement of stability, in market design. This extends the ongoing discourse on\ncomplex financial trading environments, providing an enhanced understanding of\ntheir dynamics and implications.",
            "pdf_url": "http://arxiv.org/pdf/2405.02849v1",
            "published": "2024-05-05 08:42:20+00:00",
            "updated": "2024-05-05 08:42:20+00:00"
        }
    ]
}