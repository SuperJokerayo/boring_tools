{
    "Physics": [
        {
            "title": "Local symmetries in partially ordered sets",
            "authors": "Christoph Minz",
            "summary": "Partially ordered sets (posets) have a universal appearance as an abstract\nstructure in many areas of mathematics. Though, even their explicit enumeration\nremains unknown in general, and only the counts of all partial orders on sets\nof up to 16 unlabelled elements have been calculated to date, see sequence\nA000112 in the OEIS.\n  In this work, we study automorphisms of posets in order to formulate a\nclassification by local symmetries. These symmetries give rise to a division\noperation on the set of all posets and lead us to the construction of symmetry\nclasses that are easier to characterise and enumerate. Additionally to the\nenumeration of symmetry classes, I derive polynomial expressions that count\ncertain subsets of posets with a large number of layers (a large height). As an\napplication in physics, I investigate local symmetries (or rather their lack\nof) in causal sets, which are discrete spacetime models used as a candidate\nframework for quantum gravity.",
            "pdf_url": "http://arxiv.org/pdf/2406.14533v1",
            "published": "2024-06-20 17:47:16+00:00",
            "updated": "2024-06-20 17:47:16+00:00"
        },
        {
            "title": "Ambiguity Clustering: an accurate and efficient decoder for qLDPC codes",
            "authors": "Stasiu Wolanski, Ben Barber",
            "summary": "Error correction allows a quantum computer to preserve a state long beyond\nthe decoherence time of its physical qubits by encoding logical qubits in a\nlarger number of physical qubits. The leading proposal for a scheme of quantum\nerror correction is based on the surface code, but several recently proposed\nquantum low-density parity check (qLDPC) codes allow more logical information\nto be encoded in significantly fewer physical qubits. Key to any scheme of\nquantum error correction is the decoder, an algorithm that estimates the error\nstate of the qubits from the results of syndrome measurements performed on\nthem. The surface code has a variety of fast and accurate decoders, but the\nstate-of-the-art decoder for general qLDPC codes, BP-OSD, has a high\ncomputational complexity. Here we introduce Ambiguity Clustering (AC), an\nalgorithm which seeks to divide the measurement data into clusters which are\ndecoded independently. We benchmark AC on the recently proposed bivariate\nbicycle codes and find that, at physically realistic error rates, AC is between\none and three orders of magnitude faster than BP-OSD with no reduction in\nlogical fidelity. Our CPU implementation of AC is already fast enough to decode\nthe 144-qubit Gross code in real time for neutral atom and trapped ion systems.",
            "pdf_url": "http://arxiv.org/pdf/2406.14527v1",
            "published": "2024-06-20 17:39:31+00:00",
            "updated": "2024-06-20 17:39:31+00:00"
        },
        {
            "title": "Scaling up global kinetic models of pulsar magnetospheres using a hybrid force-free-PIC numerical approach",
            "authors": "Adrien Soudais, Beno\u00eet Cerutti, Ioannis Contopoulos",
            "summary": "The particle-in-cell approach has proven effective at modeling neutron star\nand black hole magnetospheres from first principles, but global simulations are\nplagued with an unrealistically small separation between the scales where\nmicrophysics operates and the system-size scales due to limited numerical\nresources. A legitimate concern is whether the scale separation currently\nachieved is large enough, such that results can be safely extrapolated to\nrealistic scales. In this work, our aim is to explore the effect of scaling\nphysical parameters up, and to check whether salient features uncovered by pure\nkinetic models at smaller scales are still valid, with a special emphasis on\nparticle acceleration and high-energy radiation emitted beyond the light\ncylinder. To reach this objective, we develop a new hybrid numerical scheme\ncoupling the ideal force-free and the particle-in-cell methods, to optimize the\nnumerical cost of global models. We propose a domain decomposition of the\nmagnetosphere based on the magnetic field topology using the flux function. The\nforce-free model is enforced along open field lines while the particle-in-cell\nmodel is restricted to the reconnecting field line region. As a proof of\nconcept, this new hybrid model is applied to simulate a weak millisecond pulsar\nmagnetosphere with realistic scales using high-resolution axisymmetric\nsimulations. Magnetospheric features reported by previous kinetic models are\nrecovered, and strong synchrotron radiation above 100MeV consistent with the\nFermi-LAT gamma-ray pulsar population is successfully reproduced. This work\nfurther consolidates the shining reconnecting current sheet scenario as the\norigin of the gamma-ray emission in pulsars, as well as firmly establishes\npulsar magnetospheres as at least TeV particle accelerators.",
            "pdf_url": "http://arxiv.org/pdf/2406.14512v1",
            "published": "2024-06-20 17:20:45+00:00",
            "updated": "2024-06-20 17:20:45+00:00"
        },
        {
            "title": "rKAN: Rational Kolmogorov-Arnold Networks",
            "authors": "Alireza Afzal Aghaei",
            "summary": "The development of Kolmogorov-Arnold networks (KANs) marks a significant\nshift from traditional multi-layer perceptrons in deep learning. Initially,\nKANs employed B-spline curves as their primary basis function, but their\ninherent complexity posed implementation challenges. Consequently, researchers\nhave explored alternative basis functions such as Wavelets, Polynomials, and\nFractional functions. In this research, we explore the use of rational\nfunctions as a novel basis function for KANs. We propose two different\napproaches based on Pade approximation and rational Jacobi functions as\ntrainable basis functions, establishing the rational KAN (rKAN). We then\nevaluate rKAN's performance in various deep learning and physics-informed tasks\nto demonstrate its practicality and effectiveness in function approximation.",
            "pdf_url": "http://arxiv.org/pdf/2406.14495v1",
            "published": "2024-06-20 16:59:38+00:00",
            "updated": "2024-06-20 16:59:38+00:00"
        },
        {
            "title": "Valid Error Bars for Neural Weather Models using Conformal Prediction",
            "authors": "Vignesh Gopakumar, Joel Oskarrson, Ander Gray, Lorenzo Zanisi, Stanislas Pamela, Daniel Giles, Matt Kusner, Marc Deisenroth",
            "summary": "Neural weather models have shown immense potential as inexpensive and\naccurate alternatives to physics-based models. However, most models trained to\nperform weather forecasting do not quantify the uncertainty associated with\ntheir forecasts. This limits the trust in the model and the usefulness of the\nforecasts. In this work we construct and formalise a conformal prediction\nframework as a post-processing method for estimating this uncertainty. The\nmethod is model-agnostic and gives calibrated error bounds for all variables,\nlead times and spatial locations. No modifications are required to the model\nand the computational cost is negligible compared to model training. We\ndemonstrate the usefulness of the conformal prediction framework on a limited\narea neural weather model for the Nordic region. We further explore the\nadvantages of the framework for deterministic and probabilistic models.",
            "pdf_url": "http://arxiv.org/pdf/2406.14483v1",
            "published": "2024-06-20 16:45:41+00:00",
            "updated": "2024-06-20 16:45:41+00:00"
        },
        {
            "title": "High-threshold, low-overhead and single-shot decodable fault-tolerant quantum memory",
            "authors": "Thomas R. Scruby, Timo Hillmann, Joschka Roffe",
            "summary": "We present a new family of quantum low-density parity-check codes, which we\ncall radial codes, obtained from the lifted product of a specific subset of\nclassical quasi-cyclic codes. The codes are defined using a pair of integers\n$(r,s)$ and have parameters $[\\![2r^2s,2(r-1)^2,\\leq2s]\\!]$, with numerical\nstudies suggesting average-case distance linear in $s$. In simulations of\ncircuit-level noise, we observe comparable error suppression to surface codes\nof similar distance while using approximately five times fewer physical qubits.\nThis is true even when radial codes are decoded using a single-shot approach,\nwhich can allow for faster logical clock speeds and reduced decoding\ncomplexity. We describe an intuitive visual representation, canonical basis of\nlogical operators and optimal-length stabiliser measurement circuits for these\ncodes, and argue that their error correction capabilities, tunable parameters\nand small size make them promising candidates for implementation on near-term\nquantum devices.",
            "pdf_url": "http://arxiv.org/pdf/2406.14445v1",
            "published": "2024-06-20 16:08:06+00:00",
            "updated": "2024-06-20 16:08:06+00:00"
        },
        {
            "title": "Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology",
            "authors": "Qingsong Xu, Yilei Shi, Jonathan Bamber, Ye Tuo, Ralf Ludwig, Xiao Xiang Zhu",
            "summary": "Accurate hydrological understanding and water cycle prediction are crucial\nfor addressing scientific and societal challenges associated with the\nmanagement of water resources, particularly under the dynamic influence of\nanthropogenic climate change. Existing reviews predominantly concentrate on the\ndevelopment of machine learning (ML) in this field, yet there is a clear\ndistinction between hydrology and ML as separate paradigms. Here, we introduce\nphysics-aware ML as a transformative approach to overcome the perceived barrier\nand revolutionize both fields. Specifically, we present a comprehensive review\nof the physics-aware ML methods, building a structured community (PaML) of\nexisting methodologies that integrate prior physical knowledge or physics-based\nmodeling into ML. We systematically analyze these PaML methodologies with\nrespect to four aspects: physical data-guided ML, physics-informed ML,\nphysics-embedded ML, and physics-aware hybrid learning. PaML facilitates\nML-aided hypotheses, accelerating insights from big data and fostering\nscientific discoveries. We first conduct a systematic review of hydrology in\nPaML, including rainfall-runoff hydrological processes and hydrodynamic\nprocesses, and highlight the most promising and challenging directions for\ndifferent objectives and PaML methods. Finally, a new PaML-based hydrology\nplatform, termed HydroPML, is released as a foundation for hydrological\napplications. HydroPML enhances the explainability and causality of ML and lays\nthe groundwork for the digital water cycle's realization. The HydroPML platform\nis publicly available at https://hydropml.github.io/.",
            "pdf_url": "http://arxiv.org/pdf/2310.05227v4",
            "published": "2023-10-08 16:48:29+00:00",
            "updated": "2024-06-20 16:05:07+00:00"
        },
        {
            "title": "Transferable Boltzmann Generators",
            "authors": "Leon Klein, Frank No\u00e9",
            "summary": "The generation of equilibrium samples of molecular systems has been a\nlong-standing problem in statistical physics. Boltzmann Generators are a\ngenerative machine learning method that addresses this issue by learning a\ntransformation via a normalizing flow from a simple prior distribution to the\ntarget Boltzmann distribution of interest. Recently, flow matching has been\nemployed to train Boltzmann Generators for small molecular systems in Cartesian\ncoordinates. We extend this work and propose a first framework for Boltzmann\nGenerators that are transferable across chemical space, such that they predict\nzero-shot Boltzmann distributions for test molecules without being retrained\nfor these systems. These transferable Boltzmann Generators allow approximate\nsampling from the target distribution of unseen systems, as well as efficient\nreweighting to the target Boltzmann distribution. The transferability of the\nproposed framework is evaluated on dipeptides, where we show that it\ngeneralizes efficiently to unseen systems. Furthermore, we demonstrate that our\nproposed architecture enhances the efficiency of Boltzmann Generators trained\non single molecular systems.",
            "pdf_url": "http://arxiv.org/pdf/2406.14426v1",
            "published": "2024-06-20 15:50:12+00:00",
            "updated": "2024-06-20 15:50:12+00:00"
        },
        {
            "title": "Electrical switching of Ising-superconducting nonreciprocity for quantum neuronal transistor",
            "authors": "Junlin Xiong, Jiao Xie, Bin Cheng, Yudi Dai, Xinyu Cui, Lizheng Wang, Zenglin Liu, Ji Zhou, Naizhou Wang, Xianghan Xu, Xianhui Chen, Sang-Wook Cheong, Shi-Jun Liang, Feng Miao",
            "summary": "Nonreciprocal quantum transport effect is mainly governed by the symmetry\nbreaking of the material systems and is gaining extensive attention in\ncondensed matter physics. Realizing electrical switching of the polarity of the\nnonreciprocal transport without external magnetic field is essential to the\ndevelopment of nonreciprocal quantum devices. However, electrical switching of\nsuperconducting nonreciprocity remains yet to be achieved. Here, we report the\nobservation of field-free electrical switching of nonreciprocal Ising\nsuperconductivity in Fe3GeTe2/NbSe2 van der Waals (vdW) heterostructure. By\ntaking advantage of this electrically switchable superconducting\nnonreciprocity, we demonstrate a proof-of-concept nonreciprocal quantum\nneuronal transistor, which allows for implementing the XOR logic gate and\nfaithfully emulating biological functionality of a cortical neuron in the\nbrain. Our work provides a promising pathway to realize field-free and\nelectrically switchable nonreciprocity of quantum transport and demonstrate its\npotential in exploring neuromorphic quantum devices with both functionality and\nperformance beyond the traditional devices.",
            "pdf_url": "http://arxiv.org/pdf/2406.14417v1",
            "published": "2024-06-20 15:38:50+00:00",
            "updated": "2024-06-20 15:38:50+00:00"
        },
        {
            "title": "Silicon Nitride C-Band Grating Coupler with Reduced Waveguide Back-Reflection Using Adaptively Corrected Elliptical Grates",
            "authors": "Ibrahim Ghannam, Florian Merget, Jeremy Witzens",
            "summary": "We present experimental results for a fully etched C-band grating coupler\nwith reduced back reflection fabricated in an 800 nm silicon nitride platform.\nBack-reflections are reduced by symmetrically interrupting the first few grates\naround the center axis of the propagating light. The span of the etched grates\nis gradually increased until they cover the full width. By interrupting the\ngrates, light is reflected back obliquely, which leads to the excitation of\nhigher-order modes that are scattered out of the structure. While this approach\nhas been previously shown in silicon, it comes with a significant penalty in\ncoupling efficiency of around 2.4 dB of extra loss in the layer stack\ninvestigated here. In this work, we present the design and measurement results\nof a grating coupler in which waveguide-to-waveguide back-reflections are\nsuppressed by ~10 dB with this technique, while at the same time mitigating\nexcess insertion losses by reshaping the grates as ellipses of varying\neccentricity. This helps to compensate the phase front error induced by the\ninterruption of the grates. This correction does not affect the level by which\nthe back-reflection is suppressed, but reduces the insertion loss penalty from\n2.4 dB to 1 dB.",
            "pdf_url": "http://arxiv.org/pdf/2406.14413v1",
            "published": "2024-06-20 15:33:40+00:00",
            "updated": "2024-06-20 15:33:40+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Consistency Models Made Easy",
            "authors": "Zhengyang Geng, Ashwini Pokle, William Luo, Justin Lin, J. Zico Kolter",
            "summary": "Consistency models (CMs) are an emerging class of generative models that\noffer faster sampling than traditional diffusion models. CMs enforce that all\npoints along a sampling trajectory are mapped to the same initial point. But\nthis target leads to resource-intensive training: for example, as of 2024,\ntraining a SoTA CM on CIFAR-10 takes one week on 8 GPUs. In this work, we\npropose an alternative scheme for training CMs, vastly improving the efficiency\nof building such models. Specifically, by expressing CM trajectories via a\nparticular differential equation, we argue that diffusion models can be viewed\nas a special case of CMs with a specific discretization. We can thus fine-tune\na consistency model starting from a pre-trained diffusion model and\nprogressively approximate the full consistency condition to stronger degrees\nover the training process. Our resulting method, which we term Easy Consistency\nTuning (ECT), achieves vastly improved training times while indeed improving\nupon the quality of previous methods: for example, ECT achieves a 2-step FID of\n2.73 on CIFAR10 within 1 hour on a single A100 GPU, matching Consistency\nDistillation trained of hundreds of GPU hours. Owing to this computational\nefficiency, we investigate the scaling law of CMs under ECT, showing that they\nseem to obey classic power law scaling, hinting at their ability to improve\nefficiency and performance at larger scales. Code\n(https://github.com/locuslab/ect) is available.",
            "pdf_url": "http://arxiv.org/pdf/2406.14548v1",
            "published": "2024-06-20 17:56:02+00:00",
            "updated": "2024-06-20 17:56:02+00:00"
        },
        {
            "title": "V-LASIK: Consistent Glasses-Removal from Videos Using Synthetic Data",
            "authors": "Rotem Shalev-Arkushin, Aharon Azulay, Tavi Halperin, Eitan Richardson, Amit H. Bermano, Ohad Fried",
            "summary": "Diffusion-based generative models have recently shown remarkable image and\nvideo editing capabilities. However, local video editing, particularly removal\nof small attributes like glasses, remains a challenge. Existing methods either\nalter the videos excessively, generate unrealistic artifacts, or fail to\nperform the requested edit consistently throughout the video. In this work, we\nfocus on consistent and identity-preserving removal of glasses in videos, using\nit as a case study for consistent local attribute removal in videos. Due to the\nlack of paired data, we adopt a weakly supervised approach and generate\nsynthetic imperfect data, using an adjusted pretrained diffusion model. We show\nthat despite data imperfection, by learning from our generated data and\nleveraging the prior of pretrained diffusion models, our model is able to\nperform the desired edit consistently while preserving the original video\ncontent. Furthermore, we exemplify the generalization ability of our method to\nother local video editing tasks by applying it successfully to facial\nsticker-removal. Our approach demonstrates significant improvement over\nexisting methods, showcasing the potential of leveraging synthetic data and\nstrong video priors for local video editing tasks.",
            "pdf_url": "http://arxiv.org/pdf/2406.14510v1",
            "published": "2024-06-20 17:14:43+00:00",
            "updated": "2024-06-20 17:14:43+00:00"
        },
        {
            "title": "SafeSora: Towards Safety Alignment of Text2Video Generation via a Human Preference Dataset",
            "authors": "Josef Dai, Tianle Chen, Xuyao Wang, Ziran Yang, Taiye Chen, Jiaming Ji, Yaodong Yang",
            "summary": "To mitigate the risk of harmful outputs from large vision models (LVMs), we\nintroduce the SafeSora dataset to promote research on aligning text-to-video\ngeneration with human values. This dataset encompasses human preferences in\ntext-to-video generation tasks along two primary dimensions: helpfulness and\nharmlessness. To capture in-depth human preferences and facilitate structured\nreasoning by crowdworkers, we subdivide helpfulness into 4 sub-dimensions and\nharmlessness into 12 sub-categories, serving as the basis for pilot\nannotations. The SafeSora dataset includes 14,711 unique prompts, 57,333 unique\nvideos generated by 4 distinct LVMs, and 51,691 pairs of preference annotations\nlabeled by humans. We further demonstrate the utility of the SafeSora dataset\nthrough several applications, including training the text-video moderation\nmodel and aligning LVMs with human preference by fine-tuning a prompt\naugmentation module or the diffusion model. These applications highlight its\npotential as the foundation for text-to-video alignment research, such as human\npreference modeling and the development and validation of alignment algorithms.",
            "pdf_url": "http://arxiv.org/pdf/2406.14477v1",
            "published": "2024-06-20 16:38:56+00:00",
            "updated": "2024-06-20 16:38:56+00:00"
        },
        {
            "title": "CollaFuse: Collaborative Diffusion Models",
            "authors": "Simeon Allmendinger, Domenique Zipperling, Lukas Struppek, Niklas K\u00fchl",
            "summary": "In the landscape of generative artificial intelligence, diffusion-based\nmodels have emerged as a promising method for generating synthetic images.\nHowever, the application of diffusion models poses numerous challenges,\nparticularly concerning data availability, computational requirements, and\nprivacy. Traditional approaches to address these shortcomings, like federated\nlearning, often impose significant computational burdens on individual clients,\nespecially those with constrained resources. In response to these challenges,\nwe introduce a novel approach for distributed collaborative diffusion models\ninspired by split learning. Our approach facilitates collaborative training of\ndiffusion models while alleviating client computational burdens during image\nsynthesis. This reduced computational burden is achieved by retaining data and\ncomputationally inexpensive processes locally at each client while outsourcing\nthe computationally expensive processes to shared, more efficient server\nresources. Through experiments on the common CelebA dataset, our approach\ndemonstrates enhanced privacy by reducing the necessity for sharing raw data.\nThese capabilities hold significant potential across various application areas,\nincluding the design of edge computing solutions. Thus, our work advances\ndistributed machine learning by contributing to the evolution of collaborative\ndiffusion models.",
            "pdf_url": "http://arxiv.org/pdf/2406.14429v1",
            "published": "2024-06-20 15:54:21+00:00",
            "updated": "2024-06-20 15:54:21+00:00"
        },
        {
            "title": "Active Diffusion Subsampling",
            "authors": "Oisin Nolan, Tristan S. W. Stevens, Wessel L. van Nierop, Ruud J. G. van Sloun",
            "summary": "Subsampling is commonly used to mitigate costs associated with data\nacquisition, such as time or energy requirements, motivating the development of\nalgorithms for estimating the fully-sampled signal of interest $x$ from\npartially observed measurements $y$. In maximum-entropy sampling, one selects\nmeasurement locations that are expected to have the highest entropy, so as to\nminimize uncertainty about $x$. This approach relies on an accurate model of\nthe posterior distribution over future measurements, given the measurements\nobserved so far. Recently, diffusion models have been shown to produce\nhigh-quality posterior samples of high-dimensional signals using guided\ndiffusion. In this work, we propose Active Diffusion Subsampling (ADS), a\nmethod for performing active subsampling using guided diffusion in which the\nmodel tracks a distribution of beliefs over the true state of $x$ throughout\nthe reverse diffusion process, progressively decreasing its uncertainty by\nchoosing to acquire measurements with maximum expected entropy, and ultimately\ngenerating the posterior distribution $p(x | y)$. ADS can be applied using\npre-trained diffusion models for any subsampling rate, and does not require\ntask-specific retraining - just the specification of a measurement model.\nFurthermore, the maximum entropy sampling policy employed by ADS is\ninterpretable, enhancing transparency relative to existing methods using\nblack-box policies. Experimentally, we show that ADS outperforms fixed sampling\nstrategies, and study an application of ADS in Magnetic Resonance Imaging\nacceleration using the fastMRI dataset, finding that ADS performs competitively\nwith supervised methods. Code available at\nhttps://active-diffusion-subsampling.github.io/.",
            "pdf_url": "http://arxiv.org/pdf/2406.14388v1",
            "published": "2024-06-20 15:05:06+00:00",
            "updated": "2024-06-20 15:05:06+00:00"
        }
    ]
}