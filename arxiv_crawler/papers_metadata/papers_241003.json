{
    "Physics": [
        {
            "title": "FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments Generation from In-The-Wild Clothing Images",
            "authors": "Cheng Zhang, Yuanhao Wang, Francisco Vicente Carrasco, Chenglei Wu, Jinlong Yang, Thabo Beeler, Fernando De la Torre",
            "summary": "We introduce FabricDiffusion, a method for transferring fabric textures from\na single clothing image to 3D garments of arbitrary shapes. Existing approaches\ntypically synthesize textures on the garment surface through 2D-to-3D texture\nmapping or depth-aware inpainting via generative models. Unfortunately, these\nmethods often struggle to capture and preserve texture details, particularly\ndue to challenging occlusions, distortions, or poses in the input image.\nInspired by the observation that in the fashion industry, most garments are\nconstructed by stitching sewing patterns with flat, repeatable textures, we\ncast the task of clothing texture transfer as extracting distortion-free,\ntileable texture materials that are subsequently mapped onto the UV space of\nthe garment. Building upon this insight, we train a denoising diffusion model\nwith a large-scale synthetic dataset to rectify distortions in the input\ntexture image. This process yields a flat texture map that enables a tight\ncoupling with existing Physically-Based Rendering (PBR) material generation\npipelines, allowing for realistic relighting of the garment under various\nlighting conditions. We show that FabricDiffusion can transfer various features\nfrom a single clothing image including texture patterns, material properties,\nand detailed prints and logos. Extensive experiments demonstrate that our model\nsignificantly outperforms state-to-the-art methods on both synthetic data and\nreal-world, in-the-wild clothing images while generalizing to unseen textures\nand garment shapes.",
            "pdf_url": "http://arxiv.org/pdf/2410.01801v1",
            "published": "2024-10-02 17:57:12+00:00",
            "updated": "2024-10-02 17:57:12+00:00"
        },
        {
            "title": "Thermodynamic Bayesian Inference",
            "authors": "Maxwell Aifer, Samuel Duffield, Kaelan Donatella, Denis Melanson, Phoebe Klett, Zach Belateche, Gavin Crooks, Antonio J. Martinez, Patrick J. Coles",
            "summary": "A fully Bayesian treatment of complicated predictive models (such as deep\nneural networks) would enable rigorous uncertainty quantification and the\nautomation of higher-level tasks including model selection. However, the\nintractability of sampling Bayesian posteriors over many parameters inhibits\nthe use of Bayesian methods where they are most needed. Thermodynamic computing\nhas emerged as a paradigm for accelerating operations used in machine learning,\nsuch as matrix inversion, and is based on the mapping of Langevin equations to\nthe dynamics of noisy physical systems. Hence, it is natural to consider the\nimplementation of Langevin sampling algorithms on thermodynamic devices. In\nthis work we propose electronic analog devices that sample from Bayesian\nposteriors by realizing Langevin dynamics physically. Circuit designs are given\nfor sampling the posterior of a Gaussian-Gaussian model and for Bayesian\nlogistic regression, and are validated by simulations. It is shown, under\nreasonable assumptions, that the Bayesian posteriors for these models can be\nsampled in time scaling with $\\ln(d)$, where $d$ is dimension. For the\nGaussian-Gaussian model, the energy cost is shown to scale with $ d \\ln(d)$.\nThese results highlight the potential for fast, energy-efficient Bayesian\ninference using thermodynamic computing.",
            "pdf_url": "http://arxiv.org/pdf/2410.01793v1",
            "published": "2024-10-02 17:51:58+00:00",
            "updated": "2024-10-02 17:51:58+00:00"
        },
        {
            "title": "Dynamical-generative downscaling of climate model ensembles",
            "authors": "Ignacio Lopez-Gomez, Zhong Yi Wan, Leonardo Zepeda-N\u00fa\u00f1ez, Tapio Schneider, John Anderson, Fei Sha",
            "summary": "Regional high-resolution climate projections are crucial for many\napplications, such as agriculture, hydrology, and natural hazard risk\nassessment. Dynamical downscaling, the state-of-the-art method to produce\nlocalized future climate information, involves running a regional climate model\n(RCM) driven by an Earth System Model (ESM), but it is too computationally\nexpensive to apply to large climate projection ensembles. We propose a novel\napproach combining dynamical downscaling with generative artificial\nintelligence to reduce the cost and improve the uncertainty estimates of\ndownscaled climate projections. In our framework, an RCM dynamically downscales\nESM output to an intermediate resolution, followed by a generative diffusion\nmodel that further refines the resolution to the target scale. This approach\nleverages the generalizability of physics-based models and the sampling\nefficiency of diffusion models, enabling the downscaling of large multi-model\nensembles. We evaluate our method against dynamically-downscaled climate\nprojections from the CMIP6 ensemble. Our results demonstrate its ability to\nprovide more accurate uncertainty bounds on future regional climate than\nalternatives such as dynamical downscaling of smaller ensembles, or traditional\nempirical statistical downscaling methods. We also show that\ndynamical-generative downscaling results in significantly lower errors than\nbias correction and spatial disaggregation (BCSD), and captures more accurately\nthe spectra and multivariate correlations of meteorological fields. These\ncharacteristics make the dynamical-generative framework a flexible, accurate,\nand efficient way to downscale large ensembles of climate projections,\ncurrently out of reach for pure dynamical downscaling.",
            "pdf_url": "http://arxiv.org/pdf/2410.01776v1",
            "published": "2024-10-02 17:31:01+00:00",
            "updated": "2024-10-02 17:31:01+00:00"
        },
        {
            "title": "$^{229}\\mathrm{ThF}_4$ thin films for solid-state nuclear clocks",
            "authors": "Chuankun Zhang, Lars von der Wense, Jack F. Doyle, Jacob S. Higgins, Tian Ooi, Hans U. Friebel, Jun Ye, R. Elwell, J. E. S. Terhune, H. W. T. Morgan, A. N. Alexandrova, H. B. Tran Tan, Andrei Derevianko, Eric R. Hudson",
            "summary": "After nearly fifty years of searching, the vacuum ultraviolet $^{229}$Th\nnuclear isomeric transition has recently been directly laser excited [1,2] and\nmeasured with high spectroscopic precision [3]. Nuclear clocks based on this\ntransition are expected to be more robust [4,5] than and may outperform [6,7]\ncurrent optical atomic clocks. They also promise sensitive tests for new\nphysics beyond the standard model [5,8,9]. In light of these important advances\nand applications, a dramatic increase in the need for $^{229}$Th spectroscopy\ntargets in a variety of platforms is anticipated. However, the growth and\nhandling of high-concentration $^{229}$Th-doped crystals [5] used in previous\nmeasurements [1-3,10] are challenging due to the scarcity and radioactivity of\nthe $^{229}$Th material. Here, we demonstrate a potentially scalable solution\nto these problems by demonstrating laser excitation of the nuclear transition\nin $^{229}$ThF$_4$ thin films grown with a physical vapor deposition process,\nconsuming only micrograms of $^{229}$Th material. The $^{229}$ThF$_4$ thin\nfilms are intrinsically compatible with photonics platforms and nanofabrication\ntools for integration with laser sources and detectors, paving the way for an\nintegrated and field-deployable solid-state nuclear clock with radioactivity up\nto three orders of magnitude smaller than typical \\thor-doped crystals\n[1-3,10]. The high nuclear emitter density in $^{229}$ThF$_4$ also potentially\nenables quantum optics studies in a new regime. Finally, we describe the\noperation and present the estimation of the performance of a nuclear clock\nbased on a defect-free ThF$_4$ crystal.",
            "pdf_url": "http://arxiv.org/pdf/2410.01753v1",
            "published": "2024-10-02 17:03:06+00:00",
            "updated": "2024-10-02 17:03:06+00:00"
        },
        {
            "title": "TorchSISSO: A PyTorch-Based Implementation of the Sure Independence Screening and Sparsifying Operator for Efficient and Interpretable Model Discovery",
            "authors": "Madhav Muthyala, Farshud Sorourifar, Joel A. Paulson",
            "summary": "Symbolic regression (SR) is a powerful machine learning approach that\nsearches for both the structure and parameters of algebraic models, offering\ninterpretable and compact representations of complex data. Unlike traditional\nregression methods, SR explores progressively complex feature spaces, which can\nuncover simple models that generalize well, even from small datasets. Among SR\nalgorithms, the Sure Independence Screening and Sparsifying Operator (SISSO)\nhas proven particularly effective in the natural sciences, helping to\nrediscover fundamental physical laws as well as discover new interpretable\nequations for materials property modeling. However, its widespread adoption has\nbeen limited by performance inefficiencies and the challenges posed by its\nFORTRAN-based implementation, especially in modern computing environments. In\nthis work, we introduce TorchSISSO, a native Python implementation built in the\nPyTorch framework. TorchSISSO leverages GPU acceleration, easy integration, and\nextensibility, offering a significant speed-up and improved accuracy over the\noriginal. We demonstrate that TorchSISSO matches or exceeds the performance of\nthe original SISSO across a range of tasks, while dramatically reducing\ncomputational time and improving accessibility for broader scientific\napplications.",
            "pdf_url": "http://arxiv.org/pdf/2410.01752v1",
            "published": "2024-10-02 17:02:17+00:00",
            "updated": "2024-10-02 17:02:17+00:00"
        },
        {
            "title": "Strategies for Pretraining Neural Operators",
            "authors": "Anthony Zhou, Cooper Lorsung, AmirPouya Hemmasian, Amir Barati Farimani",
            "summary": "Pretraining for partial differential equation (PDE) modeling has recently\nshown promise in scaling neural operators across datasets to improve\ngeneralizability and performance. Despite these advances, our understanding of\nhow pretraining affects neural operators is still limited; studies generally\npropose tailored architectures and datasets that make it challenging to compare\nor examine different pretraining frameworks. To address this, we compare\nvarious pretraining methods without optimizing architecture choices to\ncharacterize pretraining dynamics on different models and datasets as well as\nto understand its scaling and generalization behavior. We find that pretraining\nis highly dependent on model and dataset choices, but in general transfer\nlearning or physics-based pretraining strategies work best. In addition,\npretraining performance can be further improved by using data augmentations.\nLastly, pretraining can be additionally beneficial when fine-tuning in scarce\ndata regimes or when generalizing to downstream data similar to the pretraining\ndistribution. Through providing insights into pretraining neural operators for\nphysics prediction, we hope to motivate future work in developing and\nevaluating pretraining methods for PDEs.",
            "pdf_url": "http://arxiv.org/pdf/2406.08473v2",
            "published": "2024-06-12 17:56:46+00:00",
            "updated": "2024-10-02 16:37:16+00:00"
        },
        {
            "title": "Observation of quantum entanglement in top-quark pairs using the ATLAS detector",
            "authors": "ATLAS Collaboration",
            "summary": "Entanglement is a key feature of quantum mechanics, with applications in\nfields such as metrology, cryptography, quantum information, and quantum\ncomputation. It has been observed in a wide variety of systems and length\nscales, ranging from the microscopic to the macroscopic. However, entanglement\nremains largely unexplored at the highest accessible energy scales. Here we\nreport the highest-energy observation of entanglement, in top$-$antitop quark\nevents produced at the Large Hadron Collider, using a proton$-$proton collision\ndataset with a center-of-mass energy of $\\sqrt{s}=13$ TeV and an integrated\nluminosity of 140 fb$^{-1}$ recorded with the ATLAS experiment. Spin\nentanglement is detected from the measurement of a single observable $D$,\ninferred from the angle between the charged leptons in their parent top- and\nantitop-quark rest frames. The observable is measured in a narrow interval\naround the top$-$antitop quark production threshold, where the entanglement\ndetection is expected to be significant. It is reported in a fiducial phase\nspace defined with stable particles to minimize the uncertainties that stem\nfrom limitations of the Monte Carlo event generators and the parton shower\nmodel in modeling top-quark pair production. The entanglement marker is\nmeasured to be $D=-0.537 \\pm 0.002~\\text{(stat.)} \\pm 0.019~\\text{(syst.)}$ for\n$340 < m_{t\\bar{t}} < 380$ GeV. The observed result is more than five standard\ndeviations from a scenario without entanglement and constitutes the first\nobservation of entanglement in a pair of quarks and the highest-energy\nobservation of entanglement so far.",
            "pdf_url": "http://arxiv.org/pdf/2311.07288v3",
            "published": "2023-11-13 12:33:25+00:00",
            "updated": "2024-10-02 16:26:22+00:00"
        },
        {
            "title": "Mind Scramble: Unveiling Large Language Model Psychology Via Typoglycemia",
            "authors": "Miao Yu, Junyuan Mao, Guibin Zhang, Jingheng Ye, Junfeng Fang, Aoxiao Zhong, Yang Liu, Yuxuan Liang, Kun Wang, Qingsong Wen",
            "summary": "Research into the external behaviors and internal mechanisms of large\nlanguage models (LLMs) has shown promise in addressing complex tasks in the\nphysical world. Studies suggest that powerful LLMs, like GPT-4, are beginning\nto exhibit human-like cognitive abilities, including planning, reasoning, and\nreflection. In this paper, we introduce a research line and methodology called\nLLM Psychology, leveraging human psychology experiments to investigate the\ncognitive behaviors and mechanisms of LLMs. We migrate the Typoglycemia\nphenomenon from psychology to explore the \"mind\" of LLMs. Unlike human brains,\nwhich rely on context and word patterns to comprehend scrambled text, LLMs use\ndistinct encoding and decoding processes. Through Typoglycemia experiments at\nthe character, word, and sentence levels, we observe: (I) LLMs demonstrate\nhuman-like behaviors on a macro scale, such as lower task accuracy and higher\ntoken/time consumption; (II) LLMs exhibit varying robustness to scrambled\ninput, making Typoglycemia a benchmark for model evaluation without new\ndatasets; (III) Different task types have varying impacts, with complex logical\ntasks (e.g., math) being more challenging in scrambled form; (IV) Each LLM has\na unique and consistent \"cognitive pattern\" across tasks, revealing general\nmechanisms in its psychology process. We provide an in-depth analysis of hidden\nlayers to explain these phenomena, paving the way for future research in LLM\nPsychology and deeper interpretability.",
            "pdf_url": "http://arxiv.org/pdf/2410.01677v1",
            "published": "2024-10-02 15:47:25+00:00",
            "updated": "2024-10-02 15:47:25+00:00"
        },
        {
            "title": "Path integral treatment of coherence effects in charmonium production in nuclear ultra-peripheral collisions",
            "authors": "J. \u00d3bertov\u00e1, J. Nemchik",
            "summary": "We present for the first time a revised study of charmonium production in\nnuclear ultra-peripheral collisions (UPC) based on a rigorous Green function\nformalism. This formalism allows for the proper incorporation of the effects of\ncolor transparency, as well as the quantum coherence inherent in the higher\ntwist quark shadowing related to the $Q\\bar Q$ Fock component of the photon.\nThe significance of this effect gradually decreases towards forward and/or\nbackward rapidities. In the LHC kinematic region we additionally incorporate\nwithin the same formalism the leading twist gluon shadowing corrections related\nto higher multi-gluon photon fluctuations. They represent a dominant source of\nnuclear phenomena in the mid-rapidity region. Model predictions for the\nrapidity distributions $d\\sigma/dy$ are in good agreement with available UPC\ndata on coherent charmonium production at RHIC and the LHC. They can also be\nverified by future measurements at the LHC, as well as at EIC.",
            "pdf_url": "http://arxiv.org/pdf/2410.01668v1",
            "published": "2024-10-02 15:35:55+00:00",
            "updated": "2024-10-02 15:35:55+00:00"
        },
        {
            "title": "The Resonance Condition for Slow Wave Antennas: a Lagrangian Approach",
            "authors": "Robert Nevels, Steven Scully, Francisco Espinal, Anatoly Svidzinsky",
            "summary": "A proof of the resonant property of linear periodically loaded antennas with\nsubwavelength elements is obtained by applying a Lagrangian formalism. A\nLagrangian is developed by modeling the antenna with lumped inductance and\ncapacitance elements on a single line, thereby physically similar to the\nantenna and thus avoiding the inaccurate two parallel conductor transmission\nline model. An equation for the antenna current driven by an incident\nelectromagnetic field is obtained via vector and scalar potentials. It is shown\nthat periodic loading provides a means to shorten the resonant length while the\nantenna pattern remains unchanged. The Lagrangian model is validated through a\ncalculation showing the loaded resonant length is determined by a product of a\nresonant half-wavelength dipole with the ratio of the free space velocity and\nthe longitudinal traveling wave velocity. A periodically loaded disk-on-rod\nantenna example with simulations and measurements provides further validation\nof the mathematics.",
            "pdf_url": "http://arxiv.org/pdf/2410.01662v1",
            "published": "2024-10-02 15:29:55+00:00",
            "updated": "2024-10-02 15:29:55+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Bellman Diffusion: Generative Modeling as Learning a Linear Operator in the Distribution Space",
            "authors": "Yangming Li, Chieh-Hsin Lai, Carola-Bibiane Sch\u00f6nlieb, Yuki Mitsufuji, Stefano Ermon",
            "summary": "Deep Generative Models (DGMs), including Energy-Based Models (EBMs) and\nScore-based Generative Models (SGMs), have advanced high-fidelity data\ngeneration and complex continuous distribution approximation. However, their\napplication in Markov Decision Processes (MDPs), particularly in distributional\nReinforcement Learning (RL), remains underexplored, with conventional\nhistogram-based methods dominating the field. This paper rigorously highlights\nthat this application gap is caused by the nonlinearity of modern DGMs, which\nconflicts with the linearity required by the Bellman equation in MDPs. For\ninstance, EBMs involve nonlinear operations such as exponentiating energy\nfunctions and normalizing constants. To address this, we introduce Bellman\nDiffusion, a novel DGM framework that maintains linearity in MDPs through\ngradient and scalar field modeling. With divergence-based training techniques\nto optimize neural network proxies and a new type of stochastic differential\nequation (SDE) for sampling, Bellman Diffusion is guaranteed to converge to the\ntarget distribution. Our empirical results show that Bellman Diffusion achieves\naccurate field estimations and is a capable image generator, converging 1.5x\nfaster than the traditional histogram-based baseline in distributional RL\ntasks. This work enables the effective integration of DGMs into MDP\napplications, unlocking new avenues for advanced decision-making frameworks.",
            "pdf_url": "http://arxiv.org/pdf/2410.01796v1",
            "published": "2024-10-02 17:53:23+00:00",
            "updated": "2024-10-02 17:53:23+00:00"
        },
        {
            "title": "VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models",
            "authors": "Kailai Feng, Yabo Zhang, Haodong Yu, Zhilong Ji, Jinfeng Bai, Hongzhi Zhang, Wangmeng Zuo",
            "summary": "Artistic typography is a technique to visualize the meaning of input\ncharacter in an imaginable and readable manner. With powerful text-to-image\ndiffusion models, existing methods directly design the overall geometry and\ntexture of input character, making it challenging to ensure both creativity and\nlegibility. In this paper, we introduce a dual-branch and training-free method,\nnamely VitaGlyph, enabling flexible artistic typography along with controllable\ngeometry change to maintain the readability. The key insight of VitaGlyph is to\ntreat input character as a scene composed of Subject and Surrounding, followed\nby rendering them under varying degrees of geometry transformation. The subject\nflexibly expresses the essential concept of input character, while the\nsurrounding enriches relevant background without altering the shape.\nSpecifically, we implement VitaGlyph through a three-phase framework: (i)\nKnowledge Acquisition leverages large language models to design text\ndescriptions of subject and surrounding. (ii) Regional decomposition detects\nthe part that most matches the subject description and divides input glyph\nimage into subject and surrounding regions. (iii) Typography Stylization\nfirstly refines the structure of subject region via Semantic Typography, and\nthen separately renders the textures of Subject and Surrounding regions through\nControllable Compositional Generation. Experimental results demonstrate that\nVitaGlyph not only achieves better artistry and readability, but also manages\nto depict multiple customize concepts, facilitating more creative and pleasing\nartistic typography generation. Our code will be made publicly at\nhttps://github.com/Carlofkl/VitaGlyph.",
            "pdf_url": "http://arxiv.org/pdf/2410.01738v1",
            "published": "2024-10-02 16:48:47+00:00",
            "updated": "2024-10-02 16:48:47+00:00"
        },
        {
            "title": "Latent Diffusion Models for Controllable RNA Sequence Generation",
            "authors": "Kaixuan Huang, Yukang Yang, Kaidi Fu, Yanyi Chu, Le Cong, Mengdi Wang",
            "summary": "This work presents RNAdiffusion, a latent diffusion model for generating and\noptimizing discrete RNA sequences of variable lengths. RNA is a key\nintermediary between DNA and protein, exhibiting high sequence diversity and\ncomplex three-dimensional structures to support a wide range of functions. We\nutilize pretrained BERT-type models to encode raw RNA sequences into\ntoken-level, biologically meaningful representations. A Query Transformer is\nemployed to compress such representations into a set of fixed-length latent\nvectors, with an autoregressive decoder trained to reconstruct RNA sequences\nfrom these latent variables. We then develop a continuous diffusion model\nwithin this latent space. To enable optimization, we integrate the gradients of\nreward models--surrogates for RNA functional properties--into the backward\ndiffusion process, thereby generating RNAs with high reward scores. Empirical\nresults confirm that RNAdiffusion generates non-coding RNAs that align with\nnatural distributions across various biological metrics. Further, we fine-tune\nthe diffusion model on mRNA 5' untranslated regions (5'-UTRs) and optimize\nsequences for high translation efficiencies. Our guided diffusion model\neffectively generates diverse 5'-UTRs with high Mean Ribosome Loading (MRL) and\nTranslation Efficiency (TE), outperforming baselines in balancing rewards and\nstructural stability trade-off. Our findings hold potential for advancing RNA\nsequence-function research and therapeutic RNA design.",
            "pdf_url": "http://arxiv.org/pdf/2409.09828v2",
            "published": "2024-09-15 19:04:50+00:00",
            "updated": "2024-10-02 16:42:46+00:00"
        },
        {
            "title": "Data Extrapolation for Text-to-image Generation on Small Datasets",
            "authors": "Senmao Ye, Fei Liu",
            "summary": "Text-to-image generation requires large amount of training data to\nsynthesizing high-quality images. For augmenting training data, previous\nmethods rely on data interpolations like cropping, flipping, and mixing up,\nwhich fail to introduce new information and yield only marginal improvements.\nIn this paper, we propose a new data augmentation method for text-to-image\ngeneration using linear extrapolation. Specifically, we apply linear\nextrapolation only on text feature, and new image data are retrieved from the\ninternet by search engines. For the reliability of new text-image pairs, we\ndesign two outlier detectors to purify retrieved images. Based on\nextrapolation, we construct training samples dozens of times larger than the\noriginal dataset, resulting in a significant improvement in text-to-image\nperformance. Moreover, we propose a NULL-guidance to refine score estimation,\nand apply recurrent affine transformation to fuse text information. Our model\nachieves FID scores of 7.91, 9.52 and 5.00 on the CUB, Oxford and COCO\ndatasets. The code and data will be available on GitHub\n(https://github.com/senmaoy/RAT-Diffusion).",
            "pdf_url": "http://arxiv.org/pdf/2410.01638v1",
            "published": "2024-10-02 15:08:47+00:00",
            "updated": "2024-10-02 15:08:47+00:00"
        }
    ]
}