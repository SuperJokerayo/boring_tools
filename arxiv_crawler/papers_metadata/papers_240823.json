{
    "Physics": [
        {
            "title": "Local ergotropy and its fluctuations across a dissipative quantum phase transition",
            "authors": "G. Di Bello, D. Farina, D. Jansen, C. A. Perroni, V. Cataudella, G. De Filippis",
            "summary": "We investigate a two-qubit open Rabi model, focusing on local ergotropy--the\nmaximum extractable work by acting solely on the two qubits--within a parameter\nregime where a Berezinskii-Kosterlitz-Thouless dissipative phase transition\noccurs. First, we aim to define a protocol for charging, storing, and\ndischarging the two-qubit system, interpreted as the working principle of an\nopen quantum battery. Second, we examine the impact of the phase transition on\nergotropy and identify potential markers. To achieve these goals, we construct\nan ad-hoc charging unitary operator, leveraging our knowledge of the ground\nstate near the transition to bring it into a decoherence-free state during\nstorage. Using state-of-the-art numerics based on matrix product state\nrepresentation, we reveal that high couplings to an external bath approximately\ndouble the local ergotropy immediately post-charging. Over time we observe\noscillatory behaviors in ergotropy and its fluctuations, which undergo\nsignificant changes near the transition, signaling its occurrence. Furthermore,\nwe optimize local ergotropy over time using a physically inspired ansatz,\nenabling work extraction at a generic time (local ergotropy never reaches\nzero). Our work proposes a tunable, experimentally realizable protocol for work\nextraction, leveraging decoherence-free states and phase transitions.\nAdditionally, it sheds light on the complex interaction between local ergotropy\nand quantum phase transitions.",
            "pdf_url": "http://arxiv.org/pdf/2408.02655v3",
            "published": "2024-08-05 17:40:43+00:00",
            "updated": "2024-08-22 17:35:26+00:00"
        },
        {
            "title": "A Short Introduction to Quantum Computing for Physicists",
            "authors": "Oswaldo Zapata",
            "summary": "These notes provide an introduction to standard topics on quantum computation\nand communication for those who already have a basic knowledge of quantum\nmechanics. The main target audience are professional physicists as well as\nadvanced students of physics; however, engineers and computer scientists may\nalso benefit from them.",
            "pdf_url": "http://arxiv.org/pdf/2306.09388v2",
            "published": "2023-06-15 15:33:42+00:00",
            "updated": "2024-08-22 17:33:50+00:00"
        },
        {
            "title": "Climate Bistability at the Inner Edge of the Habitable Zone due to Runaway Greenhouse and Cloud Feedbacks",
            "authors": "Bowen Fan, Da Yang, Dorian S. Abbot",
            "summary": "Understanding the climate dynamics at the inner edge of the habitable zone\n(HZ) is crucial for predicting the habitability of rocky exoplanets. Previous\nstudies using Global Climate Models (GCMs) have indicated that planets\nreceiving high stellar flux can exhibit climate bifurcations, leading to\nbistability between a cold (temperate) and a hot (runaway) climate. However,\nthe mechanism causing this bistability has not been fully explained, in part\ndue to the difficulty associated with inferring mechanisms from small numbers\nof expensive numerical simulations in GCMs. In this study, we employ a\ntwo-column (dayside and nightside), two-layer climate model to investigate the\nphysical mechanisms driving this bistability. Through mechanism-denial\nexperiments, we demonstrate that the runaway greenhouse effect, coupled with a\ncloud feedback on either the dayside or nightside, leads to climate\nbistability. We also map out the parameters that control the location of the\nbifurcations and size of the bistability. This work identifies which mechanisms\nand GCM parameters control the stellar flux at which rocky planets are likely\nto retain a hot, thick atmosphere if they experience a hot start. This is\ncritical for the prioritization of targets and interpretation of observations\nby the James Webb Space Telescope (JWST). Furthermore, our modeling framework\ncan be extended to planets with different condensable species and cloud types.",
            "pdf_url": "http://arxiv.org/pdf/2408.12563v1",
            "published": "2024-08-22 17:25:59+00:00",
            "updated": "2024-08-22 17:25:59+00:00"
        },
        {
            "title": "Hybrid branes from split kinks",
            "authors": "D. Bazeia, A. S. Lob\u00e3o, M. A. Marques",
            "summary": "In this work, we investigate braneworld models generated by scalar fields in\nwhich one field has a split kink profile, in which a kink separates into two\nkinklike configurations. Our analysis covers models with two and three fields,\nexamining the behavior of the most important quantities associated with the\nbrane, such as the warp factor and the stability of the corresponding gravity\nsector. The results show that the brane is stable and supports a hybrid\ncharacter, behaving as a thin and thick configuration.",
            "pdf_url": "http://arxiv.org/pdf/2408.12562v1",
            "published": "2024-08-22 17:24:12+00:00",
            "updated": "2024-08-22 17:24:12+00:00"
        },
        {
            "title": "Time arrow without past hypothesis: a toy model explanation",
            "authors": "Pablo Arrighi, Gilles Dowek, Am\u00e9lia Durbec",
            "summary": "The laws of Physics are time-reversible, making no qualitative distinction\nbetween the past and the future -- yet we can only go towards the future. This\napparent contradiction is known as the \"arrow of time problem\". Its current\nresolution states that the future is the direction of increasing entropy. But\nentropy can only increase towards the future if it was low in the past, and\npast low entropy is a very strong assumption to make, because low entropy\nstates are rather improbable, non-generic. Recent works from the Physics\nliterature suggest, however, we may do away with this so-called \"past\nhypothesis\", in the presence of reversible dynamical laws featuring expansion.\nWe prove that this can be the case in principle, within a toy model. It\nconsists in graphs upon which particles circulate and interact according to\nlocal reversible rules. Some rules locally shrink or expand the graph. We prove\nthat almost all states expand; entropy always increases as a consequence of\nexpansion -- thereby providing a local explanation for the rise of an entropic\narrow of time without the need for a past hypothesis. The discrete setting of\nthis toy model allows us to deploy the full rigour of theoretical Computer\nScience proof techniques. It also allows for the numerical exploration of\nseveral physically-motivated variants: a time-symmetric variant; two\ninflationary variants; and a damping variant -- which slows down thermal death.\nThe fact that all of these models exhibit similar behaviours suggests that\nlocal reversible expansion mechanisms constitute a robust recipe for a time\narrow without past hypothesis. In this qualitative sense, the explanation may\ntherefore also be relevant at the cosmological level.",
            "pdf_url": "http://arxiv.org/pdf/2306.07121v2",
            "published": "2023-06-12 13:54:58+00:00",
            "updated": "2024-08-22 17:10:33+00:00"
        },
        {
            "title": "Dynamics of Meta-learning Representation in the Teacher-student Scenario",
            "authors": "Hui Wang, Cho Tung Yip, Bo Li",
            "summary": "Gradient-based meta-learning algorithms have gained popularity for their\nability to train models on new tasks using limited data. Empirical observations\nindicate that such algorithms are able to learn a shared representation across\ntasks, which is regarded as a key factor in their success. However, the\nin-depth theoretical understanding of the learning dynamics and the origin of\nthe shared representation remains underdeveloped. In this work, we investigate\nthe meta-learning dynamics of the non-linear two-layer neural networks trained\non streaming tasks in the teach-student scenario. Through the lens of\nstatistical physics analysis, we characterize the macroscopic behavior of the\nmeta-training processes, the formation of the shared representation, and the\ngeneralization ability of the model on new tasks. The analysis also points to\nthe importance of the choice of certain hyper-parameters of the learning\nalgorithms.",
            "pdf_url": "http://arxiv.org/pdf/2408.12545v1",
            "published": "2024-08-22 16:59:32+00:00",
            "updated": "2024-08-22 16:59:32+00:00"
        },
        {
            "title": "Approximating the eigenvalues of self-adjoint trace-class operators",
            "authors": "Rich\u00e1rd Balka, G\u00e1bor Homa, Andr\u00e1s Csord\u00e1s",
            "summary": "Spectral properties of bounded linear operators play a crucial role in\nseveral areas of mathematics and physics. For each self-adjoint, trace-class\noperator $O$ we define a set $\\Lambda_n\\subset \\mathbb{R}$, and we show that it\nconverges to the spectrum of $O$ in the Hausdorff metric under mild conditions.\nOur set $\\Lambda_n$ only depends on the first $n$ moments of $O$. We show that\nit can be effectively calculated for physically relevant operators, and it\napproximates the spectrum well.\n  We prove that using the above method we can converge to the minimal and\nmaximal eigenvalues with super-exponential speed.\n  We also construct monotone increasing lower bounds $q_n$ for the minimal\neigenvalue (or decreasing upper bounds for the maximal eigenvalue). This\nsequence only depends on the moments of $O$ and a concrete upper estimate of\nits $1$-norm; we also demonstrate that $q_n$ can be effectively calculated for\na large class of physically relevant operators. This rigorous lower bound $q_n$\ntends to the minimal eigenvalue with super-exponential speed provided that $O$\nis not positive semidefinite. As a by-product, we obtain computable upper\nbounds for the $1$-norm of $O$, too.",
            "pdf_url": "http://arxiv.org/pdf/2407.04478v2",
            "published": "2024-07-05 12:56:20+00:00",
            "updated": "2024-08-22 16:50:49+00:00"
        },
        {
            "title": "Neural interval-censored survival regression with feature selection",
            "authors": "Carlos Garc\u00eda Meixide, Marcos Matabuena, Louis Abraham, Michael R. Kosorok",
            "summary": "Survival analysis is a fundamental area of focus in biomedical research,\nparticularly in the context of personalized medicine. This prominence is due to\nthe increasing prevalence of large and high-dimensional datasets, such as omics\nand medical image data. However, the literature on non-linear regression\nalgorithms and variable selection techniques for interval-censoring is either\nlimited or non-existent, particularly in the context of neural networks. Our\nobjective is to introduce a novel predictive framework tailored for\ninterval-censored regression tasks, rooted in Accelerated Failure Time (AFT)\nmodels. Our strategy comprises two key components: i) a variable selection\nphase leveraging recent advances on sparse neural network architectures, ii) a\nregression model targeting prediction of the interval-censored response. To\nassess the performance of our novel algorithm, we conducted a comprehensive\nevaluation through both numerical experiments and real-world applications that\nencompass scenarios related to diabetes and physical activity. Our results\noutperform traditional AFT algorithms, particularly in scenarios featuring\nnon-linear relationships.",
            "pdf_url": "http://arxiv.org/pdf/2206.06885v3",
            "published": "2022-06-14 14:40:10+00:00",
            "updated": "2024-08-22 16:48:12+00:00"
        },
        {
            "title": "$\u03c4$SPECT: A spin-flip loaded magnetic ultracold neutron trap for a determination of the neutron lifetime",
            "authors": "J. Auler, M. Engler, K. Franz, J. Kahlenberg, J. Karch, N. Pfeifer, K. Ro\u00df, C. -F. Strid, N. Yazdandoost, E. Adamek, S. Kaufmann, Ch. Schmidt, P. Bl\u00fcmler, M. Fertl, W. Heil, D. Ries",
            "summary": "The confinement of ultracold neutrons (UCNs) in a three dimensional magnetic\nfield gradient trap allows for a measurement of the free neutron lifetime with\nsuperior control over spurious loss channels and can provide a large kinetic\nenergy acceptance to enhance statistical sensitivity. In this paper, we present\nthe first successful implementation of a pulsed spin-flip based loading scheme\nfor a three-dimensional magnetic UCN trap. The measurements with the\n$\\tau$SPECT experiment were performed at the pulsed UCN source of the research\nreactor TRIGA Mainz. We report on detailed investigations of major systematic\neffects influencing the neutron storage time, statistically limited by the size\nof the recorded data set. The extracted neutron storage time constant of $\\tau\n= 859(16)\\mathrm{s}$ is compatible with, but not to be interpreted as, a\nmeasurement of the free neutron lifetime.",
            "pdf_url": "http://arxiv.org/pdf/2311.00712v2",
            "published": "2023-10-25 07:48:44+00:00",
            "updated": "2024-08-22 16:26:25+00:00"
        },
        {
            "title": "UV Completion of Neutral Triple Gauge Couplings",
            "authors": "John Ellis, Hong-Jian He, Rui-Qing Xiao, Shi-Ping Zeng, Jiaming Zheng",
            "summary": "Neutral triple gauge couplings (nTGCs) are manifestation of new physics\nbeyond the Standard Model (SM), as they are absent in the SM and are first\ngenerated by dimension-8 operators in the SM Effective Field Theory (SMEFT). We\nstudy the UV completion of nTGCs in a renormalizable model with vector-like\nheavy fermions. We compute the one-loop heavy fermion contributions to nTGC\nvertices by matching them to dimension-8 operators in the low energy limit.\nSuch fermion loops contain either heavy fermions only or mixture of heavy\nfermions with light SM fermions. We find that their contributions can induce\ndimension-8 nTGC effective operators containing two SM Higgs-doublet fields,\nwhich are formulated with a complete set of 7 dimension-8 operators generating\noff-shell CP-even nTGCs. We present the results in terms of SMEFT coefficients\nand in terms of nTGC vertices (form factors) with two on-shell gauge bosons. In\nthe heavy-light mixing case there appear terms that cannot be accommodated by\nconventional parametrizations of form factors due to extra logarithmic\ncorrections. We further discuss the implications for probing such UV dynamics\nvia nTGCs at the high energy colliders.",
            "pdf_url": "http://arxiv.org/pdf/2408.12508v1",
            "published": "2024-08-22 16:07:08+00:00",
            "updated": "2024-08-22 16:07:08+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations",
            "authors": "Can Qin, Congying Xia, Krithika Ramakrishnan, Michael Ryoo, Lifu Tu, Yihao Feng, Manli Shu, Honglu Zhou, Anas Awadalla, Jun Wang, Senthil Purushwalkam, Le Xue, Yingbo Zhou, Huan Wang, Silvio Savarese, Juan Carlos Niebles, Zeyuan Chen, Ran Xu, Caiming Xiong",
            "summary": "We present xGen-VideoSyn-1, a text-to-video (T2V) generation model capable of\nproducing realistic scenes from textual descriptions. Building on recent\nadvancements, such as OpenAI's Sora, we explore the latent diffusion model\n(LDM) architecture and introduce a video variational autoencoder (VidVAE).\nVidVAE compresses video data both spatially and temporally, significantly\nreducing the length of visual tokens and the computational demands associated\nwith generating long-sequence videos. To further address the computational\ncosts, we propose a divide-and-merge strategy that maintains temporal\nconsistency across video segments. Our Diffusion Transformer (DiT) model\nincorporates spatial and temporal self-attention layers, enabling robust\ngeneralization across different timeframes and aspect ratios. We have devised a\ndata processing pipeline from the very beginning and collected over 13M\nhigh-quality video-text pairs. The pipeline includes multiple steps such as\nclipping, text detection, motion estimation, aesthetics scoring, and dense\ncaptioning based on our in-house video-LLM model. Training the VidVAE and DiT\nmodels required approximately 40 and 642 H100 days, respectively. Our model\nsupports over 14-second 720p video generation in an end-to-end way and\ndemonstrates competitive performance against state-of-the-art T2V models.",
            "pdf_url": "http://arxiv.org/pdf/2408.12590v1",
            "published": "2024-08-22 17:55:22+00:00",
            "updated": "2024-08-22 17:55:22+00:00"
        },
        {
            "title": "ssProp: Energy-Efficient Training for Convolutional Neural Networks with Scheduled Sparse Back Propagation",
            "authors": "Lujia Zhong, Shuo Huang, Yonggang Shi",
            "summary": "Recently, deep learning has made remarkable strides, especially with\ngenerative modeling, such as large language models and probabilistic diffusion\nmodels. However, training these models often involves significant computational\nresources, requiring billions of petaFLOPs. This high resource consumption\nresults in substantial energy usage and a large carbon footprint, raising\ncritical environmental concerns. Back-propagation (BP) is a major source of\ncomputational expense during training deep learning models. To advance research\non energy-efficient training and allow for sparse learning on any machine and\ndevice, we propose a general, energy-efficient convolution module that can be\nseamlessly integrated into any deep learning architecture. Specifically, we\nintroduce channel-wise sparsity with additional gradient selection schedulers\nduring backward based on the assumption that BP is often dense and inefficient,\nwhich can lead to over-fitting and high computational consumption. Our\nexperiments demonstrate that our approach reduces 40\\% computations while\npotentially improving model performance, validated on image classification and\ngeneration tasks. This reduction can lead to significant energy savings and a\nlower carbon footprint during the research and development phases of\nlarge-scale AI systems. Additionally, our method mitigates over-fitting in a\nmanner distinct from Dropout, allowing it to be combined with Dropout to\nfurther enhance model performance and reduce computational resource usage.\nExtensive experiments validate that our method generalizes to a variety of\ndatasets and tasks and is compatible with a wide range of deep learning\narchitectures and modules. Code is publicly available at\nhttps://github.com/lujiazho/ssProp.",
            "pdf_url": "http://arxiv.org/pdf/2408.12561v1",
            "published": "2024-08-22 17:22:59+00:00",
            "updated": "2024-08-22 17:22:59+00:00"
        },
        {
            "title": "Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion Models",
            "authors": "Jiang Hao, Xiao Jin, Hu Xiaoguang, Chen Tianyou, Zhao Jiajia",
            "summary": "Diffusion models (DMs) are regarded as one of the most advanced generative\nmodels today, yet recent studies suggest that they are vulnerable to backdoor\nattacks, which establish hidden associations between particular input patterns\nand model behaviors, compromising model integrity by causing undesirable\nactions with manipulated inputs. This vulnerability poses substantial risks,\nincluding reputational damage to model owners and the dissemination of harmful\ncontent. To mitigate the threat of backdoor attacks, there have been some\ninvestigations on backdoor detection and model repair. However, previous work\nfails to reliably purify the models backdoored by state-of-the-art attack\nmethods, rendering the field much underexplored. To bridge this gap, we\nintroduce Diff-Cleanse, a novel two-stage backdoor defense framework\nspecifically designed for DMs. The first stage employs a novel trigger\ninversion technique to reconstruct the trigger and detect the backdoor, and the\nsecond stage utilizes a structural pruning method to eliminate the backdoor. We\nevaluate our framework on hundreds of DMs that are attacked by three existing\nbackdoor attack methods with a wide range of hyperparameter settings. Extensive\nexperiments demonstrate that Diff-Cleanse achieves nearly 100\\% detection\naccuracy and effectively mitigates backdoor impacts, preserving the model's\nbenign performance with minimal compromise. Our code is avaliable at\nhttps://github.com/shymuel/diff-cleanse.",
            "pdf_url": "http://arxiv.org/pdf/2407.21316v2",
            "published": "2024-07-31 03:54:41+00:00",
            "updated": "2024-08-22 14:46:40+00:00"
        },
        {
            "title": "4D Diffusion for Dynamic Protein Structure Prediction with Reference Guided Motion Alignment",
            "authors": "Kaihui Cheng, Ce Liu, Qingkun Su, Jun Wang, Liwei Zhang, Yining Tang, Yao Yao, Siyu Zhu, Yuan Qi",
            "summary": "Protein structure prediction is pivotal for understanding the\nstructure-function relationship of proteins, advancing biological research, and\nfacilitating pharmaceutical development and experimental design. While deep\nlearning methods and the expanded availability of experimental 3D protein\nstructures have accelerated structure prediction, the dynamic nature of protein\nstructures has received limited attention. This study introduces an innovative\n4D diffusion model incorporating molecular dynamics (MD) simulation data to\nlearn dynamic protein structures. Our approach is distinguished by the\nfollowing components: (1) a unified diffusion model capable of generating\ndynamic protein structures, including both the backbone and side chains,\nutilizing atomic grouping and side-chain dihedral angle predictions; (2) a\nreference network that enhances structural consistency by integrating the\nlatent embeddings of the initial 3D protein structures; and (3) a motion\nalignment module aimed at improving temporal structural coherence across\nmultiple time steps. To our knowledge, this is the first diffusion-based model\naimed at predicting protein trajectories across multiple time steps\nsimultaneously. Validation on benchmark datasets demonstrates that our model\nexhibits high accuracy in predicting dynamic 3D structures of proteins\ncontaining up to 256 amino acids over 32 time steps, effectively capturing both\nlocal flexibility in stable states and significant conformational changes.",
            "pdf_url": "http://arxiv.org/pdf/2408.12419v1",
            "published": "2024-08-22 14:12:50+00:00",
            "updated": "2024-08-22 14:12:50+00:00"
        },
        {
            "title": "CODE: Confident Ordinary Differential Editing",
            "authors": "Bastien van Delft, Tommaso Martorella, Alexandre Alahi",
            "summary": "Conditioning image generation facilitates seamless editing and the creation\nof photorealistic images. However, conditioning on noisy or Out-of-Distribution\n(OoD) images poses significant challenges, particularly in balancing fidelity\nto the input and realism of the output. We introduce Confident Ordinary\nDifferential Editing (CODE), a novel approach for image synthesis that\neffectively handles OoD guidance images. Utilizing a diffusion model as a\ngenerative prior, CODE enhances images through score-based updates along the\nprobability-flow Ordinary Differential Equation (ODE) trajectory. This method\nrequires no task-specific training, no handcrafted modules, and no assumptions\nregarding the corruptions affecting the conditioning image. Our method is\ncompatible with any diffusion model. Positioned at the intersection of\nconditional image generation and blind image restoration, CODE operates in a\nfully blind manner, relying solely on a pre-trained generative model. Our\nmethod introduces an alternative approach to blind restoration: instead of\ntargeting a specific ground truth image based on assumptions about the\nunderlying corruption, CODE aims to increase the likelihood of the input image\nwhile maintaining fidelity. This results in the most probable in-distribution\nimage around the input. Our contributions are twofold. First, CODE introduces a\nnovel editing method based on ODE, providing enhanced control, realism, and\nfidelity compared to its SDE-based counterpart. Second, we introduce a\nconfidence interval-based clipping method, which improves CODE's effectiveness\nby allowing it to disregard certain pixels or information, thus enhancing the\nrestoration process in a blind manner. Experimental results demonstrate CODE's\neffectiveness over existing methods, particularly in scenarios involving severe\ndegradation or OoD inputs.",
            "pdf_url": "http://arxiv.org/pdf/2408.12418v1",
            "published": "2024-08-22 14:12:20+00:00",
            "updated": "2024-08-22 14:12:20+00:00"
        }
    ]
}