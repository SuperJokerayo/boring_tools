{
    "Physics": [
        {
            "title": "To reset, or not to reset -- that is the question",
            "authors": "Gy\u00f6rgy P. Geh\u00e9r, Marcin Jastrzebski, Earl T. Campbell, Ophelia Crawford",
            "summary": "Whether to reset qubits, or not, during quantum error correction experiments\nis a question of both foundational and practical importance for quantum\ncomputing. Text-book quantum error correction demands that qubits are reset\nafter measurement. However, fast qubit reset has proven challenging to execute\nat high fidelity. Consequently, many cutting-edge quantum error correction\nexperiments are opting for the no-reset approach, where physical reset is not\nperformed. It has recently been postulated that no-reset is functionally\nequivalent to reset procedures, as well as being faster and easier. For memory\nexperiments, we confirm numerically that resetting provides no benefit. On the\nother hand, we identify a remarkable difference during logical operations. We\nfind that unconditionally resetting qubits can reduce the duration of\nfault-tolerant logical operation by up to a factor of two as the number of\nmeasurement errors that can be tolerated is doubled. We support this with\nnumerical simulations. However, our simulations also reveal that the no-reset\nperformance is superior if the reset duration or infidelity exceeds a given\nthreshold. Lastly, we introduce two novel syndrome extraction circuits that can\nreduce the time overhead of no-reset approaches. Our findings provide guidance\non how experimentalists should design future experiments.",
            "pdf_url": "http://arxiv.org/pdf/2408.00758v1",
            "published": "2024-08-01 17:57:56+00:00",
            "updated": "2024-08-01 17:57:56+00:00"
        },
        {
            "title": "Thermal Conductivity Predictions with Foundation Atomistic Models",
            "authors": "Bal\u00e1zs P\u00f3ta, Paramvir Ahlawat, G\u00e1bor Cs\u00e1nyi, Michele Simoncelli",
            "summary": "Recent advances in machine learning have led to foundation models for\natomistic materials chemistry, potentially enabling quantum-accurate\ndescriptions of interatomic forces at reduced computational cost. These models\nare benchmarked by predicting materials' properties over large databases;\nhowever, these computationally intensive tests have been limited to basic\nquantities related to harmonic phonons, leaving uncertainty about the\nreliability for complex, technologically and experimentally relevant anharmonic\nheat-conduction properties. Here we present an automated framework that relies\non foundation models to compute microscopic vibrational properties, and employs\nthem within the Wigner formulation of heat transport to predict the macroscopic\nthermal conductivity in solids with arbitrary composition and structure. We\napply this framework with the foundation models M3GNet, CHGNet, MACE-MP-0, and\nSevenNET to 103 diverse compounds, comparing predictions against\nfirst-principles references and introducing a benchmark metric based on\nconductivity. This framework paves the way for physics-aware, accurate\npredictions of vibrational and thermal properties, and for uncovering materials\nthat violate semiclassical Boltzmann transport and feature exceptional\nheat-shielding or thermoelectric performance.",
            "pdf_url": "http://arxiv.org/pdf/2408.00755v1",
            "published": "2024-08-01 17:57:24+00:00",
            "updated": "2024-08-01 17:57:24+00:00"
        },
        {
            "title": "The Inevitable Quark Three-Body Force and its Implications for Exotic States",
            "authors": "Sungsik Noh, Aaron Park, Hyeongock Yun, Sungtae Cho, Su Houng Lee",
            "summary": "Three-body nuclear forces are essential for explaining the properties of\nlight nuclei with a nucleon number greater than three. Building on insights\nfrom nuclear physics, we extract the form of quark three-body interactions and\ndemonstrate that these terms are crucial for extending the quark model fit of\nthe meson spectrum to include baryons using the same parameter set. We then\ndiscuss the implications of our findings for exotic configurations involving\nmore than three quarks, such as the $T_{cc}$ and $\\chi_{c1}(3872)$. We find\nthat the quark three-body interactions provide additional repulsion on the\norder of 10 MeV for the compact configurations of both the $T_{cc}$ and\n$\\chi_{c1}(3872)$. This result, combined with previous calculations, strongly\nsuggests that these tetraquark states are molecular rather than compact states.",
            "pdf_url": "http://arxiv.org/pdf/2408.00715v1",
            "published": "2024-08-01 17:00:35+00:00",
            "updated": "2024-08-01 17:00:35+00:00"
        },
        {
            "title": "Attosecond Probing of Coherent Vibrational Dynamics in CBr$_4$",
            "authors": "Jen-Hao Ou, Diptarka Hait, Patrick Rupprecht, John E. Beetar, Todd J. Mart\u00ednez, Stephen R. Leone",
            "summary": "A coherent vibrational wavepacket is launched and manipulated in the\nsymmetric stretch (a$_1$) mode of CBr$_4$, by impulsive stimulated Raman\nscattering from non-resonant 400 nm laser pump pulses with various peak\nintensities on the order of tens of 10$^{12}$ W/cm$^2$. Extreme ultraviolet\n(XUV) attosecond transient absorption spectroscopy (ATAS) records the\nwavepacket dynamics as temporal oscillations in XUV absorption energy at the\nbromine M$_{4,5}$ 3d$_{3/2,5/2}$ edges around 70 eV. The results are augmented\nby nuclear time-dependent Schr\\\"odinger equation simulations. Slopes of the\n(Br-3d$_{3/2,5/2}$)$^{-1}$10a$_1^*$ core-excited state potential energy surface\n(PES) along the a$_1$ mode are calculated to be -9.4 eV/{\\AA} from restricted\nopen-shell Kohn-Sham calculations. Using analytical relations derived for the\nsmall-displacement limit with the calculated slopes of the core-excited state\nPES, a deeper insight into the vibrational dynamics is obtained by retrieving\nthe experimental excursion amplitude of the vibrational wavepacket and the\namount of population transferred to the vibrational first-excited state, as a\nfunction of pump-pulse peak intensity. Experimentally, the results show that\nXUV ATAS is capable of easily resolving oscillations in the XUV absorption\nenergy on the order of few to tens of meV and tens of femtosecond time\nprecision, limited only by the averaging times in the experimental scans. This\ncorresponds to oscillations of C-Br bond length on the order of 10$^{-4}$ to\n10$^{-3}$ {\\AA}. The results and the analytic relationships offer a clear\nphysical picture, on multiple levels of understanding, for how the pump-pulse\nintensity controls the vibrational dynamics launched by non-resonant ISRS in\nthe small-displacement limit.",
            "pdf_url": "http://arxiv.org/pdf/2408.00696v1",
            "published": "2024-08-01 16:39:27+00:00",
            "updated": "2024-08-01 16:39:27+00:00"
        },
        {
            "title": "Accelerating Full Waveform Inversion By Transfer Learning",
            "authors": "Divya Shyam Singh, Leon Herrmann, Qing Sun, Tim B\u00fcrchner, Felix Dietrich, Stefan Kollmannsberger",
            "summary": "Full waveform inversion (FWI) is a powerful tool for reconstructing material\nfields based on sparsely measured data obtained by wave propagation. For\nspecific problems, discretizing the material field with a neural network (NN)\nimproves the robustness and reconstruction quality of the corresponding\noptimization problem. We call this method NN-based FWI. Starting from an\ninitial guess, the weights of the NN are iteratively updated to fit the\nsimulated wave signals to the sparsely measured data set. For gradient-based\noptimization, a suitable choice of the initial guess, i.e., a suitable NN\nweight initialization, is crucial for fast and robust convergence.\n  In this paper, we introduce a novel transfer learning approach to further\nimprove NN-based FWI. This approach leverages supervised pretraining to provide\na better NN weight initialization, leading to faster convergence of the\nsubsequent optimization problem. Moreover, the inversions yield physically more\nmeaningful local minima. The network is pretrained to predict the unknown\nmaterial field using the gradient information from the first iteration of\nconventional FWI. In our computational experiments on two-dimensional domains,\nthe training data set consists of reference simulations with arbitrarily\npositioned elliptical voids of different shapes and orientations. We compare\nthe performance of the proposed transfer learning NN-based FWI with three other\nmethods: conventional FWI, NN-based FWI without pretraining and conventional\nFWI with an initial guess predicted from the pretrained NN. Our results show\nthat transfer learning NN-based FWI outperforms the other methods in terms of\nconvergence speed and reconstruction quality.",
            "pdf_url": "http://arxiv.org/pdf/2408.00695v1",
            "published": "2024-08-01 16:39:06+00:00",
            "updated": "2024-08-01 16:39:06+00:00"
        },
        {
            "title": "Subspace-projected multireference covariant density functional theory",
            "authors": "X. Zhang, C. C. Wang, C. R. Ding, J. M. Yao",
            "summary": "Multireference density functional theory (MR-DFT) has been a pivotal method\nfor studying nuclear spectroscopy and neutrinoless double-beta\n($0\\nu\\beta\\beta$) decay. However, quantifying their theoretical uncertainties\nhas been a significant challenge due to the computational demands. This study\nintroduces a subspace-projected covariant density functional theory (SP-CDFT),\nwhich efficiently emulates MR-CDFT calculations for nuclear low-lying states.\nThis approach leverages the eigenvector continuation method combined with the\nquantum-number projected generator coordinate method, based on a relativistic\nenergy density functional (EDF). We apply SP-CDFT to investigate the\ncorrelations among the physical quantities of nuclear matter, nuclear low-lying\nspectroscopy, and the nuclear matrix elements (NMEs) of $0\\nu\\beta\\beta$ decay\nin the two heaviest candidate nuclei. Our findings reveal generally strong\ncorrelations between the NMEs of $0\\nu\\beta\\beta$ decay and the excitation\nenergy of the $2_1^+$ state, as well as the $E2$ transition strength, although\nthese correlations vary significantly among nuclei. The Bayesian analysis,\nwhich integrates the properties of nuclear matter and low-lying states, yields\nmean values and statistical uncertainties for the NMEs 4.33(5) for $^{136}$Xe\nand 5.51(14) for $^{150}$Nd. This work also paves the way for refining nuclear\nEDF parameters using spectroscopic data.",
            "pdf_url": "http://arxiv.org/pdf/2408.00691v1",
            "published": "2024-08-01 16:33:34+00:00",
            "updated": "2024-08-01 16:33:34+00:00"
        },
        {
            "title": "Application of Transformers for Nonlinear Channel Compensation in Optical Systems",
            "authors": "Behnam Behinaein Hamgini, Hossein Najafi, Ali Bakhshali, Zhuhong Zhang",
            "summary": "In this paper, we introduce a new nonlinear optical channel equalizer based\non Transformers. By leveraging parallel computation and attending directly to\nthe memory across a sequence of symbols, we show that Transformers can be used\neffectively for nonlinear compensation (NLC) in coherent long-haul transmission\nsystems. For this application, we present an implementation of the encoder part\nof the Transformer and analyze its performance over a wide range of different\nhyper-parameters. It is shown that by proper embeddings and processing blocks\nof symbols at each iteration and also carefully selecting subsets of the\nencoder's output to be processed together, an efficient nonlinear equalization\ncan be achieved for different complexity constraints. To reduce the\ncomputational complexity of the attention mechanism, we further propose the use\nof a physic-informed mask inspired by nonlinear perturbation theory. We also\ncompare the Transformer-NLC with digital back-propagation (DBP) under different\ntransmission scenarios in order to demonstrate the flexibility and\ngeneralizability of the proposed data-driven solution.",
            "pdf_url": "http://arxiv.org/pdf/2304.13119v3",
            "published": "2023-04-25 19:48:54+00:00",
            "updated": "2024-08-01 15:52:32+00:00"
        },
        {
            "title": "Actor-Critic Physics-informed Neural Lyapunov Control",
            "authors": "Jiarui Wang, Mahyar Fazlyab",
            "summary": "Designing control policies for stabilization tasks with provable guarantees\nis a long-standing problem in nonlinear control. A crucial performance metric\nis the size of the resulting region of attraction, which essentially serves as\na robustness \"margin\" of the closed-loop system against uncertainties. In this\npaper, we propose a new method to train a stabilizing neural network controller\nalong with its corresponding Lyapunov certificate, aiming to maximize the\nresulting region of attraction while respecting the actuation constraints.\nCrucial to our approach is the use of Zubov's Partial Differential Equation\n(PDE), which precisely characterizes the true region of attraction of a given\ncontrol policy. Our framework follows an actor-critic pattern where we\nalternate between improving the control policy (actor) and learning a Zubov\nfunction (critic). Finally, we compute the largest certifiable region of\nattraction by invoking an SMT solver after the training procedure. Our\nnumerical experiments on several design problems show consistent and\nsignificant improvements in the size of the resulting region of attraction.",
            "pdf_url": "http://arxiv.org/pdf/2403.08448v2",
            "published": "2024-03-13 12:03:27+00:00",
            "updated": "2024-08-01 15:16:26+00:00"
        },
        {
            "title": "Graph neural network-based surrogate modelling for real-time hydraulic prediction of urban drainage networks",
            "authors": "Zhiyu Zhang, Chenkaixiang Lu, Wenchong Tian, Zhenliang Liao, Zhiguo Yuan",
            "summary": "Physics-based models are computationally time-consuming and infeasible for\nreal-time scenarios of urban drainage networks, and a surrogate model is needed\nto accelerate the online predictive modelling. Fully-connected neural networks\n(NNs) are potential surrogate models, but may suffer from low interpretability\nand efficiency in fitting complex targets. Owing to the state-of-the-art\nmodelling power of graph neural networks (GNNs) and their match with urban\ndrainage networks in the graph structure, this work proposes a GNN-based\nsurrogate of the flow routing model for the hydraulic prediction problem of\ndrainage networks, which regards recent hydraulic states as initial conditions,\nand future runoff and control policy as boundary conditions. To incorporate\nhydraulic constraints and physical relationships into drainage modelling,\nphysics-guided mechanisms are designed on top of the surrogate model to\nrestrict the prediction variables with flow balance and flooding occurrence\nconstraints. According to case results in a stormwater network, the GNN-based\nmodel is more cost-effective with better hydraulic prediction accuracy than the\nNN-based model after equal training epochs, and the designed mechanisms further\nlimit prediction errors with interpretable domain knowledge. As the model\nstructure adheres to the flow routing mechanisms and hydraulic constraints in\nurban drainage networks, it provides an interpretable and effective solution\nfor data-driven surrogate modelling. Simultaneously, the surrogate model\naccelerates the predictive modelling of urban drainage networks for real-time\nuse compared with the physics-based model.",
            "pdf_url": "http://arxiv.org/pdf/2404.10324v2",
            "published": "2024-04-16 07:08:04+00:00",
            "updated": "2024-08-01 15:10:45+00:00"
        },
        {
            "title": "Distributed quantum architecture search",
            "authors": "Haozhen Situ, Zhimin He, Shenggen Zheng, Lvzhou Li",
            "summary": "Variational quantum algorithms, inspired by neural networks, have become a\nnovel approach in quantum computing. However, designing efficient parameterized\nquantum circuits remains a challenge. Quantum architecture search tackles this\nby adjusting circuit structures along with gate parameters to automatically\ndiscover high-performance circuit structures. In this study, we propose an\nend-to-end distributed quantum architecture search framework, where we aim to\nautomatically design distributed quantum circuit structures for interconnected\nquantum processing units with specific qubit connectivity. We devise a circuit\ngeneration algorithm which incorporates TeleGate and TeleData methods to enable\nnonlocal gate implementation across quantum processing units. While taking into\naccount qubit connectivity, we also incorporate qubit assignment from logical\nto physical qubits within our quantum architecture search framework. A\ntwo-stage progressive training-free strategy is employed to evaluate extensive\ncircuit structures without circuit training costs. Through numerical\nexperiments on three VQE tasks, the efficacy and efficiency of our scheme is\ndemonstrated. Our research into discovering efficient structures for\ndistributed quantum circuits is crucial for near-term quantum computing where a\nsingle quantum processing unit has a limited number of qubits. Distributed\nquantum circuits allow for breaking down complex computations into manageable\nparts that can be processed across multiple quantum processing units.",
            "pdf_url": "http://arxiv.org/pdf/2403.06214v2",
            "published": "2024-03-10 13:28:56+00:00",
            "updated": "2024-08-01 15:08:50+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention",
            "authors": "Susung Hong",
            "summary": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.",
            "pdf_url": "http://arxiv.org/pdf/2408.00760v1",
            "published": "2024-08-01 17:59:09+00:00",
            "updated": "2024-08-01 17:59:09+00:00"
        },
        {
            "title": "TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models",
            "authors": "Gilad Deutch, Rinon Gal, Daniel Garibi, Or Patashnik, Daniel Cohen-Or",
            "summary": "Diffusion models have opened the path to a wide range of text-based image\nediting frameworks. However, these typically build on the multi-step nature of\nthe diffusion backwards process, and adapting them to distilled, fast-sampling\nmethods has proven surprisingly challenging. Here, we focus on a popular line\nof text-based editing frameworks - the ``edit-friendly'' DDPM-noise inversion\napproach. We analyze its application to fast sampling methods and categorize\nits failures into two classes: the appearance of visual artifacts, and\ninsufficient editing strength. We trace the artifacts to mismatched noise\nstatistics between inverted noises and the expected noise schedule, and suggest\na shifted noise schedule which corrects for this offset. To increase editing\nstrength, we propose a pseudo-guidance approach that efficiently increases the\nmagnitude of edits without introducing new artifacts. All in all, our method\nenables text-based image editing with as few as three diffusion steps, while\nproviding novel insights into the mechanisms behind popular text-based editing\napproaches.",
            "pdf_url": "http://arxiv.org/pdf/2408.00735v1",
            "published": "2024-08-01 17:27:28+00:00",
            "updated": "2024-08-01 17:27:28+00:00"
        },
        {
            "title": "Alpha-VI DeepONet: A prior-robust variational Bayesian approach for enhancing DeepONets with uncertainty quantification",
            "authors": "Soban Nasir Lone, Subhayan De, Rajdip Nayek",
            "summary": "We introduce a novel deep operator network (DeepONet) framework that\nincorporates generalised variational inference (GVI) using R\\'enyi's\n$\\alpha$-divergence to learn complex operators while quantifying uncertainty.\nBy incorporating Bayesian neural networks as the building blocks for the branch\nand trunk networks, our framework endows DeepONet with uncertainty\nquantification. The use of R\\'enyi's $\\alpha$-divergence, instead of the\nKullback-Leibler divergence (KLD), commonly used in standard variational\ninference, mitigates issues related to prior misspecification that are\nprevalent in Variational Bayesian DeepONets. This approach offers enhanced\nflexibility and robustness. We demonstrate that modifying the variational\nobjective function yields superior results in terms of minimising the mean\nsquared error and improving the negative log-likelihood on the test set. Our\nframework's efficacy is validated across various mechanical systems, where it\noutperforms both deterministic and standard KLD-based VI DeepONets in\npredictive accuracy and uncertainty quantification. The hyperparameter\n$\\alpha$, which controls the degree of robustness, can be tuned to optimise\nperformance for specific problems. We apply this approach to a range of\nmechanics problems, including gravity pendulum, advection-diffusion, and\ndiffusion-reaction systems. Our findings underscore the potential of\n$\\alpha$-VI DeepONet to advance the field of data-driven operator learning and\nits applications in engineering and scientific domains.",
            "pdf_url": "http://arxiv.org/pdf/2408.00681v1",
            "published": "2024-08-01 16:22:03+00:00",
            "updated": "2024-08-01 16:22:03+00:00"
        },
        {
            "title": "Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model",
            "authors": "Felipe Mahlow, Andr\u00e9 Felipe Zanella, William Alberto Cruz Casta\u00f1eda, Regilene Aparecida Sarzi-Ribeiro",
            "summary": "In recent years, Generative Artificial Intelligence (GenAI) has undergone a\nprofound transformation in addressing intricate tasks involving diverse\nmodalities such as textual, auditory, visual, and pictorial generation. Within\nthis spectrum, text-to-image (TTI) models have emerged as a formidable approach\nto generating varied and aesthetically appealing compositions, spanning\napplications from artistic creation to realistic facial synthesis, and\ndemonstrating significant advancements in computer vision, image processing,\nand multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a\nparadigm shift in the domain of AI capabilities. This article delves into the\nfeasibility of employing the Stable Diffusion LDM to illustrate literary works.\nFor this exploration, seven classic Brazilian books have been selected as case\nstudies. The objective is to ascertain the practicality of this endeavor and to\nevaluate the potential of Stable Diffusion in producing illustrations that\naugment and enrich the reader's experience. We will outline the beneficial\naspects, such as the capacity to generate distinctive and contextually\npertinent images, as well as the drawbacks, including any shortcomings in\nfaithfully capturing the essence of intricate literary depictions. Through this\nstudy, we aim to provide a comprehensive assessment of the viability and\nefficacy of utilizing AI-generated illustrations in literary contexts,\nelucidating both the prospects and challenges encountered in this pioneering\napplication of technology.",
            "pdf_url": "http://arxiv.org/pdf/2408.00544v1",
            "published": "2024-08-01 13:28:15+00:00",
            "updated": "2024-08-01 13:28:15+00:00"
        },
        {
            "title": "A new approach for encoding code and assisting code understanding",
            "authors": "Mengdan Fan, Wei Zhang, Haiyan Zhao, Zhi Jin",
            "summary": "Some companies(e.g., Microsoft Research and Google DeepMind) have discovered\nsome of the limitations of GPTs autoregressive paradigm next-word prediction,\nmanifested in the model lack of planning, working memory, backtracking, and\nreasoning skills. GPTs rely on a local and greedy process of generating the\nnext word, without a global understanding of the task or the output.We have\nconfirmed the above limitations through specialized empirical studies of code\ncomprehension. Although GPT4 is good at producing fluent and coherent text, it\ncannot handle complex logic and generate new code that haven not been seen, and\nit relies too much on the formatting of the prompt to generate the correct\ncode.We propose a new paradigm for code understanding that goes beyond the\nnext-word prediction paradigm, inspired by the successful application of\ndiffusion techniques to image generation(Dalle2, Sora) and protein structure\ngeneration(AlphaFold3), which have no autoregressive constraints.Instead of\nencoding the code in a form that mimics natural language, we encode the code as\na heterogeneous image paradigm with a memory of global information that mimics\nboth images and protein structures.We then refer to Sora's CLIP upstream\ntext-to-image encoder model to design a text-to-code encoder model that can be\napplied to various downstream code understanding tasks.The model learns the\nglobal understanding of code under the new paradigm heterogeneous image,\nconnects the encoding space of text and code, and encodes the input of text\ninto the vector of code most similar to it.Using self-supervised comparative\nlearning on 456,360 text-code pairs, the model achieved a zero-shot prediction\nof new data. This work is the basis for future work on code generation using\ndiffusion techniques under a new paradigm to avoid autoregressive limitations.",
            "pdf_url": "http://arxiv.org/pdf/2408.00521v1",
            "published": "2024-08-01 12:52:48+00:00",
            "updated": "2024-08-01 12:52:48+00:00"
        }
    ]
}