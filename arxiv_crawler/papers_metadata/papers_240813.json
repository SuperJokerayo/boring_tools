{
    "Physics": [
        {
            "title": "Non-Maxwellian Ion Distribution in the Equatorial and Auroral Electrojets",
            "authors": "Rattanakorn Koontaweepunya, Yakov S. Dimant, Meers M. Oppenheim",
            "summary": "Strong electric fields in the auroral and equatorial electrojets can distort\nthe background ion distribution function away from Maxwellian. We developed a\ncollisional plasma kinetic model using the Boltzmann equation and a simple BGK\ncollision operator which predicts a relatively simple relationship between the\nintensity of the background electric field and the resulting ion distribution\nfunction. To test the model, we perform 3-D plasma particle-in-cell simulations\nand compare the results to the model. The simulation applies an elastic\ncollision operator assuming a constant ion-neutral collision rate. These\nsimulations show less ion heating in the Pedersen direction than the analytic\nmodel but show similar overall heating. The model overestimates the heating in\nthe Pedersen direction because the simple BGK operator includes no angular\ncollisional scattering in the ion velocity space. On the other hand, the\nfully-kinetic particle-in-cell code is able to capture the physics of ion\nscattering in 3-D and therefore heats ions more isotropically. Although the\nsimple BGK analytic theory does not precisely model the non-Maxwellian ion\ndistribution function, it does capture the overall momentum and energy flows\nand therefore can provide the basis of further analysis of E-region wave\nevolution.",
            "pdf_url": "http://arxiv.org/pdf/2408.06339v1",
            "published": "2024-08-12 17:54:47+00:00",
            "updated": "2024-08-12 17:54:47+00:00"
        },
        {
            "title": "Nicolai maps for super Yang-Mills on the light cone",
            "authors": "Olaf Lechtenfeld",
            "summary": "We construct Nicolai maps for supersymmetric Yang-Mills theory in four and\nten spacetime dimensions in the light-cone gauge, where the elimination of\nnon-propagating degrees of freedom causes nonlocal and four-fermi interactions\nin the Lagrangian. The presence of the latter used to be an obstruction to the\nNicolai map, which has recently been overcome at the price of quantum\ncorrections to the map. No gauge-fixing or ghost terms arise in this\nformulation, since only physical transverse degrees of freedom occur. We\npresent an explicit form of the Nicolai map to second order in the gauge\ncoupling. In four dimensions, a `chiral' choice of the map leaves one of the\ntwo transverse gauge-field modes invariant, which forces the classical part of\nthe map (on the other mode) to become a polynomial (quadratic in the gauge\ncoupling, cubic in the gauge field)! In the power series expansion for the\nten-dimensional map however, cancellations at each order in the coupling are\nsystematic but incomplete, still leaving an infinite power series for the\nNicolai map (on all eight transverse modes). Nevertheless, the existence of a\npolynomial variant is conceivable, also for the maximal ${\\cal N}{=}\\,4$ theory\nin four dimensions.",
            "pdf_url": "http://arxiv.org/pdf/2406.04406v2",
            "published": "2024-06-06 18:00:05+00:00",
            "updated": "2024-08-12 17:41:52+00:00"
        },
        {
            "title": "Dynamical resource theory of incompatibility preservability",
            "authors": "Chung-Yun Hsieh, Benjamin Stratton, Chao-Hsien Wu, Huan-Yu Ku",
            "summary": "The uncertainty principle is one of quantum theory's most foundational\nfeatures. It underpins a quantum phenomenon called measurement incompatibility\n-- two physical observables of a single quantum system may not always be\nmeasured simultaneously. Apart from being fundamentally important, measurement\nincompatibility is also a powerful resource in the broad quantum science and\ntechnologies, with wide applications to cryptography, communication, random\nnumber generation, and device-independent tasks. Since every physical system is\nunavoidably subject to noise, an important, yet still open, question is how to\ncharacterise the ability of noisy quantum dynamics to preserve measurement\nincompatibility. This work fills this gap by providing the first resource\ntheory of this ability, termed incompatibility preservability. We quantify\nincompatibility preservability by a robustness measure. Then, we introduce an\noperational task, entanglement-assisted filter game, to completely characterise\nboth the robustness measure and the conversion of incompatibility\npreservability. Our results provide a general framework to describe how noisy\ndynamics affect the uncertainty principle's signature.",
            "pdf_url": "http://arxiv.org/pdf/2408.06315v1",
            "published": "2024-08-12 17:28:45+00:00",
            "updated": "2024-08-12 17:28:45+00:00"
        },
        {
            "title": "Inverse designing metamaterials with programmable nonlinear functional responses in graph space",
            "authors": "Marco Maurizi, Derek Xu, Yu-Tong Wang, Desheng Yao, David Hahn, Mourad Oudich, Anish Satpati, Mathieu Bauchy, Wei Wang, Yizhou Sun, Yun Jing, Xiaoyu Rayne Zheng",
            "summary": "Material responses to static and dynamic stimuli, represented as nonlinear\ncurves, are design targets for engineering functionalities like structural\nsupport, impact protection, and acoustic and photonic bandgaps.\nThree-dimensional metamaterials offer significant tunability due to their\ninternal structure, yet existing methods struggle to capture their complex\nbehavior-to-structure relationships. We present GraphMetaMat, a graph-based\nframework capable of designing three-dimensional metamaterials with\nprogrammable responses and arbitrary manufacturing constraints. Integrating\ngraph networks, physics biases, reinforcement learning, and tree search,\nGraphMetaMat can target stress-strain curves spanning four orders of magnitude\nand complex behaviors, as well as viscoelastic transmission responses with\nvarying attenuation gaps. GraphMetaMat can create cushioning materials for\nprotective equipment and vibration-damping panels for electric vehicles,\noutperforming commercial materials, and enabling the automatic design of\nmaterials with on-demand functionalities.",
            "pdf_url": "http://arxiv.org/pdf/2408.06300v1",
            "published": "2024-08-12 17:09:28+00:00",
            "updated": "2024-08-12 17:09:28+00:00"
        },
        {
            "title": "Stabilizer Entanglement Distillation and Efficient Fault-Tolerant Encoder",
            "authors": "Yu Shi, Ashlesha Patil, Saikat Guha",
            "summary": "Entanglement is essential for quantum information processing but is limited\nby noise. We address this by developing high-yield entanglement distillation\nprotocols with several advancements. (1) We extend the 2-to-1 recurrence\nentanglement distillation protocol to higher-rate n-to-(n-1) protocols that can\ncorrect any single-qubit errors. These protocols are evaluated through\nnumerical simulations focusing on fidelity and yield. We also outline a method\nto adapt any classical error-correcting code for entanglement distillation,\nwhere the code can correct both bit-flip and phase-flip errors by incorporating\nHadamard gates. (2) We propose a constant-depth decoder for stabilizer codes\nthat transforms logical states into physical ones using single-qubit\nmeasurements. This decoder is applied to entanglement distillation protocols,\nreducing circuit depth and enabling protocols derived from advanced quantum\nerror-correcting codes. We demonstrate this by evaluating the circuit\ncomplexity for entanglement distillation protocols based on surface codes and\nquantum convolutional codes. (3) Our stabilizer entanglement distillation\ntechniques advance quantum computing. We propose a fault-tolerant protocol for\nconstant-depth encoding and decoding of arbitrary quantum states, applicable to\nquantum low-density parity-check (qLDPC) codes and surface codes. This protocol\nis feasible with state-of-the-art reconfigurable atom arrays and surpasses the\nlimits of conventional logarithmic depth encoders. Overall, our study\nintegrates stabilizer formalism, measurement-based quantum computing, and\nentanglement distillation, advancing both quantum communication and computing.",
            "pdf_url": "http://arxiv.org/pdf/2408.06299v1",
            "published": "2024-08-12 17:09:24+00:00",
            "updated": "2024-08-12 17:09:24+00:00"
        },
        {
            "title": "Adjoint-Based Enforcement of State Constraints in PDE Optimization Problems",
            "authors": "Pritpal Matharu, Bartosz Protas",
            "summary": "This study demonstrates how the adjoint-based framework traditionally used to\ncompute gradients in PDE optimization problems can be extended to handle\ngeneral constraints on the state variables. This is accomplished by\nconstructing a projection of the gradient of the objective functional onto a\nsubspace tangent to the manifold defined by the constraint. This projection is\nrealized by solving an adjoint problem defined in terms of the same adjoint\noperator as used in the system employed to determine the gradient, but with a\ndifferent forcing. We focus on the \"optimize-then-discretize\" paradigm in the\ninfinite-dimensional setting where the required regularity of both the gradient\nand of the projection is ensured. The proposed approach is illustrated with two\nexamples: a simple test problem describing optimization of heat transfer in one\ndirection and a more involved problem where an optimal closure is found for a\nturbulent flow described by the Navier-Stokes system in two dimensions, both\nconsidered subject to different state constraints. The accuracy of the\ngradients and projections computed by solving suitable adjoint systems is\ncarefully verified and the presented computational results show that the\nsolutions of the optimization problems obtained with the proposed approach\nsatisfy the state constraints with a good accuracy, although not exactly.",
            "pdf_url": "http://arxiv.org/pdf/2312.01929v2",
            "published": "2023-12-04 14:38:40+00:00",
            "updated": "2024-08-12 16:51:09+00:00"
        },
        {
            "title": "DUNE: A Machine Learning Deep UNet++ based Ensemble Approach to Monthly, Seasonal and Annual Climate Forecasting",
            "authors": "Pratik Shukla, Milton Halem",
            "summary": "Capitalizing on the recent availability of ERA5 monthly averaged long-term\ndata records of mean atmospheric and climate fields based on high-resolution\nreanalysis, deep-learning architectures offer an alternative to physics-based\ndaily numerical weather predictions for subseasonal to seasonal (S2S) and\nannual means. A novel Deep UNet++-based Ensemble (DUNE) neural architecture is\nintroduced, employing multi-encoder-decoder structures with residual blocks.\nWhen initialized from a prior month or year, this architecture produced the\nfirst AI-based global monthly, seasonal, or annual mean forecast of 2-meter\ntemperatures (T2m) and sea surface temperatures (SST). ERA5 monthly mean data\nis used as input for T2m over land, SST over oceans, and solar radiation at the\ntop of the atmosphere for each month of 40 years to train the model. Validation\nforecasts are performed for an additional two years, followed by five years of\nforecast evaluations to account for natural annual variability. AI-trained\ninference forecast weights generate forecasts in seconds, enabling ensemble\nseasonal forecasts. Root Mean Squared Error (RMSE), Anomaly Correlation\nCoefficient (ACC), and Heidke Skill Score (HSS) statistics are presented\nglobally and over specific regions. These forecasts outperform persistence,\nclimatology, and multiple linear regression for all domains. DUNE forecasts\ndemonstrate comparable statistical accuracy to NOAA's operational monthly and\nseasonal probabilistic outlook forecasts over the US but at significantly\nhigher resolutions. RMSE and ACC error statistics for other recent AI-based\ndaily forecasts also show superior performance for DUNE-based forecasts. The\nDUNE model's application to an ensemble data assimilation cycle shows\ncomparable forecast accuracy with a single high-resolution model, potentially\neliminating the need for retraining on extrapolated datasets.",
            "pdf_url": "http://arxiv.org/pdf/2408.06262v1",
            "published": "2024-08-12 16:22:30+00:00",
            "updated": "2024-08-12 16:22:30+00:00"
        },
        {
            "title": "Quantum Simulations of Chemistry in First Quantization with any Basis Set",
            "authors": "Timothy N. Georges, Marius Bothe, Christoph S\u00fcnderhauf, Bjorn K. Berntson, R\u00f3bert Izs\u00e1k, Aleksei V. Ivanov",
            "summary": "Quantum computation of the energy of molecules and materials is one of the\nmost promising applications of fault-tolerant quantum computers. However,\npractical applications require algorithms with reduced resource requirements.\nPrevious work has mainly represented the Hamiltonian of the system in second\nquantization. Existing methods in first quantization are limited to grid-based\napproaches that do not allow for active space calculations. In this work, we\npresent a method to solve the generic ground-state chemistry problem in first\nquantization on a fault-tolerant quantum computer using any basis set. This\nallows for calculations in the active space using modern quantum chemistry\nbasis sets. We derive a linear-combination-of-unitaries decomposition for a\nchemical Hamiltonian in first quantization and then construct an efficient\nblock encoding, exploiting sparsity of the Hamiltonian. For active space\ncalculations using a molecular orbital basis set, we achieve an asymptotic\nspeed up in Toffoli-gate count compared to the equivalent method in second\nquantization [Berry, et. al. Quantum 3, 208 (2019)]. We also consider the dual\nplane waves for materials simulations and find that in physically interesting\nregimes we achieve orders of magnitude improvement in quantum resources\ncompared to the second quantization counterpart. In some instances, our\napproach provides similar or even lower resources compared to the first\nquantization plane wave algorithm of Refs.[Babbush, et. al npj Quantum Inf 5(1)\n92 (2019), Su et. al PRX Quantum 2(4), 040332 (2021)] that, unlike our\napproach, avoids loading the classical data from quantum memory. This work\nopens up possibilities to reduce quantum resources even further using\nfactorization methods of a Hamiltonian or modern pseudopotentials. Furthermore,\nour approach can be adapted to other applications, such as the vibrational\nproperties of chemical systems.",
            "pdf_url": "http://arxiv.org/pdf/2408.03145v2",
            "published": "2024-08-06 12:40:32+00:00",
            "updated": "2024-08-12 15:58:52+00:00"
        },
        {
            "title": "One-loop impact factors for heavy quarkonium production: $S$-wave case",
            "authors": "Maxim Nefedov",
            "summary": "With the aim to extend the study of inclusive heavy quarkonium production at\nforward rapidities with the resummation of high partinic\ncenter-of-momentum-energy logarithms beyond Leading Logarithmic Approximation\n(LLA), the explicit analytic results for one-loop corrections to the following\nimpact factors had been obtained: $\\gamma R \\to Q\\bar{Q}\\left[^1S_0^{[8]}\n\\right]$, $g R \\to Q\\bar{Q}\\left[^1S_0^{[1]} \\right]$, $gR\\to Q\\bar{Q}\\left[\n^1S_0^{[8]} \\right]$ and $gR\\to Q\\bar{Q}\\left[ ^3S_1^{[8]}\\right]$, with $R$\nbeing the Reggeized gluon and $Q$ is the heavy quark. The computation is done\nin the framework of Lipatov's gauge-invariant EFT for Multi-Regge processes in\nQCD with the tilted-Wilson-line regularisation for rapidity divergences. As\nexpected, only single-logarithmic rapidity divergence proportional to the\none-loop Regge trajetory of a gluon remains in the final result for\nimpact-factors. Numerical comparison with Regge limits ($s/(-t) \\gg 1$) of\none-loop QCD amplitudes, described in the paper, provides a strong cross-check\nof obtained results. The relations of obtained results with other\nregularisation schemes for rapidity divergences used in low-$x$ physics, such\nas BFKL scheme, High-Energy Factorisation (HEF) scheme and shockwave scheme,\nare given.",
            "pdf_url": "http://arxiv.org/pdf/2408.06234v1",
            "published": "2024-08-12 15:37:23+00:00",
            "updated": "2024-08-12 15:37:23+00:00"
        },
        {
            "title": "A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring",
            "authors": "Vispi Karkaria, Jie Chen, Christopher Luey, Chase Siuta, Damien Lim, Robert Radulescu, Wei Chen",
            "summary": "We introduce a novel digital twin framework for predictive maintenance of\nlong-term physical systems. Using monitoring tire health as an application, we\nshow how the digital twin framework can be used to enhance automotive safety\nand efficiency, and how the technical challenges can be overcome using a\nthree-step approach. Firstly, for managing the data complexity over a long\noperation span, we employ data reduction techniques to concisely represent\nphysical tires using historical performance and usage data. Relying on these\ndata, for fast real-time prediction, we train a transformer-based model offline\non our concise dataset to predict future tire health over time, represented as\nRemaining Casing Potential (RCP). Based on our architecture, our model\nquantifies both epistemic and aleatoric uncertainty, providing reliable\nconfidence intervals around predicted RCP. Secondly, to incorporate real-time\ndata, we update the predictive model in the digital twin framework, ensuring\nits accuracy throughout its life span with the aid of hybrid modeling and the\nuse of discrepancy function. Thirdly, to assist decision making in predictive\nmaintenance, we implement a Tire State Decision Algorithm, which strategically\ndetermines the optimal timing for tire replacement based on RCP forecasted by\nour transformer model. This approach ensures our digital twin accurately\npredicts system health, continually refines its digital representation, and\nsupports predictive maintenance decisions. Our framework effectively embodies a\nphysical system, leveraging big data and machine learning for predictive\nmaintenance, model updates, and decision-making.",
            "pdf_url": "http://arxiv.org/pdf/2408.06220v1",
            "published": "2024-08-12 15:21:35+00:00",
            "updated": "2024-08-12 15:21:35+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
            "authors": "Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha",
            "summary": "One of the grand challenges of artificial general intelligence is developing\nagents capable of conducting scientific research and discovering new knowledge.\nWhile frontier models have already been used as aids to human scientists, e.g.\nfor brainstorming ideas, writing code, or prediction tasks, they still conduct\nonly a small part of the scientific process. This paper presents the first\ncomprehensive framework for fully automatic scientific discovery, enabling\nfrontier large language models to perform research independently and\ncommunicate their findings. We introduce The AI Scientist, which generates\nnovel research ideas, writes code, executes experiments, visualizes results,\ndescribes its findings by writing a full scientific paper, and then runs a\nsimulated review process for evaluation. In principle, this process can be\nrepeated to iteratively develop ideas in an open-ended fashion, acting like the\nhuman scientific community. We demonstrate its versatility by applying it to\nthree distinct subfields of machine learning: diffusion modeling,\ntransformer-based language modeling, and learning dynamics. Each idea is\nimplemented and developed into a full paper at a cost of less than $15 per\npaper. To evaluate the generated papers, we design and validate an automated\nreviewer, which we show achieves near-human performance in evaluating paper\nscores. The AI Scientist can produce papers that exceed the acceptance\nthreshold at a top machine learning conference as judged by our automated\nreviewer. This approach signifies the beginning of a new era in scientific\ndiscovery in machine learning: bringing the transformative benefits of AI\nagents to the entire research process of AI itself, and taking us closer to a\nworld where endless affordable creativity and innovation can be unleashed on\nthe world's most challenging problems. Our code is open-sourced at\nhttps://github.com/SakanaAI/AI-Scientist",
            "pdf_url": "http://arxiv.org/pdf/2408.06292v1",
            "published": "2024-08-12 16:58:11+00:00",
            "updated": "2024-08-12 16:58:11+00:00"
        },
        {
            "title": "Unified Discrete Diffusion for Categorical Data",
            "authors": "Lingxiao Zhao, Xueying Ding, Lijun Yu, Leman Akoglu",
            "summary": "Discrete diffusion models have seen a surge of attention with applications on\nnaturally discrete data such as language and graphs. Although discrete-time\ndiscrete diffusion has been established for a while, only recently Campbell et\nal. (2022) introduced the first framework for continuous-time discrete\ndiffusion. However, their training and sampling processes differ significantly\nfrom the discrete-time version, necessitating nontrivial approximations for\ntractability. In this paper, we first present a series of mathematical\nsimplifications of the variational lower bound that enable more accurate and\neasy-to-optimize training for discrete diffusion. In addition, we derive a\nsimple formulation for backward denoising that enables exact and accelerated\nsampling, and importantly, an elegant unification of discrete-time and\ncontinuous-time discrete diffusion. Thanks to simpler analytical formulations,\nboth forward and now also backward probabilities can flexibly accommodate any\nnoise distribution, including different noise distributions for multi-element\nobjects. Experiments show that our proposed USD3 (for Unified Simplified\nDiscrete Denoising Diffusion) outperform all SOTA baselines on established\ndatasets. We open-source our unified code at\nhttps://github.com/LingxiaoShawn/USD3.",
            "pdf_url": "http://arxiv.org/pdf/2402.03701v2",
            "published": "2024-02-06 04:42:36+00:00",
            "updated": "2024-08-12 16:22:38+00:00"
        },
        {
            "title": "Control-A-Video: Controllable Text-to-Video Diffusion Models with Motion Prior and Reward Feedback Learning",
            "authors": "Weifeng Chen, Yatai Ji, Jie Wu, Hefeng Wu, Pan Xie, Jiashi Li, Xin Xia, Xuefeng Xiao, Liang Lin",
            "summary": "Recent advances in text-to-image (T2I) diffusion models have enabled\nimpressive image generation capabilities guided by text prompts. However,\nextending these techniques to video generation remains challenging, with\nexisting text-to-video (T2V) methods often struggling to produce high-quality\nand motion-consistent videos. In this work, we introduce Control-A-Video, a\ncontrollable T2V diffusion model that can generate videos conditioned on text\nprompts and reference control maps like edge and depth maps. To tackle video\nquality and motion consistency issues, we propose novel strategies to\nincorporate content prior and motion prior into the diffusion-based generation\nprocess. Specifically, we employ a first-frame condition scheme to transfer\nvideo generation from the image domain. Additionally, we introduce\nresidual-based and optical flow-based noise initialization to infuse motion\npriors from reference videos, promoting relevance among frame latents for\nreduced flickering. Furthermore, we present a Spatio-Temporal Reward Feedback\nLearning (ST-ReFL) algorithm that optimizes the video diffusion model using\nmultiple reward models for video quality and motion consistency, leading to\nsuperior outputs. Comprehensive experiments demonstrate that our framework\ngenerates higher-quality, more consistent videos compared to existing\nstate-of-the-art methods in controllable text-to-video generation",
            "pdf_url": "http://arxiv.org/pdf/2305.13840v3",
            "published": "2023-05-23 09:03:19+00:00",
            "updated": "2024-08-12 08:30:05+00:00"
        },
        {
            "title": "Between Randomness and Arbitrariness: Some Lessons for Reliable Machine Learning at Scale",
            "authors": "A. Feder Cooper",
            "summary": "To develop rigorous knowledge about ML models -- and the systems in which\nthey are embedded -- we need reliable measurements. But reliable measurement is\nfundamentally challenging, and touches on issues of reproducibility,\nscalability, uncertainty quantification, epistemology, and more. This\ndissertation addresses criteria needed to take reliability seriously: both\ncriteria for designing meaningful metrics, and for methodologies that ensure\nthat we can dependably and efficiently measure these metrics at scale and in\npractice. In doing so, this dissertation articulates a research vision for a\nnew field of scholarship at the intersection of machine learning, law, and\npolicy. Within this frame, we cover topics that fit under three different\nthemes: (1) quantifying and mitigating sources of arbitrariness in ML, (2)\ntaming randomness in uncertainty estimation and optimization algorithms, in\norder to achieve scalability without sacrificing reliability, and (3) providing\nmethods for evaluating generative-AI systems, with specific focuses on\nquantifying memorization in language models and training latent diffusion\nmodels on open-licensed data. By making contributions in these three themes,\nthis dissertation serves as an empirical proof by example that research on\nreliable measurement for machine learning is intimately and inescapably bound\nup with research in law and policy. These different disciplines pose similar\nresearch questions about reliable measurement in machine learning. They are, in\nfact, two complementary sides of the same research vision, which, broadly\nconstrued, aims to construct machine-learning systems that cohere with broader\nsocietal values.",
            "pdf_url": "http://arxiv.org/pdf/2406.09548v2",
            "published": "2024-06-13 19:29:37+00:00",
            "updated": "2024-08-12 08:02:06+00:00"
        },
        {
            "title": "Residual Corrective Diffusion Modeling for Km-scale Atmospheric Downscaling",
            "authors": "Morteza Mardani, Noah Brenowitz, Yair Cohen, Jaideep Pathak, Chieh-Yu Chen, Cheng-Chin Liu, Arash Vahdat, Mohammad Amin Nabian, Tao Ge, Akshay Subramaniam, Karthik Kashinath, Jan Kautz, Mike Pritchard",
            "summary": "The state of the art for physical hazard prediction from weather and climate\nrequires expensive km-scale numerical simulations driven by coarser resolution\nglobal inputs. Here, a generative diffusion architecture is explored for\ndownscaling such global inputs to km-scale, as a cost-effective machine\nlearning alternative. The model is trained to predict 2km data from a regional\nweather model over Taiwan, conditioned on a 25km global reanalysis. To address\nthe large resolution ratio, different physics involved at different scales and\nprediction of channels beyond those in the input data, we employ a two-step\napproach where a UNet predicts the mean and a corrector diffusion (CorrDiff)\nmodel predicts the residual. CorrDiff exhibits encouraging skill in bulk MAE\nand CRPS scores. The predicted spectra and distributions from CorrDiff\nfaithfully recover important power law relationships in the target data. Case\nstudies of coherent weather phenomena show that CorrDiff can help sharpen wind\nand temperature gradients that co-locate with intense rainfall in cold front,\nand can help intensify typhoons and synthesize rain band structures.\nCalibration of model uncertainty remains challenging. The prospect of unifying\nmethods like CorrDiff with coarser resolution global weather models implies a\npotential for global-to-regional multi-scale machine learning simulation.",
            "pdf_url": "http://arxiv.org/pdf/2309.15214v4",
            "published": "2023-09-24 19:57:22+00:00",
            "updated": "2024-08-11 21:36:46+00:00"
        }
    ]
}