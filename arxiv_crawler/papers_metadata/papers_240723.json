{
    "Physics": [
        {
            "title": "Multicell-Fold: geometric learning in folding multicellular life",
            "authors": "Haiqian Yang, Anh Q. Nguyen, Dapeng Bi, Markus J. Buehler, Ming Guo",
            "summary": "During developmental processes such as embryogenesis, how a group of cells\nfold into specific structures, is a central question in biology that defines\nhow living organisms form. Establishing tissue-level morphology critically\nrelies on how every single cell decides to position itself relative to its\nneighboring cells. Despite its importance, it remains a major challenge to\nunderstand and predict the behavior of every cell within the living tissue over\ntime during such intricate processes. To tackle this question, we propose a\ngeometric deep learning model that can predict multicellular folding and\nembryogenesis, accurately capturing the highly convoluted spatial interactions\namong cells. We demonstrate that multicellular data can be represented with\nboth granular and foam-like physical pictures through a unified graph data\nstructure, considering both cellular interactions and cell junction networks.\nWe successfully use our model to achieve two important tasks, interpretable 4-D\nmorphological sequence alignment, and predicting local cell rearrangements\nbefore they occur at single-cell resolution. Furthermore, using an activation\nmap and ablation studies, we demonstrate that cell geometries and cell junction\nnetworks together regulate local cell rearrangement which is critical for\nembryo morphogenesis. This approach provides a novel paradigm to study\nmorphogenesis, highlighting a unified data structure and harnessing the power\nof geometric deep learning to accurately model the mechanisms and behaviors of\ncells during development. It offers a pathway toward creating a unified dynamic\nmorphological atlas for a variety of developmental processes such as\nembryogenesis.",
            "pdf_url": "http://arxiv.org/pdf/2407.07055v2",
            "published": "2024-07-09 17:21:49+00:00",
            "updated": "2024-07-22 17:59:15+00:00"
        },
        {
            "title": "Turing's Test, a Beautiful Thought Experiment",
            "authors": "Bernardo Gon\u00e7alves",
            "summary": "In the wake of the latest trends of artificial intelligence (AI), there has\nbeen a resurgence of claims and questions about the Turing test and its value,\nwhich are reminiscent of decades of practical \"Turing\" tests. If AI were\nquantum physics, by now several \"Schr\\\"odinger's\" cats would have been killed.\nIt is time for a historical reconstruction of Turing's beautiful thought\nexperiment. This paper presents a wealth of evidence, including new archival\nsources, and gives original answers to several open questions about Turing's\n1950 paper, including its relation with early AI.",
            "pdf_url": "http://arxiv.org/pdf/2401.00009v3",
            "published": "2023-12-18 19:38:26+00:00",
            "updated": "2024-07-22 17:29:32+00:00"
        },
        {
            "title": "Towards Relational Quantum Field Theory",
            "authors": "Jan G\u0142owacki",
            "summary": "This paper presents a research program aimed at establishing relational\nfoundations for relativistic quantum physics. Although the formalism is still\nunder development, we believe it has matured enough to be shared with the\nbroader scientific community. Our approach seeks to integrate Quantum Field\nTheory on curved backgrounds and scenarios with indefinite causality. Building\non concepts from the operational approach to Quantum Reference Frames, we\nextend these ideas significantly. Specifically, we initiate the development of\na general integration theory for operator-valued functions (quantum fields)\nwith respect to positive operator-valued measures (quantum frames). This allows\nus to define quantum frames within the context of arbitrary principal bundles,\nreplacing group structures. By considering Lorentz principal bundles, we enable\na relational treatment of quantum fields on arbitrarily curved spacetimes. A\nform of indefinite spatiotemporality arises from quantum states in the context\nof frame bundles. This offers novel perspectives on the problem of reconciling\nprinciples of generally relativistic and quantum physics and on modelling\ngravitational fields sourced by quantum systems.",
            "pdf_url": "http://arxiv.org/pdf/2405.15455v2",
            "published": "2024-05-24 11:31:27+00:00",
            "updated": "2024-07-22 17:24:34+00:00"
        },
        {
            "title": "Flux-mediated effective Su-Schrieffer-Heeger model in an impurity decorated diamond chain",
            "authors": "David Viedma, Anselmo M. Marques, Ricardo G. Dias, Ver\u00f2nica Ahufinger",
            "summary": "In flat-band systems with non-orthogonal compact localized states (CLSs),\nonsite perturbations couple neighboring CLSs and generate\nexponentially-decaying impurity states, whose degree of localization depends on\nlattice parameters. In this work, a diamond chain with constant magnetic flux\nper plaquette is decorated with several controlled onsite impurities in a\npatterned arrangement, generating an effective system that emerges from the\nflat band. The coupling distribution of the effective system is determined by\nthe relative distance between impurities and the value of the flux, which can\nbe chosen to engineer a wide variety of models. We employ a staggered\ndistribution of impurities that effectively produces the well-known\nSu-Schrieffer-Heeger model, and show that the topological edge states display\nan enhanced robustness to non-chiral disorder due to an averaging effect over\ntheir extension. Finally, we provide a route to implement the system\nexperimentally using optical waveguides that guide orbital angular momentum\n(OAM) modes. This work opens the way for the design of topologically protected\nimpurity states in other flat-band systems or physical platforms with\nnon-orthogonal bases.",
            "pdf_url": "http://arxiv.org/pdf/2407.15789v1",
            "published": "2024-07-22 16:48:58+00:00",
            "updated": "2024-07-22 16:48:58+00:00"
        },
        {
            "title": "Reinterpretation of the Fermi acceleration of cosmic rays in terms of the ballistic surfing acceleration in supernova shocks",
            "authors": "Krzysztof Stasiewicz",
            "summary": "The applicability of first-order Fermi acceleration in explaining the cosmic\nray spectrum has been reexamined using recent results on shock acceleration\nmechanisms from the Multiscale Magnetospheric mission in Earth's bow shock. It\nis demonstrated that the Fermi mechanism is a crude approximation of the\nballistic surfing acceleration (BSA) mechanism. While both mechanisms yield\nsimilar expressions for the energy gain of a particle after encountering a\nshock once, leading to similar power-law distributions of the cosmic ray energy\nspectrum, the Fermi mechanism is found to be inconsistent with fundamental\nequations of electrodynamics.\n  It is shown that the spectral index of cosmic rays is determined by the\naverage magnetic field compression rather than the density compression, as in\nthe Fermi model. It is shown that the knee observed in the spectrum at an\nenergy of 5x10^{15} eV could correspond to ions with a gyroradius comparable to\nthe size of shocks in supernova remnants. The BSA mechanism can accurately\nreproduce the observed spectral index s = -2.5 below the knee energy, as well\nas a steeper spectrum, s = -3, above the knee. The acceleration time up to the\nknee, as implied by BSA, is on the order of 300 years.\n  First-order Fermi acceleration does not represent a physically valid\nmechanism and should be replaced by ballistic surfing acceleration in\napplications or models related to quasi-perpendicular shocks in space. It is\nnoted that BSA, which operates outside of shocks, was previously misattributed\nto shock drift acceleration (SDA), which operates within shocks.",
            "pdf_url": "http://arxiv.org/pdf/2407.15767v1",
            "published": "2024-07-22 16:18:11+00:00",
            "updated": "2024-07-22 16:18:11+00:00"
        },
        {
            "title": "An instructional lab apparatus for quantum experiments with single nitrogen-vacancy centers in diamond",
            "authors": "Zhiyang Yuan, Sounak Mukherjee, Aedan Gardill, Jeff D. Thompson, Shimon Kolkowitz, Nathalie P. de Leon",
            "summary": "Hands-on experimental experience with quantum systems in the undergraduate\nphysics curriculum provides students with a deeper understanding of quantum\nphysics and equips them for the fast-growing quantum science industry. Here we\npresent an experimental apparatus for performing quantum experiments with\nsingle nitrogen-vacancy (NV) centers in diamond. This apparatus is capable of\nbasic experiments such as single-qubit initialization, rotation, and\nmeasurement, as well as more advanced experiments investigating\nelectron-nuclear spin interactions. We describe the basic physics of the NV\ncenter and give examples of potential experiments that can be performed with\nthis apparatus. We also discuss the options and inherent trade-offs associated\nwith the choice of diamond samples and hardware. The apparatus described here\nenables students to write their own experimental control and data analysis\nsoftware from scratch all within a single semester of a typical lab course, as\nwell as to inspect the optical components and inner workings of the apparatus.\nWe hope that this work can serve as a standalone resource for any institution\nthat would like to integrate a quantum instructional lab into its undergraduate\nphysics and engineering curriculum.",
            "pdf_url": "http://arxiv.org/pdf/2407.15759v1",
            "published": "2024-07-22 16:10:59+00:00",
            "updated": "2024-07-22 16:10:59+00:00"
        },
        {
            "title": "Non-Abelian Hopf-Euler insulators",
            "authors": "Wojciech J. Jankowski, Arthur S. Morris, Zory Davoyan, Adrien Bouhon, F. Nur \u00dcnal, Robert-Jan Slager",
            "summary": "We discuss a class of three-band non-Abelian topological insulators in three\ndimensions which carry a single bulk Hopf index protected by spatiotemporal\n($\\mathcal{PT}$) inversion symmetry. These phases may also host subdimensional\ntopological invariants given by the Euler characteristic class, resulting in\nreal Hopf-Euler insulators. Such systems naturally realize helical nodal\nstructures in the 3D Brillouin zone, providing a physical manifestation of the\nlinking number described by the Hopf invariant. We show that, by opening a gap\nbetween the valence bands of these systems, one finds a fully-gapped `flag'\nphase, which displays a three-band multi-gap Pontryagin invariant. Unlike the\npreviously reported $\\mathcal{PT}$-symmetric four-band real Hopf insulator,\nwhich hosts a $\\mathbb{Z} \\oplus \\mathbb{Z}$ invariant, these phases are not\nunitarily equivalent to two copies of a complex two-band Hopf insulator. We\nshow that these uncharted phases can be obtained through dimensional extension\nof two-dimensional Euler insulators, and that they support (1) an optical bulk\nintegrated circular shift effect quantized by the Hopf invariant, (2)\nquantum-geometric breathing in the real space Wannier functions, and (3)\nsurface Euler topology on boundaries. Consequently, our findings pave a way for\nnovel experimental realizations of real-space quantum-geometry, as these\nsystems may be directly simulated by utilizing synthethic dimensions in\nmetamaterials or ultracold atoms.",
            "pdf_url": "http://arxiv.org/pdf/2405.17305v2",
            "published": "2024-05-27 16:07:47+00:00",
            "updated": "2024-07-22 15:51:21+00:00"
        },
        {
            "title": "Can foreign exchange rates violate Bell inequalities?",
            "authors": "Hans De Raedt, Mikhail I. Katsnelson, Manpreet S. Jattana, Vrinda Mehta, Madita Willsch, Dennis Willsch, Kristel Michielsen, Fengping Jin",
            "summary": "The analysis of empirical data through model-free inequalities leads to the\nconclusion that violations of Bell-type inequalities by empirical data cannot\nhave any significance unless one believes that the universe operates according\nto the rules of a mathematical model.",
            "pdf_url": "http://arxiv.org/pdf/2407.15747v1",
            "published": "2024-07-22 15:48:39+00:00",
            "updated": "2024-07-22 15:48:39+00:00"
        },
        {
            "title": "Einstein-Podolsky-Rosen-Bohm experiments: a discrete data driven approach",
            "authors": "Hans De Raedt, Mikhail I. Katsnelson, Manpreet S. Jattana, Vrinda Mehta, Madita Willsch, Dennis Willsch, Kristel Michielsen, Fengping Jin",
            "summary": "We take the point of view that building a one-way bridge from experimental\ndata to mathematical models instead of the other way around avoids running into\ncontroversies resulting from attaching meaning to the symbols used in the\nlatter. In particular, we show that adopting this view offers new perspectives\nfor constructing mathematical models for and interpreting the results of\nEinstein-Podolsky-Rosen-Bohm experiments. We first prove new Bell-type\ninequalities constraining the values of the four correlations obtained by\nperforming Einstein-Podolsky-Rosen-Bohm experiments under four different\nconditions. The proof is ``model-free'' in the sense that it does not refer to\nany mathematical model that one imagines to have produced the data. The\nconstraints only depend on the number of quadruples obtained by reshuffling the\ndata in the four data sets without changing the values of the correlations.\nThese new inequalities reduce to model-free versions of the well-known\nBell-type inequalities if the maximum fraction of quadruples is equal to one.\nBeing model-free, a violation of the latter by experimental data implies that\nnot all the data in the four data sets can be reshuffled to form quadruples.\nFurthermore, being model-free inequalities, a violation of the latter by\nexperimental data only implies that any mathematical model assumed to produce\nthis data does not apply. Starting from the data obtained by performing\nEinstein-Podolsky-Rosen-Bohm experiments, we construct instead of postulate\nmathematical models that describe the main features of these data. The\nmathematical framework of plausible reasoning is applied to reproducible and\nrobust data, yielding without using any concept of quantum theory, the\nexpression of the correlation for a system of two spin-1/2 objects in the\nsinglet state. (truncated here)",
            "pdf_url": "http://arxiv.org/pdf/2304.03962v4",
            "published": "2023-04-08 09:06:23+00:00",
            "updated": "2024-07-22 15:33:52+00:00"
        },
        {
            "title": "Inferring turbulent velocity and temperature fields and their statistics from Lagrangian velocity measurements using physics-informed Kolmogorov-Arnold Networks",
            "authors": "Juan Diego Toscano, Theo K\u00e4ufer, Martin Maxey, Christian Cierpka, George Em Karniadakis",
            "summary": "We propose the Artificial Intelligence Velocimetry-Thermometry (AIVT) method\nto infer hidden temperature fields from experimental turbulent velocity data.\nThis physics-informed machine learning method enables us to infer continuous\ntemperature fields using only sparse velocity data, hence eliminating the need\nfor direct temperature measurements. Specifically, AIVT is based on\nphysics-informed Kolmogorov-Arnold Networks (not neural networks) and is\ntrained by optimizing a combined loss function that minimizes the residuals of\nthe velocity data, boundary conditions, and the governing equations. We apply\nAIVT to a unique set of experimental volumetric and simultaneous temperature\nand velocity data of Rayleigh-B\\'enard convection (RBC) that we acquired by\ncombining Particle Image Thermometry and Lagrangian Particle Tracking. This\nallows us to compare AIVT predictions and measurements directly. We demonstrate\nthat we can reconstruct and infer continuous and instantaneous velocity and\ntemperature fields from sparse experimental data at a fidelity comparable to\ndirect numerical simulations (DNS) of turbulence. This, in turn, enables us to\ncompute important quantities for quantifying turbulence, such as fluctuations,\nviscous and thermal dissipation, and QR distribution. This paradigm shift in\nprocessing experimental data using AIVT to infer turbulent fields at DNS-level\nfidelity is a promising avenue in breaking the current deadlock of quantitative\nunderstanding of turbulence at high Reynolds numbers, where DNS is\ncomputationally infeasible.",
            "pdf_url": "http://arxiv.org/pdf/2407.15727v1",
            "published": "2024-07-22 15:30:21+00:00",
            "updated": "2024-07-22 15:30:21+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget",
            "authors": "Vikash Sehwag, Xianghao Kong, Jingtao Li, Michael Spranger, Lingjuan Lyu",
            "summary": "As scaling laws in generative AI push performance, they also simultaneously\nconcentrate the development of these models among actors with large\ncomputational resources. With a focus on text-to-image (T2I) generative models,\nwe aim to address this bottleneck by demonstrating very low-cost training of\nlarge-scale T2I diffusion transformer models. As the computational cost of\ntransformers increases with the number of patches in each image, we propose to\nrandomly mask up to 75% of the image patches during training. We propose a\ndeferred masking strategy that preprocesses all patches using a patch-mixer\nbefore masking, thus significantly reducing the performance degradation with\nmasking, making it superior to model downscaling in reducing computational\ncost. We also incorporate the latest improvements in transformer architecture,\nsuch as the use of mixture-of-experts layers, to improve performance and\nfurther identify the critical benefit of using synthetic images in micro-budget\ntraining. Finally, using only 37M publicly available real and synthetic images,\nwe train a 1.16 billion parameter sparse transformer with only \\$1,890\neconomical cost and achieve a 12.7 FID in zero-shot generation on the COCO\ndataset. Notably, our model achieves competitive FID and high-quality\ngenerations while incurring 118$\\times$ lower cost than stable diffusion models\nand 14$\\times$ lower cost than the current state-of-the-art approach that costs\n\\$28,400. We aim to release our end-to-end training pipeline to further\ndemocratize the training of large-scale diffusion models on micro-budgets.",
            "pdf_url": "http://arxiv.org/pdf/2407.15811v1",
            "published": "2024-07-22 17:23:28+00:00",
            "updated": "2024-07-22 17:23:28+00:00"
        },
        {
            "title": "Diffusion Model Based Resource Allocation Strategy in Ultra-Reliable Wireless Networked Control Systems",
            "authors": "Amirhassan Babazadeh Darabi, Sinem Coleri",
            "summary": "Diffusion models are vastly used in generative AI, leveraging their\ncapability to capture complex data distributions. However, their potential\nremains largely unexplored in the field of resource allocation in wireless\nnetworks. This paper introduces a novel diffusion model-based resource\nallocation strategy for Wireless Networked Control Systems (WNCSs) with the\nobjective of minimizing total power consumption through the optimization of the\nsampling period in the control system, and blocklength and packet error\nprobability in the finite blocklength regime of the communication system. The\nproblem is first reduced to the optimization of blocklength only based on the\nderivation of the optimality conditions. Then, the optimization theory solution\ncollects a dataset of channel gains and corresponding optimal blocklengths.\nFinally, the Denoising Diffusion Probabilistic Model (DDPM) uses this collected\ndataset to train the resource allocation algorithm that generates optimal\nblocklength values conditioned on the channel state information (CSI). Via\nextensive simulations, the proposed approach is shown to outperform previously\nproposed Deep Reinforcement Learning (DRL) based approaches with close to\noptimal performance regarding total power consumption. Moreover, an improvement\nof up to eighteen-fold in the reduction of critical constraint violations is\nobserved, further underscoring the accuracy of the solution.",
            "pdf_url": "http://arxiv.org/pdf/2407.15784v1",
            "published": "2024-07-22 16:44:57+00:00",
            "updated": "2024-07-22 16:44:57+00:00"
        },
        {
            "title": "Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond",
            "authors": "Silvio Galesso, Philipp Schr\u00f6ppel, Hssan Driss, Thomas Brox",
            "summary": "In recent years, research on out-of-distribution (OoD) detection for semantic\nsegmentation has mainly focused on road scenes -- a domain with a constrained\namount of semantic diversity. In this work, we challenge this constraint and\nextend the domain of this task to general natural images. To this end, we\nintroduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and\nincludes images from diverse domains with a high semantic diversity, and 2. a\nnovel approach that uses Diffusion score matching for OoD detection (DOoD) and\nis robust to the increased semantic diversity. ADE-OoD features indoor and\noutdoor images, defines 150 semantic categories as in-distribution, and\ncontains a variety of OoD objects. For DOoD, we train a diffusion model with an\nMLP architecture on semantic in-distribution embeddings and build on the score\nmatching interpretation to compute pixel-wise OoD scores at inference time. On\ncommon road scene OoD benchmarks, DOoD performs on par or better than the state\nof the art, without using outliers for training or making assumptions about the\ndata domain. On ADE-OoD, DOoD outperforms previous approaches, but leaves much\nroom for future improvements.",
            "pdf_url": "http://arxiv.org/pdf/2407.15739v1",
            "published": "2024-07-22 15:41:37+00:00",
            "updated": "2024-07-22 15:41:37+00:00"
        },
        {
            "title": "Estimating Probability Densities with Transformer and Denoising Diffusion",
            "authors": "Henry W. Leung, Jo Bovy, Joshua S. Speagle",
            "summary": "Transformers are often the go-to architecture to build foundation models that\ningest a large amount of training data. But these models do not estimate the\nprobability density distribution when trained on regression problems, yet\nobtaining full probabilistic outputs is crucial to many fields of science,\nwhere the probability distribution of the answer can be non-Gaussian and\nmultimodal. In this work, we demonstrate that training a probabilistic model\nusing a denoising diffusion head on top of the Transformer provides reasonable\nprobability density estimation even for high-dimensional inputs. The combined\nTransformer+Denoising Diffusion model allows conditioning the output\nprobability density on arbitrary combinations of inputs and it is thus a highly\nflexible density function emulator of all possible input/output combinations.\nWe illustrate our Transformer+Denoising Diffusion model by training it on a\nlarge dataset of astronomical observations and measured labels of stars within\nour Galaxy and we apply it to a variety of inference tasks to show that the\nmodel can infer labels accurately with reasonable distributions.",
            "pdf_url": "http://arxiv.org/pdf/2407.15703v1",
            "published": "2024-07-22 15:10:41+00:00",
            "updated": "2024-07-22 15:10:41+00:00"
        },
        {
            "title": "Discrete Flow Matching",
            "authors": "Itai Gat, Tal Remez, Neta Shaul, Felix Kreuk, Ricky T. Q. Chen, Gabriel Synnaeve, Yossi Adi, Yaron Lipman",
            "summary": "Despite Flow Matching and diffusion models having emerged as powerful\ngenerative paradigms for continuous variables such as images and videos, their\napplication to high-dimensional discrete data, such as language, is still\nlimited. In this work, we present Discrete Flow Matching, a novel discrete flow\nparadigm designed specifically for generating discrete data. Discrete Flow\nMatching offers several key contributions: (i) it works with a general family\nof probability paths interpolating between source and target distributions;\n(ii) it allows for a generic formula for sampling from these probability paths\nusing learned posteriors such as the probability denoiser ($x$-prediction) and\nnoise-prediction ($\\epsilon$-prediction); (iii) practically, focusing on\nspecific probability paths defined with different schedulers considerably\nimproves generative perplexity compared to previous discrete diffusion and flow\nmodels; and (iv) by scaling Discrete Flow Matching models up to 1.7B\nparameters, we reach 6.7% Pass@1 and 13.4% Pass@10 on HumanEval and 6.7% Pass@1\nand 20.6% Pass@10 on 1-shot MBPP coding benchmarks. Our approach is capable of\ngenerating high-quality discrete data in a non-autoregressive fashion,\nsignificantly closing the gap between autoregressive models and discrete flow\nmodels.",
            "pdf_url": "http://arxiv.org/pdf/2407.15595v1",
            "published": "2024-07-22 12:33:27+00:00",
            "updated": "2024-07-22 12:33:27+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "JaFIn: Japanese Financial Instruction Dataset",
            "authors": "Kota Tanabe, Masahiro Suzuki, Hiroki Sakaji, Itsuki Noda",
            "summary": "We construct an instruction dataset for the large language model (LLM) in the\nJapanese finance domain. Domain adaptation of language models, including LLMs,\nis receiving more attention as language models become more popular. This study\ndemonstrates the effectiveness of domain adaptation through instruction tuning.\nTo achieve this, we propose an instruction tuning data in Japanese called\nJaFIn, the Japanese Financial Instruction Dataset. JaFIn is manually\nconstructed based on multiple data sources, including Japanese government\nwebsites, which provide extensive financial knowledge. We then utilize JaFIn to\napply instruction tuning for several LLMs, demonstrating that our models\nspecialized in finance have better domain adaptability than the original\nmodels. The financial-specialized LLMs created were evaluated using a\nquantitative Japanese financial benchmark and qualitative response comparisons,\nshowing improved performance over the originals.",
            "pdf_url": "http://arxiv.org/pdf/2404.09260v2",
            "published": "2024-04-14 14:01:53+00:00",
            "updated": "2024-07-20 02:27:52+00:00"
        }
    ]
}