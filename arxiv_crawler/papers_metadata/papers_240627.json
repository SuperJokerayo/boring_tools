{
    "Physics": [
        {
            "title": "Mental Modeling of Reinforcement Learning Agents by Language Models",
            "authors": "Wenhao Lu, Xufeng Zhao, Josua Spisak, Jae Hee Lee, Stefan Wermter",
            "summary": "Can emergent language models faithfully model the intelligence of\ndecision-making agents? Though modern language models exhibit already some\nreasoning ability, and theoretically can potentially express any probable\ndistribution over tokens, it remains underexplored how the world knowledge\nthese pretrained models have memorized can be utilized to comprehend an agent's\nbehaviour in the physical world. This study empirically examines, for the first\ntime, how well large language models (LLMs) can build a mental model of agents,\ntermed agent mental modelling, by reasoning about an agent's behaviour and its\neffect on states from agent interaction history. This research may unveil the\npotential of leveraging LLMs for elucidating RL agent behaviour, addressing a\nkey challenge in eXplainable reinforcement learning (XRL). To this end, we\npropose specific evaluation metrics and test them on selected RL task datasets\nof varying complexity, reporting findings on agent mental model establishment.\nOur results disclose that LLMs are not yet capable of fully mental modelling\nagents through inference alone without further innovations. This work thus\nprovides new insights into the capabilities and limitations of modern LLMs.",
            "pdf_url": "http://arxiv.org/pdf/2406.18505v1",
            "published": "2024-06-26 17:14:45+00:00",
            "updated": "2024-06-26 17:14:45+00:00"
        },
        {
            "title": "$\u039b_{\\rm s}$CDM cosmology: Alleviating major cosmological tensions by predicting standard neutrino properties",
            "authors": "Anita Yadav, Suresh Kumar, Cihad Kibris, Ozgur Akarsu",
            "summary": "We investigate a two-parameter extension of the $\\Lambda_{\\rm s}$CDM model by\nallowing variations in the effective number of neutrino species $N_{\\rm eff}$\nand their total mass $\\sum m_\\nu$. Our motivation is twofold: (i) to examine\nwhether $\\Lambda_{\\rm s}$CDM retains its success in fitting the data and\naddressing major cosmological tensions, without suggesting a need for a\ndeviation from the standard model of particle physics, and (ii) to determine\nwhether the data indicate new physics that could potentially address\ncosmological tensions, either in the post-recombination universe through the\nlate-time mirror AdS-dS transition, or in the pre-recombination universe\nthrough modifications in the standard values of $N_{\\rm eff}$ and $\\sum m_\\nu$,\nor both. Within the extended $\\Lambda_{\\rm s}$CDM model, referred to as\n$\\Lambda_{\\rm s}$CDM+$N_{\\rm eff}$+$\\sum m_{\\rm \\nu}$, we find no significant\ntension when considering the Planck-alone analysis. We observe that\nincorporating BAO data limits the further success of the $\\Lambda_{\\rm s}$CDM\nextension. However, the weakly model-dependent BAOtr data, along with Planck\nand Planck+PP\\&SH0ES, favor $H_0\\sim 73\\,{\\rm km\\, s^{-1}\\, Mpc^{-1}}$. In\ncases where BAOtr dataset is used, the mirror AdS-dS transition is very\neffective in providing enhanced $H_0$ values, and thus the model requires no\nsignificant deviation from the standard value of $N_{\\rm eff} = 3.044$. Both\nthe $H_0$ and $S_8$ tensions are effectively addressed, with some compromise in\nthe case of the Planck+BAO dataset. Finally, the upper bounds obtained on $\\sum\nm_\\nu \\lesssim 0.5$~eV are fully compatible with neutrino oscillation\nexperiments. Our findings provide evidence that late-time physics beyond\n$\\Lambda$CDM, such as $\\Lambda_{\\rm s}$CDM, without altering the standard\npre-recombination universe, can suffice to alleviate the major cosmological\ntensions.",
            "pdf_url": "http://arxiv.org/pdf/2406.18496v1",
            "published": "2024-06-26 16:59:13+00:00",
            "updated": "2024-06-26 16:59:13+00:00"
        },
        {
            "title": "Indefinite Causal Structure and Causal Inequalities with Time-Symmetry",
            "authors": "Luke Mrini, Lucien Hardy",
            "summary": "Time-reversal symmetry is a prevalent feature of microscopic physics,\nincluding operational quantum theory and classical general relativity. Previous\nworks have studied indefinite causal structure using the language of\noperational quantum theory, however, these rely on time-asymmetric conditions\nto constrain both operations and the process matrix. Here, we use\ntime-symmetric, operational probabilistic theory to develop a time-symmetric\nprocess matrix formalism for indefinite causal structure. This framework allows\nfor more processes than previously considered and a larger set of causal\ninequalities. We demonstrate that this larger set of causal inequalities offers\nnew opportunities for device-independent certification of causal\nnon-separability by violating new inequalities. Additionally, we determined\nthat the larger class of time-symmetric processes found here is equivalent to\nthose with Indefinite Causal Order and Time Direction (ICOTD) considered by\nChiribella and Liu, thereby providing a description of these processes in terms\nof process matrices.",
            "pdf_url": "http://arxiv.org/pdf/2406.18489v1",
            "published": "2024-06-26 16:53:44+00:00",
            "updated": "2024-06-26 16:53:44+00:00"
        },
        {
            "title": "Modeling the amplitude and energy decay of a weakly damped harmonic oscillator using the energy dissipation rate and a simple trick",
            "authors": "Karlo Lelas, Robert Pezer",
            "summary": "We demonstrate how to derive the exponential decrease of amplitude and an\nexcellent approximation of the energy decay of a weakly damped harmonic\noscillator. This is achieved using a basic understanding of the undamped\nharmonic oscillator and the connection between the damping force's power and\nthe energy dissipation rate. The trick is to add the energy dissipation rates\ncorresponding to two specific pairs of initial conditions with the same initial\nenergy. In this way, we obtain a first-order differential equation from which\nwe quickly determine the time-dependent amplitude and the energies\ncorresponding to each pair of considered initial conditions. Comparing the\nresults of our model to the exact solutions and energies yielded an excellent\nagreement. The physical concepts and mathematical tools we utilize are familiar\nto first-year undergraduates.",
            "pdf_url": "http://arxiv.org/pdf/2406.18488v1",
            "published": "2024-06-26 16:53:03+00:00",
            "updated": "2024-06-26 16:53:03+00:00"
        },
        {
            "title": "NuHepMC: A standardized event record format for neutrino event generators",
            "authors": "S. Gardiner, J. Isaacson, L. Pickering",
            "summary": "Simulations of neutrino interactions are playing an increasingly important\nrole in the pursuit of high-priority measurements for the field of particle\nphysics. A significant technical barrier for efficient development of these\nsimulations is the lack of a standard data format for representing individual\nneutrino scattering events. We propose and define such a universal format,\nnamed NuHepMC, as a common standard for the output of neutrino event\ngenerators. The NuHepMC format uses data structures and concepts from the\nHepMC3 event record library adopted by other subfields of high-energy physics.\nThese are supplemented with an original set of conventions for generically\nrepresenting neutrino interaction physics within the HepMC3 infrastructure.",
            "pdf_url": "http://arxiv.org/pdf/2310.13211v2",
            "published": "2023-10-20 01:06:44+00:00",
            "updated": "2024-06-26 16:38:16+00:00"
        },
        {
            "title": "Universal Anomaly Detection at the LHC: Transforming Optimal Classifiers and the DDD Method",
            "authors": "Sascha Caron, Jos\u00e9 Enrique Garc\u00eda Navarro, Mar\u00eda Moreno Ll\u00e1cer, Polina Moskvitina, Mats Rovers, Adri\u00e1n Rubio J\u00edmenez, Roberto Ruiz de Austri, Zhongyi Zhang",
            "summary": "In this work, we present a novel approach to transform supervised classifiers\ninto effective unsupervised anomaly detectors. The method we have developed,\ntermed Discriminatory Detection of Distortions (DDD), enhances anomaly\ndetection by training a discriminator model on both original and artificially\nmodified datasets. We conducted a comprehensive evaluation of our models on the\nDark Machines Anomaly Score Challenge channels and a search for 4-top quark\nevents, demonstrating the effectiveness of our approach across various final\nstates and beyond the Standard Model scenarios.\n  We compare the performance of the DDD method with the Deep Robust One-Class\nClassification method (DROCC), which incorporates signals in the training\nprocess, and the Deep Support Vector Data Description (DeepSVDD) method, a well\nestablished and well performing method for anomaly detection. Results show that\nthe effectiveness of each model varies by signal and channel, with DDD proving\nto be a very effective anomaly detector. We recommend the combined use of\nDeepSVDD and DDD for purely unsupervised applications, with the addition of\nflow models for improved performance when resources allow.\n  Findings suggest that network architectures that excel in supervised\ncontexts, such as the particle transformer with standard model interactions,\nalso perform well as unsupervised anomaly detectors. We also show that with\nthese methods, it is likely possible to recognize 4-top quark production as an\nanomaly without prior knowledge of the process. We argue that the Large Hadron\nCollider community can transform supervised classifiers into anomaly detectors\nto uncover potential new physical phenomena in each search.",
            "pdf_url": "http://arxiv.org/pdf/2406.18469v1",
            "published": "2024-06-26 16:27:42+00:00",
            "updated": "2024-06-26 16:27:42+00:00"
        },
        {
            "title": "Bayesian inverse Navier-Stokes problems: joint flow field reconstruction and parameter learning",
            "authors": "Alexandros Kontogiannis, Scott V. Elgersma, Andrew J. Sederman, Matthew P. Juniper",
            "summary": "We formulate and solve a Bayesian inverse Navier-Stokes (N-S) problem that\nassimilates velocimetry data in order to jointly reconstruct a 3D flow field\nand learn the unknown N-S parameters, including the boundary position. By\nhardwiring a generalised N-S problem, and regularising its unknown parameters\nusing Gaussian prior distributions, we learn the most likely parameters in a\ncollapsed search space. The most likely flow field reconstruction is then the\nN-S solution that corresponds to the learned parameters. We develop the method\nin the variational setting and use a stabilised Nitsche weak form of the N-S\nproblem that permits the control of all N-S parameters. To regularise the\ninferred the geometry, we use a viscous signed distance field (vSDF) as an\nauxiliary variable, which is given as the solution of a viscous Eikonal\nboundary value problem. We devise an algorithm that solves this inverse\nproblem, and numerically implement it using an adjoint-consistent stabilised\ncut-cell finite element method. We then use this method to reconstruct magnetic\nresonance velocimetry (flow-MRI) data of a 3D steady laminar flow through a\nphysical model of an aortic arch for two different Reynolds numbers and\nsignal-to-noise ratio (SNR) levels (low/high). We find that the method can\naccurately i) reconstruct the low SNR data by filtering out the noise/artefacts\nand recovering flow features that are obscured by noise, and ii) reproduce the\nhigh SNR data without overfitting. Although the framework that we develop\napplies to 3D steady laminar flows in complex geometries, it readily extends to\ntime-dependent laminar and Reynolds-averaged turbulent flows, as well as\nnon-Newtonian (e.g. viscoelastic) fluids.",
            "pdf_url": "http://arxiv.org/pdf/2406.18464v1",
            "published": "2024-06-26 16:16:36+00:00",
            "updated": "2024-06-26 16:16:36+00:00"
        },
        {
            "title": "Large Knowledge Model: Perspectives and Challenges",
            "authors": "Huajun Chen",
            "summary": "Humankind's understanding of the world is fundamentally linked to our\nperception and cognition, with \\emph{human languages} serving as one of the\nmajor carriers of \\emph{world knowledge}. In this vein, \\emph{Large Language\nModels} (LLMs) like ChatGPT epitomize the pre-training of extensive,\nsequence-based world knowledge into neural networks, facilitating the\nprocessing and manipulation of this knowledge in a parametric space. This\narticle explores large models through the lens of \"knowledge\". We initially\ninvestigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in\nenhancing LLMs, covering aspects like knowledge-augmented language model,\nstructure-inducing pre-training, knowledgeable prompts, structured CoT,\nknowledge editing, semantic tools for LLM and knowledgeable AI agents.\nSubsequently, we examine how LLMs can boost traditional symbolic knowledge\nbases, encompassing aspects like using LLM as KG builder and controller,\nstructured knowledge pretraining, and LLM-enhanced symbolic reasoning.\nConsidering the intricate nature of human knowledge, we advocate for the\ncreation of \\emph{Large Knowledge Models} (LKM), specifically engineered to\nmanage diversified spectrum of knowledge structures. This promising undertaking\nwould entail several key challenges, such as disentangling knowledge base from\nlanguage models, cognitive alignment with human knowledge, integration of\nperception and cognition, and building large commonsense models for interacting\nwith physical world, among others. We finally propose a five-\"A\" principle to\ndistinguish the concept of LKM.",
            "pdf_url": "http://arxiv.org/pdf/2312.02706v2",
            "published": "2023-12-05 12:07:30+00:00",
            "updated": "2024-06-26 16:11:55+00:00"
        },
        {
            "title": "Scalable tomography of many-body quantum environments with low temporal entanglement",
            "authors": "Ilia A. Luchnikov, Michael Sonner, Dmitry A. Abanin",
            "summary": "Describing dynamics of a quantum system coupled to a complex many-body\nenvironment is a ubiquitous problem in quantum science. General non-Markovian\nenvironments are characterized by their influence matrix~(IM) -- a multi-time\ntensor arising from repeated interactions between the system and environment.\nWhile complexity of the most generic IM grows exponentially with the evolution\ntime, recent works argued that for many instances of physical many-body\nenvironments, the IM is significantly less complex. This is thanks to area-law\nscaling of temporal entanglement, which quantifies the correlations between the\npast and the future states of the system. However, efficient classical\nalgorithms for computing IM are only available for non-interacting environments\nor certain interacting 1D environments. Here, we study a learning algorithm for\nreconstructing IMs of large many-body environments simulated on a quantum\nprocessor. This hybrid algorithm involves experimentally collecting quantum\nmeasurement results of auxiliary qubits which are repeatedly coupled to the\nmany-body environment, followed by a classical machine-learning construction of\na matrix-product (MPS) representation of the IM. Using the example of 1D\nspin-chain environments, with a classically generated training dataset, we\ndemonstrate that the algorithm allows scalable reconstruction of IMs for long\nevolution times. The reconstructed IM can be used to efficiently model quantum\ntransport through an impurity, including cases with multiple leads and\ntime-dependent controls. These results indicate the feasibility of\ncharacterizing long-time dynamics of complex environments using a limited\nnumber of measurements, under the assumption of a moderate temporal\nentanglement.",
            "pdf_url": "http://arxiv.org/pdf/2406.18458v1",
            "published": "2024-06-26 16:08:45+00:00",
            "updated": "2024-06-26 16:08:45+00:00"
        },
        {
            "title": "How to Achieve High Spatial Resolution in Organic Optobioelectronic Devices?",
            "authors": "Luca Fabbri, Ludovico Migliaccio, Aleksandra \u0160irvinskyt\u0117, Giacomo Rizzi, Luca Bondi, Cristiano Tamarozzi, Stefan A. L. Weber, Beatrice Fraboni, Eric Daniel Glowacki, Tobias Cramer",
            "summary": "Light activated local stimulation and sensing of biological cells offers\nenormous potential for minimally invasive bioelectronic interfaces. Organic\nsemiconductors are a promising material class to achieve this kind of\ntransduction due to their optoelectronic properties and biocompatibility. Here\nwe investigate which material properties are necessary to keep the optical\nexcitation localized. This is critical to single cell transduction with high\nspatial resolution. As a model system we use organic photocapacitors for cell\nstimulation made of the small molecule semiconductors H2Pc and PTCDI. We\ninvestigate the spatial broadening of the localized optical excitation with\nphotovoltage microscopy measurements. Our experimental data combined with\nmodelling show that resolution losses due to the broadening of the excitation\nare directly related to the effective diffusion length of charge carriers\ngenerated at the heterojunction. With additional transient photovoltage\nmeasurements we find that the H2Pc/PTCDI heterojunction offers a small\ndiffusion length of lambda = 1.5 +/- 0.1 um due to the small mobility of charge\ncarriers along the heterojunction. Instead covering the heterojunction with a\nlayer of PEDOT:PSS improves the photocapacitor performance but increases the\ncarrier diffusion length to lambda = 7.0 +/- 0.3 um due to longer lifetime and\nhigher carrier mobility. Furthermore, we introduce electrochemical photocurrent\nmicroscopy experiments to demonstrate micrometric resolution with the\npn-junction under realistic aqueous operation conditions. This work offers\nvaluable insights into the physical mechanisms governing the excitation and\ntransduction profile and provide design principles for future organic\nsemiconductor junctions, aiming to achieve high efficiency and high spatial\nresolution.",
            "pdf_url": "http://arxiv.org/pdf/2406.18447v1",
            "published": "2024-06-26 15:52:40+00:00",
            "updated": "2024-06-26 15:52:40+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Towards diffusion models for large-scale sea-ice modelling",
            "authors": "Tobias Sebastian Finn, Charlotte Durand, Alban Farchi, Marc Bocquet, Julien Brajard",
            "summary": "We make the first steps towards diffusion models for unconditional generation\nof multivariate and Arctic-wide sea-ice states. While targeting to reduce the\ncomputational costs by diffusion in latent space, latent diffusion models also\noffer the possibility to integrate physical knowledge into the generation\nprocess. We tailor latent diffusion models to sea-ice physics with a censored\nGaussian distribution in data space to generate data that follows the physical\nbounds of the modelled variables. Our latent diffusion models reach similar\nscores as the diffusion model trained in data space, but they smooth the\ngenerated fields as caused by the latent mapping. While enforcing physical\nbounds cannot reduce the smoothing, it improves the representation of the\nmarginal ice zone. Therefore, for large-scale Earth system modelling, latent\ndiffusion models can have many advantages compared to diffusion in data space\nif the significant barrier of smoothing can be resolved.",
            "pdf_url": "http://arxiv.org/pdf/2406.18417v1",
            "published": "2024-06-26 15:11:15+00:00",
            "updated": "2024-06-26 15:11:15+00:00"
        },
        {
            "title": "Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process",
            "authors": "Tianyu Lin, Zhiguang Chen, Zhonghao Yan, Fudan Zheng, Weijiang Yu",
            "summary": "Diffusion models have demonstrated their effectiveness across various\ngenerative tasks. However, when applied to medical image segmentation, these\nmodels encounter several challenges, including significant resource and time\nrequirements. They also necessitate a multi-step reverse process and multiple\nsamples to produce reliable predictions. To address these challenges, we\nintroduce the first latent diffusion segmentation model, named SDSeg, built\nupon stable diffusion (SD). SDSeg incorporates a straightforward latent\nestimation strategy to facilitate a single-step reverse process and utilizes\nlatent fusion concatenation to remove the necessity for multiple samples.\nExtensive experiments indicate that SDSeg surpasses existing state-of-the-art\nmethods on five benchmark datasets featuring diverse imaging modalities.\nRemarkably, SDSeg is capable of generating stable predictions with a solitary\nreverse step and sample, epitomizing the model's stability as implied by its\nname. The code is available at\nhttps://github.com/lin-tianyu/Stable-Diffusion-Seg",
            "pdf_url": "http://arxiv.org/pdf/2406.18361v1",
            "published": "2024-06-26 14:01:07+00:00",
            "updated": "2024-06-26 14:01:07+00:00"
        },
        {
            "title": "Molecular Diffusion Models with Virtual Receptors",
            "authors": "Matan Halfon, Eyal Rozenberg, Ehud Rivlin, Daniel Freedman",
            "summary": "Machine learning approaches to Structure-Based Drug Design (SBDD) have proven\nquite fertile over the last few years. In particular, diffusion-based\napproaches to SBDD have shown great promise. We present a technique which\nexpands on this diffusion approach in two crucial ways. First, we address the\nsize disparity between the drug molecule and the target/receptor, which makes\nlearning more challenging and inference slower. We do so through the notion of\na Virtual Receptor, which is a compressed version of the receptor; it is\nlearned so as to preserve key aspects of the structural information of the\noriginal receptor, while respecting the relevant group equivariance. Second, we\nincorporate a protein language embedding used originally in the context of\nprotein folding. We experimentally demonstrate the contributions of both the\nvirtual receptors and the protein embeddings: in practice, they lead to both\nbetter performance, as well as significantly faster computations.",
            "pdf_url": "http://arxiv.org/pdf/2406.18330v1",
            "published": "2024-06-26 13:18:42+00:00",
            "updated": "2024-06-26 13:18:42+00:00"
        },
        {
            "title": "Generative artificial intelligence in ophthalmology: multimodal retinal images for the diagnosis of Alzheimer's disease with convolutional neural networks",
            "authors": "I. R. Slootweg, M. Thach, K. R. Curro-Tafili, F. D. Verbraak, F. H. Bouwman, Y. A. L. Pijnenburg, J. F. Boer, J. H. P. de Kwisthout, L. Bagheriye, P. J. Gonz\u00e1lez",
            "summary": "Background/Aim. This study aims to predict Amyloid Positron Emission\nTomography (AmyloidPET) status with multimodal retinal imaging and\nconvolutional neural networks (CNNs) and to improve the performance through\npretraining with synthetic data. Methods. Fundus autofluorescence, optical\ncoherence tomography (OCT), and OCT angiography images from 328 eyes of 59\nAmyloidPET positive subjects and 108 AmyloidPET negative subjects were used for\nclassification. Denoising Diffusion Probabilistic Models (DDPMs) were trained\nto generate synthetic images and unimodal CNNs were pretrained on synthetic\ndata and finetuned on real data or trained solely on real data. Multimodal\nclassifiers were developed to combine predictions of the four unimodal CNNs\nwith patient metadata. Class activation maps of the unimodal classifiers\nprovided insight into the network's attention to inputs. Results. DDPMs\ngenerated diverse, realistic images without memorization. Pretraining unimodal\nCNNs with synthetic data improved AUPR at most from 0.350 to 0.579. Integration\nof metadata in multimodal CNNs improved AUPR from 0.486 to 0.634, which was the\nbest overall best classifier. Class activation maps highlighted relevant\nretinal regions which correlated with AD. Conclusion. Our method for generating\nand leveraging synthetic data has the potential to improve AmyloidPET\nprediction from multimodal retinal imaging. A DDPM can generate realistic and\nunique multimodal synthetic retinal images. Our best performing unimodal and\nmultimodal classifiers were not pretrained on synthetic data, however\npretraining with synthetic data slightly improved classification performance\nfor two out of the four modalities.",
            "pdf_url": "http://arxiv.org/pdf/2406.18247v1",
            "published": "2024-06-26 10:49:26+00:00",
            "updated": "2024-06-26 10:49:26+00:00"
        },
        {
            "title": "Galaxy spectroscopy without spectra: Galaxy properties from photometric images with conditional diffusion models",
            "authors": "Lars Doorenbos, Eva Sextl, Kevin Heng, Stefano Cavuoti, Massimo Brescia, Olena Torbaniuk, Giuseppe Longo, Raphael Sznitman, Pablo M\u00e1rquez-Neila",
            "summary": "Modern spectroscopic surveys can only target a small fraction of the vast\namount of photometrically cataloged sources in wide-field surveys. Here, we\nreport the development of a generative AI method capable of predicting optical\ngalaxy spectra from photometric broad-band images alone. This method draws from\nthe latest advances in diffusion models in combination with contrastive\nnetworks. We pass multi-band galaxy images into the architecture to obtain\noptical spectra. From these, robust values for galaxy properties can be derived\nwith any methods in the spectroscopic toolbox, such as standard population\nsynthesis techniques and Lick indices. When trained and tested on 64x64-pixel\nimages from the Sloan Digital Sky Survey, the global bimodality of star-forming\nand quiescent galaxies in photometric space is recovered, as well as a\nmass-metallicity relation of star-forming galaxies. The comparison between the\nobserved and the artificially created spectra shows good agreement in overall\nmetallicity, age, Dn4000, stellar velocity dispersion, and E(B-V) values.\nPhotometric redshift estimates of our generative algorithm can compete with\nother current, specialized deep-learning techniques. Moreover, this work is the\nfirst attempt in the literature to infer velocity dispersion from photometric\nimages. Additionally, we can predict the presence of an active galactic nucleus\nup to an accuracy of 82%. With our method, scientifically interesting galaxy\nproperties, normally requiring spectroscopic inputs, can be obtained in future\ndata sets from large-scale photometric surveys alone. The spectra prediction\nvia AI can further assist in creating realistic mock catalogs.",
            "pdf_url": "http://arxiv.org/pdf/2406.18175v1",
            "published": "2024-06-26 08:49:51+00:00",
            "updated": "2024-06-26 08:49:51+00:00"
        }
    ]
}